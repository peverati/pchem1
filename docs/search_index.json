[
["index.html", "The Live Textbook of Physical Chemistry 1 Preface How to use this book", " The Live Textbook of Physical Chemistry 1 Dr. Roberto Peverati 03 November 2021 Preface This textbook is the official textbook for the Physical Chemistry 1 Course (CHM 3001) at Florida Tech. The instructor for this course and author of this textbook is Dr. Roberto Peverati. Contacts: rpeverati@fit.edu, Office: OPS 333, (321) 674-7735 Chemistry Program, Department of Biomedical and Chemical Engineering and Science Florida Institute of Technology, Melbourne, FL. This live open textbook is distributed under the CC-BY-SA 4.0 License and it was funded by the Florida Tech Open Educational Resources Grant Program: A Collaboration of the Teaching Council, eEducation, and the Evans Library. How to use this book Please read this book carefully, since everything that will be in your exams is explained here. Since this book is specifically tailored for the CHM 3001 course at Florida Tech, there are no superfluous parts. In other words, everything in it might be subject to question in the quizzes and the final exam. Definitions and exercises are usually numbered and are highlighted in the text in this format (lighter grey, indented, and following a grey vertical bar). Please study the definitions carefully since they are fundamental concepts that will be used several times in the remainder of the text, and they will be subject to quizzes and exams. Exercises are essential for cementing the concepts, and you should attempt to execute them first without looking at the solution. Even if you were able to solve an exercise on your own, always read the solution after, since it might contain additional explanations expanding the main concepts in the text. Navigating the book should be straightforward. On each page, there is a useful sidebar on the left that gives you an overview of all chapters, and a toolbar at the top with important tools. Arrows to shift between chapters might also be present, depending on your browser. If you are old-school and prefer a pdf, you can download a printout by clicking on the toolbar’s corresponding icon. If you are really old-school and prefer a printed book, the best solution is to download the pdf and print it yourself. It is a LaTeX book, and I can promise you it will look good on paper. However, I cannot provide physical copies to each student. In the toolbar, you will find a useful search box that is capable of searching the entire book. The most adventurous will find in the toolbar a link to the raw GitHub source code. Feel free to head on over there and fork the book. Each chapter of this book represents one week of work in the classroom and at home. The sidebar on the left will reflect your syllabus, as well as the main structure of the class on Canvas. The book is a live document, which means it will be updated throughout the semester with new material. While you are not required to check it every day, you might want to review each week’s chapter before the lecture on Friday. If you spot a mistake or a typo, contact Dr. Peverati via email and you will receive a credit of up to three points towards your final score, once the typo has been verified and corrected. "],
["SystemVariables.html", "1 Systems and Variables 1.1 Thermodynamic Systems 1.2 Thermodynamic Variables", " 1 Systems and Variables 1.1 Thermodynamic Systems A thermodynamic system—or just simply a system—is a portion of space with defined boundaries that separate it from its surroundings (see also the title picture of this book). The surroundings may include other thermodynamic systems or physical systems that are not thermodynamic systems. A boundary may be a real physical barrier or a purely notional one. Typical examples of systems are reported in Figure 1.1 below.1 Figure 1.1: Examples of Thermodynamic Systems. In the first case, a liquid is contained in a typical Erlenmeyer flask. The boundaries of the system are the glass walls of the beaker. The second system is represented by the gas contained in a balloon. The boundary is a physical barrier also in this case, being the plastic of the balloon. The third case is that of a thunder cloud. The boundary is not a well-defined physical barrier, but rather some condition of pressure and chemical composition at the interface between the cloud and the atmosphere. Finally, the fourth case is the case of an open flame. In this case, the boundary is again non-physical, and possibly even harder to define than for a cloud. For example, we can choose to define the flame based on some temperature threshold, color criterion, or even some chemical one. Despite the lack of physical boundaries, the cloud and the flame—as portions of space containing matter—can be defined as a thermodynamic system. A system can exchange exclusively mass, exclusively energy, or both mass and energy with its surroundings. Depending on the boundaries’ ability to transfer these quantities, a system is defined as open, closed, or isolated. An open system exchanges both mass and energy. A closed system exchanges only energy, but not mass. Finally, an isolated system does not exchange mass nor energy. When a system exchanges mass or energy with its surroundings, some of its parameters (variables) change. For example, if a system loses mass to the surroundings, the number of molecules (or moles) in the system will decrease. Similarly, if a system absorbs some energy, one or more of its variables (such as its temperature) increase. Mass and energy can flow into the system or out of the system. Let’s consider mass exchange only. If some molecules of a substance leave the system, and then the same amount of molecules flow back into the system, the system will not be modified. We can count, for example, 100 molecules leaving a system and assign them the value of –100 in an outgoing process, and then observe the same 100 molecules going back into the system and assign them a value of +100. Regardless of the number of molecules present in the system in the first place, the overall balance will be –100 (from the outgoing process) +100 (from the ingoing process) = 0, which brings the system to its initial situation (mass has not changed). However, from a mathematical standpoint, we could have equally assigned the label +100 to the outgoing process and –100 to the ingoing one, and the overall total would have stayed the same: +100–100 = 0. Which of the two labels is best? For this case, it seems natural to define a mass going out of the system as negative (the system is losing it), and a mass going into the system as positive (the system is gaining it), but is it as straightforward for energy? Type of System Mass Energy (either heat or work) Open Y Y Closed N Y Isolated N N Here is another example. Let’s consider a system that is composed of your body. When you exercise, you lose mass in the form of water (sweat) and CO2 (from respiration). This mass loss can be easily measured by stepping on a scale before and after exercise. The number you observe on the scale will go down. Hence you have lost weight. After exercise, you will reintegrate the lost mass by drinking and eating. If you have reinstated the same amount you have lost, your weight will be the same as before the exercise (no weight loss). Nevertheless, which label do you attach to the amounts that you have lost and gained? Let’s say that you are running a 5 km race without drinking nor eating, and you measure your weight dropping 2 kg after the race. After the race, you drink 1.5 kg of water and eat a 500 g energy bar. Overall you did not lose any weight, and it would seem reasonable to label the 2 kg that you’ve lost as negative (–2) and the 1.5 kg of water that you drank and the 500 g bar that you ate as positive (+1.5 +0.5 = +2). But is it the only way? After all, you didn’t gain nor lose any weight, so why not calling the 2 kg due to exercise +2 and the 2 that you’ve ingested as –2? It might seem silly, but mathematically it would not make any difference, the total would still be zero. Now, let’s consider energy instead of mass. To run the 5km race, you have spent 500 kcal, which then you reintegrate precisely by eating the energy bar. Which sign would you put in front of the kilocalories that you “burned” during the race? In principle, you’ve lost them, so if you want to be consistent, you should use a negative sign. But if you think about it, you’ve put quite an effort to “lose” those kilocalories, so it might not feel bad to assign them a positive sign instead. After all, it’s perfectly OK to say, “I’ve done a 500 kcal run today”, while it might sound quite awkward to say, “I’ve done a –500 kcal run today.” Our previous exercise with mass demonstrates that it doesn’t really matter which sign you put in front of the quantities. As long as you are consistent throughout the process, the signs will cancel out. If you’ve done a +500 kcal run, you’ve eaten a bar for –500 kcal, resulting in a total zero loss/gain. Alternatively, if you’ve done a –500 kcal run, you would have eaten a +500 kcal bar, for a total of again zero loss/gain. These simple examples demonstrate that the sign that we assign to quantities that flow through a boundary is arbitrary (i.e., we can define it any way we want, as long as we are always consistent with ourselves). There is no best way to assign those signs. If you ask two different people, you might obtain two different answers. But we are scientists, and we must make sure to be rigorous. For this reason, chemists have established a convention for the signs that we will follow throughout this course. If we are consistent in following the convention, we are guaranteed to never make any mistake with the signs. Definition 1.1 The chemistry convention of the sign is system-centric:2 If something (energy or mass) goes into the system it has a positive sign (the system is gaining) If something (energy or mass) goes out of the system it has a negative sign (the system is losing) If you want a trick to remember the convention, use the weight loss/gain during the exercise example above. You are the system, if you lose weight, the kilograms will be negative (–2 kg), while if you gain weight, they will be positive (+2 kg). Similarly, if you eat an energy bar, you are the system, and you will have increased your energy by +500 kcal (positive). In contrast, if you burned energy during exercise, you are the system, and you will have lost energy, hence –500 kcal (negative). If the system is a balloon filled with gas, and the balloon is losing mass, you are the balloon, and you are losing weight; hence the mass will be negative. If the balloon is absorbing heat (likely increasing its temperature and increasing its volume), you are the system, and you are gaining heat; hence heat will be positive. 1.2 Thermodynamic Variables The system is defined and studied using parameters that are called variables. These variables are quantities that we can measure, such as pressure and temperature. However, don’t be surprised if, on some occasions, you encounter some variable that is a little harder to measure directly, such as entropy. The variables depend only on the current state of the system, and therefore they define it. If I know the values of all the “relevant variables” of a system, I know the state of the system. The relationship between the variables is described by mathematical functions called state functions, while the “relevant variables” are called natural variables. What are the “relevant variables” of a system? The answer to this question depends on the system, and it is not always straightforward. The simplest case is the case of an ideal gas, for which the natural variables are those that enter the ideal gas law and the corresponding equation: \\[\\begin{equation} PV=nRT \\tag{1.1} \\end{equation}\\] Therefore, the natural variables for an ideal gas are the pressure P, the volume V, the number of moles n, and the temperature T, with R being the ideal gas constant. Recalling from the general chemistry courses, R is a universal dimensional constant which has the values of R = 8.31 kJ/mol in SI units. We will use the ideal gas equation and its variables as an example to discuss variables and functions in this chapter. We will analyze more complicated cases in the next chapters. Variables can be classified according to numerous criteria, each with its advantages and disadvantages. A typical classification is: Physical variables (\\(P\\), \\(V\\), \\(T\\) in the ideal gas law): independent of the chemical composition of the system. Chemical variables (\\(n\\) in the ideal gas law): dependent on the chemical composition of the system. Another useful classification is: Intensive variables (\\(P\\), \\(T\\) in the ideal gas law): independent of the physical size (extension) of the system. Extensive variables (\\(V\\), \\(n\\) in the ideal gas law): dependent on the physical size (extension) of the system. When we deal with thermodynamic systems, it is more convenient to work with intensive variables. Luckily, it is relatively easy to convert extensive variables into intensive ones by just taking the ratio between the two of them. For an ideal gas, by taking the ratio between V and n, we obtained the intensive variable called molar volume: \\[\\begin{equation} \\overline{V}=\\frac{V}{n}. \\tag{1.2} \\end{equation}\\] We can then recast eq. (1.1) as: \\[\\begin{equation} P\\overline{V}=RT, \\tag{1.3} \\end{equation}\\] which is the preferred equation that we will use for the remainder of this course. The ideal gas equation connects the 3 variables pressure, molar volume, and temperature, reducing the number of independent variables to just 2. In other words, once 2 of the 3 variables are known, the other one can be easily obtained using these simple relations: \\[\\begin{equation} P(T,\\overline{V})=\\frac{RT}{\\overline{V}}, \\tag{1.4} \\end{equation}\\] \\[\\begin{equation} \\overline{V}(T,P)=\\frac{RT}{P}, \\tag{1.5} \\end{equation}\\] \\[\\begin{equation} T(P,\\overline{V})=\\frac{P\\overline{V}}{R}. \\tag{1.6} \\end{equation}\\] These equations define three state functions, each one expressed in terms of two independent natural variables. For example, eq. (1.4) defines the state function called “pressure”, expressed as a function of temperature and molar volume. Similarly, eq. (1.5) defines the “molar volume” as a function of temperature and pressure, and eq. (1.6) defines the “temperature” as a function of pressure and molar volume. When we know the natural variables that define a state function, we can express the function using its total differential, for example for the pressure \\(P(T, \\overline{V})\\): \\[\\begin{equation} dP=\\left( \\frac{\\partial P}{\\partial T} \\right)dT + \\left( \\frac{\\partial P}{\\partial \\overline{V}} \\right)d\\overline{V} \\tag{1.7} \\end{equation}\\] Recalling Schwartz’s theorem, the mixed partial second derivatives that can be obtained from eq. (1.7) are the same: \\[\\begin{equation} \\frac{\\partial^2 P}{\\partial T \\partial \\overline{V}}=\\frac{\\partial}{\\partial \\overline{V}}\\frac{\\partial P}{\\partial T}=\\frac{\\partial}{\\partial T}\\frac{\\partial P}{\\partial \\overline{V}}=\\frac{\\partial^2 P}{\\partial \\overline{V} \\partial T} \\tag{1.8} \\end{equation}\\] Which can be easily verified considering that: \\[\\begin{equation} \\frac{\\partial}{\\partial \\overline{V}} \\frac{\\partial P}{\\partial T} = \\frac{\\partial}{\\partial \\overline{V}} \\left(\\frac{R}{\\overline{V}}\\right) = -\\frac{R}{\\overline{V}^2} \\tag{1.9} \\end{equation}\\] and \\[\\begin{equation} \\frac{\\partial}{\\partial T} \\frac{\\partial P}{\\partial \\overline{V}} = \\frac{\\partial}{\\partial T} \\left(\\frac{-RT}{\\overline{V}^2}\\right) = -\\frac{R}{\\overline{V}^2} \\tag{1.10} \\end{equation}\\] While for the ideal gas law, all the variables are “well-behaved” and always satisfy Schwartz’s theorem, we will encounter some variable for which Schwartz’s theorem does not hold. Mathematically, if the Schwartz’s theorem is violated (i.e., if the mixed second derivatives are not equal), then the corresponding function cannot be integrated, hence it is not a state function. The differential of a function that cannot be integrated cannot be defined exactly. Thus, these functions are called path functions; that is, they depend on the path rather than the state. The most typical examples of path functions that we will encounter in the next chapters are heat (\\(Q\\)) and work (\\(W\\)). For these functions, we cannot define exact differentials \\(dQ\\) and \\(dW\\), and we must introduce a new notation to define their “inexact differentials” \\(đ Q\\) and \\(đ W\\). We will return to exact and inexact differential when we discuss heat and work, but for this chapter, it is crucial to notice the difference between a state function and a path function. A typical example to understand the difference between state and path function is to consider the distance between two geographical locations. Let’s, for example, consider the distance between New York City and Los Angeles. If we fly straight from one city to the other, there are roughly 4,000 km between them. This “air distance” depends exclusively on the geographical location of the two cities. It stays constant regardless of the method of transportation that I have accessibility to travel between them. Since the cities’ positions depend uniquely on their latitudes and longitudes, the “air distance” is a state function, i.e., it is uniquely defined from a simple relationship between measurable variables. However, the “air distance” is not the distance that I will practically have to drive when I go from NYC to LA. Such “travel distance” depends on the method of transportation that I decide to take (airplane vs. car vs. train vs. boat vs. …). It will depend on a plentiful amount of other factors such as the choice of the road to be traveled (if going by car), the atmospheric conditions (if flying), and so on. A typical “travel distance” by car is, for example, about 4,500 km, which is about 12% more than the “air distance.” Indeed, we could even design a very inefficient road trip that avoids all highways and will result in a “travel distance” of 8,000 km or even more (200% of the “air distance”). The “travel distance” is a clear example of a path function because it depends on the specific path that I decide to travel to go from NYC to LA. See Figure 1.2. Figure 1.2: State Functions vs. Path Functions. The photos depicted in this figure are taken from Wikipedia: the Erlenmeyer flasks photo was taken by user Maytouch L., and distributed under CC-BY-SA license; the cloud photo was taken by user Mathew T Rader, and distributed under CC-BY-SA license; the flame picture was taken by user Oscar, and distributed under CC-BY-SA license; the balloon photo is in the public domain.↩︎ Notice that physicists use a different sign convention when it comes to thermodynamics. To eliminate confusion, I will not describe the physics convention here, but if you are reading thermodynamics on a physics textbook, or if you are browsing the web and stumble on thermodynamics formula (e.g., on Wikipedia), please be advised that some quantity, such as work, might have a different sign than the one that is used in this textbook. Obviously, the science will not change, but you need to be always consistent, so if you decide that you want to use the physics convention, make sure to always use the physics convention. In this course, on the other hand, we will always use the chemistry one, as introduced above.↩︎ "],
["ZerothLaw.html", "2 Zeroth Law of Thermodynamics 2.1 What is Thermodynamics? 2.2 The Zeroth Law of Thermodynamics 2.3 Calculation of Heat 2.4 Calculation of Work", " 2 Zeroth Law of Thermodynamics 2.1 What is Thermodynamics? Thermodynamics is the branch of science that deals with heat and work, and their relation to energy. As the definition suggests, thermodynamics is concerned with two types of energy: heat and work. A formal definition of these forms of energy is as follow: Work is exchanged if external parameters are changed during the process. Heat is exchanged if only internal parameters are changed during the process. As we saw in chapter 1, heat and work are not “well-behaved” quantities because they are path functions. On the one hand, it might be simple to measure the amount of heat and/or work experimentally, these measured quantities cannot be used to define the state of a system. Since heat and work are path functions, their values depend directly on the methods used to transfer them (their paths). Understanding and quantifying these energy transfers is the reason why thermodynamics was developed in the first place. The origin of thermodynamics dates back to the seventeenth century when people began to use heat and work for technological applications. These early scientists needed a mathematical tool to understand how heat and work were related to each other, and how they were related to the other variables that they were able to measure, such as temperature and volume. Before we even discuss the definition of energy and how it relates to heat and work, it is crucial to introduce the essential concept of temperature. Temperature is an intuitive concept that has a surprisingly complex definition at the microscopic level.3 However, for all our purposes, it is not essential to have a microscopic definition of temperature, as long as we have the guarantee that this quantity can be measured unambiguously. In other words, we only need a mathematical definition of temperature that agrees with the physical existence of thermometers. 2.2 The Zeroth Law of Thermodynamics The mathematical definition that guarantees that thermal equilibrium is an equivalence relation is called the zeroth law of thermodynamics. The zeroth law of thermodynamics states that if two thermodynamic systems are each in thermal equilibrium with a third one, then they are in thermal equilibrium with each other. The law might appear trivial and possibly redundant, but it is a fundamental requirement for the mathematical formulation of thermodynamics, so it needs to be stated. The zeroth law can be summarized by the following simple mathematical relation: Definition 2.1 Zeroth Law of Thermodynamics: If \\(T_A = T_B\\), and \\(T_B = T_C\\), then \\(T_A = T_C\\). Notice that when we state the zeroth law, it appears intuitive. However, this is not necessarily the case. Let’s, for example, consider a pot of boiling water at \\(P=1\\;\\mathrm{bar}\\). Its temperature, \\(T_{H_2O}\\), is about 373 K. Let’s now submerge in this water a coin made of wood and another coin made of metal. After some sufficient time, the wood coin will be in thermal equilibrium with the water, and its temperature \\(T_W = T_{H_2O}\\). Similarly, the metal coin will also be in thermal equilibrium with the water, hence \\(T_M = T_{H_2O}\\). According to the zeroth law, the temperature of the wood coin and that of the metal coin are precisely the same \\(T_W = T_M = 373\\;\\mathrm{K}\\), even if they are not in direct contact with each other. Now here’s the catch: since wood and metal transmit heat in different manners if I take the coins out of the water and put them immediately in your hands, one of them will be very hot, but the other will burn you. If you had to guess the temperature of the two coins without a thermometer, and without knowing that they were immersed in boiling water, would you suppose that they have the same temperature? Probably not. 2.3 Calculation of Heat Heat (\\(Q\\)) is a property that gets transferred between substances. Similarly to work, the amount of heat that flows through a boundary can be measured, but its mathematical treatment is complicated because heat is a path function. As you probably recall from general chemistry, the ability of a substance to absorb heat is given by a coefficient called the heat capacity, which is measured in SI in \\(\\frac{\\text{J}}{\\text{mol K}}\\). However, since heat is a path function, these coefficients are not unique, and we have different ones depending on how the heat transfer happens. 2.3.1 Processes at constant volume (isochoric) The heat capacity at constant volume measures the ability of a substance to absorb heat at constant volume. Recasting from general chemistry: The molar heat capacity at constant volume is the amount of heat required to increase the temperature of 1 mol of a substance by 1 K at constant volume. This simple definition can be written in mathematical terms as: \\[\\begin{equation} C_V = \\frac{đ Q_V}{n dT} \\Rightarrow đ Q_V = n C_V dT. \\tag{2.1} \\end{equation}\\] Given a known value of \\(C_V\\), the amount of heat that gets transfered can be easily calculated by measuring the changes in temperature, after integration of eq. (2.1): \\[\\begin{equation} đ Q_V = n C_V dT \\rightarrow \\int đ Q_V = n \\int_{T_i}^{T_F}C_V dT \\rightarrow Q_V = n C_V \\int_{T_i}^{T_F}dT, \\tag{2.2} \\end{equation}\\] which, assuming \\(C_V\\) independent of temperature, simply becomes: \\[\\begin{equation} Q_V \\cong n C_V \\Delta T. \\tag{2.3} \\end{equation}\\] 2.3.2 Processes at constant pressure (isobaric) Similarly to the previous case, the heat capacity at constant pressure measures the ability of a substance to absorb heat at constant pressure. Recasting again from general chemistry: The molar heat capacity at constant pressure is the amount of heat required to increase the temperature of 1 mol of a substance by 1 K at constant pressure. And once again, this mathematical treatment follows: \\[\\begin{equation} C_P = \\frac{đ Q_P}{n dT} \\Rightarrow đ Q_P = n C_P dT \\rightarrow \\int đ Q_P = n \\int_{T_i}^{T_F}C_P dT, \\tag{2.4} \\end{equation}\\] which result in the simple formula: \\[\\begin{equation} Q_P \\cong n C_P \\Delta T. \\tag{2.5} \\end{equation}\\] 2.4 Calculation of Work In thermodynamics, work (\\(W\\)) is the ability of a system to transfer energy by exerting a force on its surroundings. Work can be measured simply by evaluating its effects, such as displacing a massive object by some amount of space. The mathematical treatment of work, however, is complicated because work is a path function. In the following sections, we will analyze how work is calculated in some prototypical situations commonly encountered in the thermodynamical treatment of systems. Figure 2.1: Isothermal Expansion of an Ideal Gas Against a Constant External Pressure. Let’s consider the situation in Figure 2.1, where a special beaker with a piston that is free to move is filled with an ideal gas. The beaker sits on a desk, so the piston is not subject to any external forces other than the external pressure, \\(P_{\\text{ext}}\\), and the internal pressure of the gas, \\(P\\).4 The piston is initially compressed to a position that is not in equilibrium \\((i)\\). After the process, the piston reaches a final equilibrium position \\((f)\\). How do we calculate the work (\\(W\\)) performed by the system? From basic physics, we recall that the infinitesimal amount of work associated with an object moving in space is given by the force acting on the object (\\(F\\)) multiplied by the infinitesimal amount it gets displaced (\\(d h\\)): \\[\\begin{equation} đ W = - Fdh, \\tag{2.6} \\end{equation}\\] where the negative sign comes from the chemistry sign convention, Definition 1.1, since the work in Figure 2.1 is performed by the system (expansion). What kind of force is moving the piston? It is the force due to the pressure of the gas. Relying upon another definition from physics, the pressure is the ratio between the force (\\(F\\)) and the area (\\(A\\)) that such force acts upon: \\[\\begin{equation} P = F/A. \\tag{2.7} \\end{equation}\\] Obtaining \\(F\\) from eq. (2.7) and replacing it in eq. (2.6), we obtain: \\[\\begin{equation} đ W = - P \\underbrace{Adh}_{dV}, \\tag{2.8} \\end{equation}\\] and considering that \\(Adh\\) (area times infinitesimal height) is the definition of an infinitesimal volume \\(dV\\), we obtain: \\[\\begin{equation} đ W = - PdV, \\tag{2.9} \\end{equation}\\] If we want to calculate the amount of work performed by a system, \\(W\\), from eq. (2.9), we need to recall that \\(đ W\\) is an inexact differential. As such, we cannot integrate it from initial to final as for the (exact) differential of a state function, because: \\[\\begin{equation} \\int_{i}^{f}đ W \\neq W_f - W_i, \\tag{2.10} \\end{equation}\\] but rather: \\[\\begin{equation} \\int_{\\text{path}} đ W = W, \\tag{2.11} \\end{equation}\\] where the integration is performed along the path. Using eq. (2.11), we can integrate eq. (2.9) as: \\[\\begin{equation} \\int đ W = W = - \\int_{i}^{f} PdV, \\tag{2.12} \\end{equation}\\] where the integral on the left-hand side is taken along the path,5 while the integral on the right-hand side can be taken between the initial and final states, since \\(dV\\) is a state function. How do we solve the integral in eq. (2.12)? It turns out that there are many different ways to solve this integral (perhaps not surprisingly, since the left-hand side depends on the path), which we will explore in the next section. 2.4.1 \\(| W_{\\text{max}} |\\) and \\(| W_{\\text{min}} |\\) in processes at constant temperature (isothermal) At constant temperature, the piston in Figure 2.1 moves along the following PV diagram (this curve is obtained from an ideal gas at constant \\(T=298\\) K): An expansion of the gas will happen between \\(P_i\\) and \\(P_f\\). If the expansion happens in a one-step fast process, for example against external atmospheric pressure, then we can consider such final pressure constant (for example \\(P_f=P_{\\text{ext}} =1\\;\\mathrm{bar}\\)), and solve the integral as: \\[\\begin{equation} W_{\\text{1-step}} = - \\int_{i}^{f} P_{\\text{ext}}dV = -P_{\\text{ext}} \\int_{i}^{f} dV = -P_{\\text{ext}} (V_f-V_i), \\tag{2.13} \\end{equation}\\] Notice how the work is negative, since during an expansion the work is performed by the system (recall the chemistry sign convention). The absolute value of the work6 represents the red area of the PV-diagram: \\[\\begin{equation} \\left| W_{\\text{1-step}} \\right| = P_{\\text{ext}} (V_f-V_i) \\tag{2.14} \\end{equation}\\] If the process happens in two steps by pausing at an intermediate position (1) until equilibrium is reached, then we should calculate the work by dividing it into two separate processes, \\(A\\) and \\(B\\), and solve each one as we did in the previous case. The first process is an expansion between \\(P_i\\) and \\(P_1\\), with \\(P_1\\) constant. The absolute value of the work, \\(W_A\\), is represented by the blue area: \\[\\begin{equation} \\left| W_A \\right| = P_1 (V_1-V_i) \\tag{2.15} \\end{equation}\\] The second process is an expansion between \\(P_1\\) and \\(P_f\\), with \\(P_f=P_{\\text{ext}}\\) constant. The absolute value of the work for this second process is represented by the green area: \\[\\begin{equation} \\left| W_B \\right| = P_f (V_f-V_1) \\tag{2.16} \\end{equation}\\] The total absolute value of the work for the 2-step process is given by the sum of the two areas: \\[\\begin{equation} \\left| W_{\\text{2-step}} \\right| = \\left| W_A \\right| + \\left| W_B \\right| = P_1 (V_1-V_i)+P_f (V_f-V_1). \\tag{2.17} \\end{equation}\\] As can be easily verified by comparing the shaded areas in the plots, \\(\\left| W_{\\text{2-step}} \\right| &gt; \\left| W_{\\text{1-step}} \\right|\\). We can easily extend this procedure to consider processes that happens in 3, 4, 5, …, \\(n\\) steps. What is the limit of this procedure? In other words, what happens when \\(n \\rightarrow \\infty\\)? A simple answer is given by the plots in the next Figure, which clearly demonstrates that the maximum value of the area underneath the curve \\(\\left| W_{\\text{max}}\\right|\\) is achieved in an \\(\\infty\\)-step process, for which the work is calculated as: \\[\\begin{equation} \\left| W_{\\infty \\text{-step}} \\right| = \\left| W_{\\text{max}} \\right| = \\sum_{n}^{\\infty} P_n(V_n-V_{n-1}) = \\int_{i}^{f} PdV. \\tag{2.18} \\end{equation}\\] The integral on the right hand side of eq. (2.18) can be solved for an ideal gas by calculating the pressure using the ideal gas law \\(P=\\frac{nRT}{V}\\), and solving the integral since \\(n\\), \\(R\\), and \\(T\\) are constant: \\[\\begin{equation} \\left| W_{\\text{max}} \\right| = nRT \\int_{i}^{f} \\frac{dV}{V} = nRT \\ln \\frac{V_f}{V_i}. \\tag{2.19} \\end{equation}\\] This example demonstrates why work is a path function. If we perform a fast 1-step expansion, the system will perform an amount of work that is much smaller than the amount of work it can perform if the expansion between the same points happens slowly in an \\(\\infty\\)-step process. The same considerations that we made up to this point for expansion processes hold specularly for compression ones. The only difference is that the work associated with compressions will have a positive sign since it must be performed onto the system. As such, the amount of work for a transformation that happens in a finite amount of steps will be an upper bound to the minimum amount of work required to compress the system.7 \\(\\left| W_{\\text{min}} \\right|\\) for compressions is calculated as the area underneath the PV curve, exactly as \\(\\left| W_{\\text{min}} \\right|\\) for expansions in eq. (2.18). In fact, we will not even give a rigorous microscopic definition of temperature within this textbook.↩︎ For this simple thought experiment, we will ignore any external force that is not significant. In other words, we will not consider the friction of the piston on the beaker walls or any other foreign influence.↩︎ from here on we will replace the notation \\(\\int_{\\text{path}}\\) with the more convenient \\(\\int\\) and we will keep in mind that the integral of an inexact differential must be taken along the path.↩︎ we use the absolute value to avoid confusions due to the fact that the expansion work is negative according to Definition 1.1.↩︎ In contrast to a lower bound for expansion processes.↩︎ "],
["FirstLaw.html", "3 First Law of Thermodynamics 3.1 Calculation of Internal Energy Changes 3.2 The First Law of Thermodynamics 3.3 Reversible and Irreversible processes", " 3 First Law of Thermodynamics 3.1 Calculation of Internal Energy Changes The internal energy (\\(U\\)) of a system is a thermodynamic state function defined as: Definition 3.1 Internal Energy: Property of a system that can be either transferred or converted. In the absence of chemical transformations, heat and work are the only two forms of energy that thermodynamics is concerned with. Keeping in mind Definition 1.1, which gives the convention for the signs of heat and work, the internal energy of a system can be written as: \\[\\begin{equation} U = Q + W, \\tag{3.1} \\end{equation}\\] which we can write in differential form by considering that the internal energy is a state function, as: \\[\\begin{equation} dU = đ Q + đ W, \\tag{3.2} \\end{equation}\\] which, using eq. (2.9) becomes: \\[\\begin{equation} dU = đ Q - PdV. \\tag{3.3} \\end{equation}\\] 3.1.1 Internal energy in isothermal processes To study the behavior of the internal energy in a process at constant temperature (\\(dT=0\\)), James Prescott Joule (1818–1889) created the apparatus depicted in Figure 3.1. Figure 3.1: The Joule Expansion Experiment. The left side of the Joule apparatus’s inner chamber is filled with an ideal gas, while a vacuum is created in the right chamber. Both chambers are immersed in a water bath, to guarantee isolation from the environment. When the communication channel between the chambers is open, the gas expands and equilibrates. The work associated with the transformation is: \\[\\begin{equation} đ W=-P_{\\text{ext}}dV = 0, \\tag{3.4} \\end{equation}\\] since the chambers are not in communication with the environment, \\(P_{\\text{ext}}=0\\). Thus, changes in internal energy are associated with the heat transfer of the process, which can be measured by monitoring the temperature of the gas at the beginning, \\(T_i\\), and at the end of the experiment \\(T_f\\). Joule noticed experimentally that if he used an ideal gas for this experiment, the temperature would not change \\(T_i = T_f\\). Since the temperature doesn’t change, there is no heat transfer, and therefore the internal energy stays constant: \\[\\begin{equation} dU = đ Q = 0. \\tag{3.5} \\end{equation}\\] Notice that Joule’s conclusion is valid only for an ideal gas. If we expand a real gas, we do notice a change in temperature associated with the expansion. A typical example of this behavior is when you use a pressurized spray bottle and release its content for an extended time in the air. The container will typically get colder. We will discuss this behavior in chapter 11 when we will study non-ideal gases. From this simple experiment, we can conclude that the internal energy of an ideal gas depends only on its temperature. 3.1.2 Internal energy in adiabatic processes An adiabatic process is defined as a process that happens without the exchange of heat. As such, \\(đ Q=0\\), and the work associated with an adiabatic process becomes a state function: \\[\\begin{equation} dU=đ W=-PdV, \\tag{3.6} \\end{equation}\\] which can then be calculated using the formulas that we derived in section 2.4. Notice that isothermal and adiabatic are two very different processes. While an adiabatic process happens without the exchange of heat across the system’s boundaries, this does not mean that the system’s temperature does not change. Isothermal processes are usually associated with a heat transfer across the boundaries to maintain the temperature of the system constant. For adiabatic processes, it is quite the opposite since they are usually associated with a change in temperature. 3.1.3 Internal energy in isochoric processes An isocoric process is a process in which the volume does not change. Therefore, \\(đ W=0\\), and \\(dU = đ Q_V\\), which for 1 mol of substance and using eq. (2.1), becomes: \\[\\begin{equation} dU = đ Q_V = n C_V dT. \\tag{3.7} \\end{equation}\\] Since no work is performed at these conditions, the heat becomes a state function. Eq. (3.7) also gives a mathematical justification of the concept of heat capacity at constant volume. \\(C_V\\) can now be interpreted as the partial derivative (a coefficient) of a state function (the internal energy): \\[\\begin{equation} C_V = \\left( \\frac{\\partial U} {\\partial T} \\right)_{V,n}, \\tag{3.8} \\end{equation}\\] where we have replaced the total derivative \\(d\\) with a partial one \\(\\partial\\), and we have specified that the derivation happens at constant volume and number of moles. Eq. (3.8) equation brings a rigorous definition of heat capacity at constant volume for 1 mol of substance: Definition 3.2 The heat capacity of a substance, \\(C_V\\), represents its ability to absorb energy at constant volume. 3.1.4 Internal energy in isobaric processes In an isobaric process, the pressure does not change, hence \\(dP=0\\). Unfortunately, eq. (3.2) for this case does not simplify further, as happened in the two previous cases. However, in section 2.3.2, we have introduced the useful concept of heat capacity at constant \\(P\\). \\(C_P\\) was used in an adiabatic process in the same manner as \\(C_V\\) was used in the isochoric case. That is, as a coefficient to measure the amount of heat absorbed at constant pressure. Eq. (3.8) gave a mathematical definition of \\(C_V\\) as the partial derivative of a state function (the internal energy). But if heat capacities are coefficients, and coefficients are partial derivatives of state functions, how do we explain \\(C_P\\)? In order to do so, we can introduce a new state function, called the enthalpy (\\(H\\)), as: \\[\\begin{equation} H = U + PV, \\tag{3.9} \\end{equation}\\] and its differential, calculated as: \\[\\begin{equation} dH = dU + d(PV) = dU + PdV + \\overbrace{VdP}^{0}, \\tag{3.10} \\end{equation}\\] which can be rearranged as: \\[\\begin{equation} dU = dH -PdV, \\tag{3.11} \\end{equation}\\] Replacing eq. (3.11) into eq. (3.3): \\[\\begin{equation} dH -PdV = đ Q_P - PdV, \\tag{3.12} \\end{equation}\\] which simplifies to: \\[\\begin{equation} dH = đ Q_P. \\tag{3.13} \\end{equation}\\] Eq. (3.13) establishes that the heat exchanged at constant pressure is equal to a new state function called the enthalpy, defined by eq. (3.9). It also establishes a mathematical justification of the concept of heat capacity at constant pressure. Similarly to \\(C_V\\), \\(C_P\\) can now be interpreted as the partial derivative (a coefficient) of the new state function (the enthalpy): \\[\\begin{equation} C_P = \\left( \\frac{\\partial H} {\\partial T} \\right)_{P,n}, \\tag{3.14} \\end{equation}\\] Eq. (3.14) brings also a rigorous definition of heat capacity at constant pressure for 1 mol of substance: Definition 3.3 The heat capacity of a substance, \\(C_P\\), represents its ability to absorb enthalpy at constant pressure. 3.2 The First Law of Thermodynamics We finally come to a working definition of the first law. If we take an isolated system—i.e., a system that does not exchange heat nor mass with its surroundings—its internal energy is conserved. If the internal energy is conserved, \\(dU=0\\). Therefore, for an isolated system: \\[\\begin{equation} đ Q = -đ W, \\tag{3.15} \\end{equation}\\] and heat and work can be easily calculated using any of the appropriate formulas introduced in either section 2.4 or 2.3. The first law is a conservation law. It is intuitive since it comes directly from Lavoisier’s principle of “nothing is lost, nothing is created, everything is transformed.” Considering that the only system that is truly isolated is the universe, we can condense the first law in one simple sentence: Definition 3.4 First Law of Thermodynamics: The energy of the universe is conserved. 3.3 Reversible and Irreversible processes Let’s now consider the cycle in Figure 3.2. The process in this case starts from state 1 (system at \\(P_1V_1\\)), expands to state 2 (system at \\(P_2V_2\\)), and compresses back to state 1 (system back to \\(P_1V_1\\)). Figure 3.2: Expansion/Compression Cycle of an Ideal Gas. Since the process starts and finishes at the same state, the value of the internal energy at the end of the process will be the same as its value at the beginning, regardless of the path:8 \\[\\begin{equation} \\oint dU=0, \\tag{3.16} \\end{equation}\\] where the symbol \\(\\oint\\) indicates an integral around a cycle. Considering the work associated with the cycle, however, the situation is radically different because it depends on the path that the system is taking, and in general \\[\\begin{equation} \\oint_{\\text{path}} đW \\neq 0. \\tag{3.17} \\end{equation}\\] For instance, if we perform the expansion in one step, the work associated with it will be (using eq. (2.13)):9 \\[\\begin{equation} W^{\\text{expansion}}_{\\text{1-step}}=-P_2(\\underbrace{V_2-V_1}_{&gt;0})&lt;0, \\tag{3.18} \\end{equation}\\] and if we also perform the compression in 1-step:10 \\[\\begin{equation} W^{\\text{compression}}_{\\text{1-step}}=-P_1(\\underbrace{V_1-V_2}_{&lt;0})&gt;0. \\tag{3.19} \\end{equation}\\] With a little bit of math, it is easy to prove that the total work for the entire cycle is: \\[\\begin{equation} \\begin{aligned} W^{\\text{cycle}}_{\\text{1-step}} {} &amp; = W^{\\text{expansion}}_{\\text{1-step}}+W^{\\text{compression}}_{\\text{1-step}} \\\\ &amp; = -P_2(V_2-V_1)-P_1(V_1-V_2) \\\\ &amp; = -P_2(V_2-V_1)+P_1(V_2-V_1) \\\\ &amp; = (\\underbrace{V_2-V_1}_{&gt;0})(\\underbrace{P_1-P_2}_{&gt;0}) &gt; 0, \\end{aligned} \\tag{3.20} \\end{equation}\\] or, in other words, net work is destroyed. In practice, if we want to manually perform this cycle by pushing on the piston by hand, we will notice that it requires more energy to push down than the amount it gives back when we release it, and it moves back up. In contrast, if both the expansion and the compression happen in a slow \\(\\infty\\)-step manner, the work associated with them will be \\(W_{\\text{max}}\\) and \\(W_{\\text{min}}\\), respectively, which are calculated using eq. (2.19). The total work related with the cycle will be in this case: \\[\\begin{equation} \\begin{aligned} W^{\\text{cycle}}_{\\infty\\text{-step}} {} &amp; = W^{\\text{expansion}}_{\\text{max}}+W^{\\text{compression}}_{\\text{min}} \\\\ &amp; = -nRT \\ln \\frac{V_f}{V_i}-nRT \\ln \\frac{V_i}{V_f} \\\\ &amp; = -nRT \\underbrace{\\left( \\ln \\frac{V_f}{V_i} - \\ln \\frac{V_f}{V_i} \\right) }_{=0} = 0, \\end{aligned} \\tag{3.21} \\end{equation}\\] which means that, in this case, work is not destroyed nor created. In practice, if we were able to perform this cycle manually by pushing on the piston down by hand, we will notice that it requires the same amount of energy to push down than the amount it gives back when it moves up. This process can happen both ways without losses, and is called reversible: Definition 3.5 Reversible process: a process whose direction can be returned to its original position by inducing infinitesimal changes to some property of the system via its surroundings.11 Reversible processes are ideal processes that are hard to realize in practice since they require transformations that happen in an infinite amount of steps (infinitely slowly). recall that the internal energy is a state function, so its value depends exclusively from the conditions at the beginning and at the end. In a cycle, we’re going back to the same point, so the conditions at the beginning and at the end are equal by definition.↩︎ notice that the work for the expansion is negative, as it should be.↩︎ notice that the work for the compression is positive, as it should be.↩︎ Definition from: Sears, F.W. and Salinger, G.L. (1986), Thermodynamics, Kinetic Theory, and Statistical Thermodynamics, 3rd edition (Addison-Wesley.)↩︎ "],
["Thermochemistry.html", "4 Thermochemistry 4.1 Reaction Enthalpies 4.2 Standard Enthalpies of Formation 4.3 Hess’s Law 4.4 Calculations of Enthalpies of Reaction at \\(T \\neq 298 \\; \\text{K}\\)", " 4 Thermochemistry 4.1 Reaction Enthalpies In the previous chapter, we have discussed thermodynamical changes in energy in the absence of chemical reactions. When a chemical reaction takes place, some bonds break and/or some new one form. This process either absorbs or releases the energy contained in these bonds. For a proper thermodynamic treatment of the system, this extra energy must be included in the net balance. In this chapter, we will consider the heat associated with chemical reactions. Since most chemical reactions happen at constant atmospheric pressure (isobaric conditions) in the lab, we can use eq. (3.13) to replace the inexact differential of the heat with the exact differential of the state function called enthalpy. The advantage of this transformation is that it allows us to study the heat associated with chemical reactions at constant pressure independently of their path. If we call the molecules at the beginning of the reaction “reactants” and the molecules at the end of the reaction “products,” the heat associated with the reaction (rxn) is defined as: \\[\\begin{equation} \\Delta_{\\text{rxn}} H = H_{\\text{products}}-H_{\\text{reactants}} \\; . \\tag{4.1} \\end{equation}\\] For example, if we take a simple reaction of the form: \\[ \\mathrm{A} + \\mathrm{B} \\rightarrow \\mathrm{C} + \\mathrm{D}, \\] the heat at constant pressure is equal to the enthalpy of reaction, which is calculated as: \\[\\begin{equation} Q_P = \\Delta_{\\text{rxn}} H = \\underbrace{ \\left (H_{\\mathrm{C}}+H_{\\mathrm{D}} \\right) }_{\\text{products}} - \\underbrace{\\left( H_{\\mathrm{A}}+H_{\\mathrm{B}}\\right)}_{\\text{reactants}}. \\tag{4.2} \\end{equation}\\] Using the chemistry sign convention, Definition 1.1, reactions are classified in terms of the sign of their reaction enthalpies as follows: Definition 4.1 \\(\\;\\) \\(\\Delta_{\\text{rxn}} H &gt; 0 \\Rightarrow\\) Endothermic reaction (heat is gained by the system). \\(\\Delta_{\\text{rxn}} H &lt; 0 \\Rightarrow\\) Exothermic reaction (heat is lost by the system). If we expand the sample reaction to account for its stoichiometry: \\[ a\\mathrm{A} + b\\mathrm{B} \\rightarrow c\\mathrm{C} + d\\mathrm{D}\\; , \\] where \\(a,b,c,d\\) are the stoichiometric coefficients of species \\(\\mathrm{A,B,C,D}\\). Eq. (4.2) can be rewritten as: \\[\\begin{equation} Q_P = \\Delta_{\\text{rxn}} H = \\underbrace{\\left( cH_{\\mathrm{C}}+dH_{\\mathrm{D}} \\right) }_{\\text{products}} - \\underbrace{ \\left( aH_{\\mathrm{A}}+bH_{\\mathrm{B}} \\right)}_{\\text{reactants}}, \\tag{4.3} \\end{equation}\\] while for the most general case we can write it: \\[\\begin{equation} \\Delta_{\\text{rxn}} H = \\sum_i \\nu_i H_i, \\tag{4.4} \\end{equation}\\] where \\(\\nu_i\\) is the stoichiometric coefficient of species \\(i\\) with its own sign. The signs of the stoichiometric are defined according to eq. (4.3) as: Definition 4.2 Signs of the stoichiometric coefficients: \\(\\nu_i\\) is positive if \\(i\\) is a product. \\(\\nu_i\\) is negative if \\(i\\) is a reactant. 4.2 Standard Enthalpies of Formation In principle, we could use eq. (4.3) to calculate the reaction enthalpy associated with any reaction. However, to do so, the absolute enthalpies \\(H_i\\) of reactants and products would be required. Unfortunately, absolute enthalpies are not known—and theoretically unknowable, since this would require an absolute zero for the enthalpy scale, which does not exist.12 To prevent this problem, enthalpies relative to a deﬁned reference state must be used. This reference state is defined at the constituent elements in their standard state, and the enthalpies of 1 mol of substance in this reference state are called standard enthalpies of formation. Definition 4.3 The standard enthalpy of formation of compound \\(i\\), \\(\\Delta_{\\mathrm{f}} H_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\), is the change of enthalpy during the formation of 1 mol of \\(i\\) from its constituent elements, with all substances in their standard states. The standard pressure is defined at \\(P^{{-\\kern-6pt{\\ominus}\\kern-6pt-}} = 100 \\; \\mathrm{kPa} = 1 \\; \\mathrm{bar}\\).13 There is no standard temperature, but standard enthalpies of formation are usually reported at room temperature, \\(T = 298.15 \\; \\mathrm{K}\\). Standard states are indicated with the symbol \\({-\\kern-6pt{\\ominus}\\kern-6pt-}\\) and they are defined for elements as the form in which such element is most stable at standard pressure (for example, for hydrogen, carbon, and oxygen the standard states are \\(\\mathrm{H}_{2(g)}, \\mathrm{C}_{(s,\\text{graphite})}, \\text{and }\\mathrm{O}_{2(g)}\\), respectively).14 For example, the standard enthalpies of formation of some common compounds at \\(T = 298.15 \\; \\mathrm{K}\\) are calculated from the following reactions: \\[\\begin{equation} \\begin{aligned} \\mathrm{C}_{(s,\\text{graphite})}+\\mathrm{O}_{2(g)} \\rightarrow \\mathrm{CO}_{2(g)} \\qquad &amp; \\Delta_{\\mathrm{f}} H_{\\mathrm{CO}_{2(g)}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}= -394 \\; \\text{kJ/mol} \\\\ \\mathrm{C}_{(s,\\text{graphite})}+2 \\mathrm{H}_{2(g)} \\rightarrow \\mathrm{CH}_{4(g)} \\qquad &amp; \\Delta_{\\mathrm{f}} H_{\\mathrm{CH}_{4(g)}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}= -75 \\; \\text{kJ/mol} \\\\ \\mathrm{H}_{2(g)}+\\frac{1}{2} \\mathrm{O}_{2(g)} \\rightarrow \\mathrm{H}_2 \\mathrm{O}_{(l)} \\qquad &amp; \\Delta_{\\mathrm{f}} H_{\\mathrm{H}_2 \\mathrm{O}_{(l)}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}= -286 \\; \\text{kJ/mol} \\end{aligned} \\tag{4.5} \\end{equation}\\] A comprehensive list of standard enthalpies of formation of inorganic and organic compounds is also reported in appendix 16. 4.3 Hess’s Law The calculation of a standard reaction enthalpy can be performed using the following cycle: \\[\\begin{equation} \\begin{aligned} \\text{reactants} &amp; \\quad \\xrightarrow{\\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}} \\quad \\text{products} \\\\ \\scriptstyle{-\\Delta_{\\text{f}} H_{\\text{reactants}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}} \\quad \\bigg\\downarrow \\quad &amp; \\qquad \\qquad \\qquad \\qquad \\scriptstyle{\\bigg\\uparrow \\; \\Delta_{\\text{f}} H_{\\text{products}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}} \\\\ \\text{&quot;elements in } &amp; \\text{their standard reference state&quot;} \\end{aligned} \\tag{4.6} \\end{equation}\\] This process is summarized by the simple formula: \\[\\begin{equation} \\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}= \\Delta_{\\mathrm{f}} H_{\\text{products}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}- \\Delta_{\\mathrm{f}} H_{\\text{reactants}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}. \\tag{4.7} \\end{equation}\\] Notice how there is a negative sign in front of the enthalpy of formation of the reactants because they are normally defined for the reactions that go from the elements to the reactants and not vice-versa. To close the cycle in eq. (4.6), however, we should go from the reactants to the elements, and therefore we must invert the sign in front of the formation enthalpies of the reactants. Eq. (4.7) can be generalized using the same technique used to derive eq. (4.4), resulting in: \\[\\begin{equation} \\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}= \\sum_i \\nu_i \\Delta_{\\mathrm{f}} H_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}, \\tag{4.8} \\end{equation}\\] which is a mathematical expression of the law that is known as Hess’s Law. Hess’s law is valid at constant pressure because, at those conditions, the heat of reaction—a path function—is equal to the enthalpy of reaction—a state function. Therefore, the enthalpy of a reaction depends exclusively on the initial and final state, and it can be obtained via the pathway that passes through the elements in their standard state (the formation pathway). Exercise 4.1 Calculate the standard enthalpy of formation at 298 K for the combustion of 1 mol of methane, using the data in eq. (4.5). Solution: The reaction that is under consideration is: \\[\\begin{equation} \\mathrm{CH}_{4(g)} + 2 \\mathrm{O}_{2(g)} \\rightarrow \\mathrm{CO}_{2(g)} + 2 \\mathrm{H}_2 \\mathrm{O}_{(l)} \\qquad \\Delta_{\\mathrm{f}} H_{\\mathrm{CH}_{4(g)}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}= ? \\end{equation}\\] Using Hess’s Law, (4.8), the enthalpy of formation for methane is: \\[\\begin{equation} \\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}= \\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{CO}_{2(g)}} + 2 \\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{H}_{2}O_{(l)}} - \\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{CH}_{4(g)}} - 2 \\underbrace{\\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{O}_{2(g)}}}_{=0} \\end{equation}\\] whose values are reported in eqs. (4.5). Notice that the formation enthalpy of \\(O_{2(g)}\\) is zero, since it is an element in its standard state. The final result is: \\[\\begin{equation} \\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}= \\overbrace{-394}^{\\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{CO}_{2(g)}}} +2 \\overbrace{(-286)}^{\\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{H}_{2}O_{(l)}}} - \\overbrace{(-75)}^{\\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{CH}_{4(g)}}} = -891 \\mathrm{kJ/mol}. \\end{equation}\\] where the negative sign indicates that the reaction is exothermic (see 4.1), as we should expect. The cycle that we used to solve this exercise can be summarized with : \\[\\begin{equation} \\begin{aligned} \\mathrm{CH}_{4(g)} + &amp; 2 \\mathrm{O}_{2(g)} \\quad \\xrightarrow{\\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}} \\quad \\mathrm{CO}_{2(g)} + 2 \\mathrm{H}_2 \\mathrm{O}_{(l)} \\\\ \\scriptstyle{-\\Delta_{\\text{f}} H_{\\mathrm{CH}_{4(g)},\\mathrm{O}_{2(g)}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}} &amp; \\searrow \\qquad \\qquad \\qquad \\qquad \\qquad \\nearrow \\; \\scriptstyle{\\Delta_{\\text{f}} H_{\\text{CO}_{2(g)},\\mathrm{H}_{2(g)}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}}\\\\ &amp; \\qquad \\mathrm{H}_{2(g)}, \\mathrm{C}_{(s,\\text{graphite})}, \\mathrm{O}_{2(g)} \\end{aligned} \\end{equation}\\] Notice that at standard pressure and \\(T = 298 \\; \\mathrm{K}\\) water is in liquid form. However, when we burn methane, the heat associated with the exothermic reaction immediately vaporize the water. Substances in different states of matter have different formation enthalpies, and \\(\\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{H}_{2}O_{(l)}} = -242 \\ \\mathrm{kJ/mol}\\). The difference between the formation enthalpies of the same substance in different states represents the latent heat that separates them. For example, for water: \\[\\begin{equation} \\begin{aligned} \\Delta_{\\text{vap}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{H}_2O} &amp; = \\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{H}_{2}O_{(g)}} - \\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{H}_{2}O_{(l)}} \\\\ &amp; = (-242) - (-286) = + 44 \\; \\text{kJ/mol} \\end{aligned} \\end{equation}\\] which is the latent heat of vaporization for water, \\(\\Delta_{\\text{vap}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{H}_2O}\\). The latent heat is positive to indicate that the system absorbs energy in going from the liquid to the gaseous state (and it will release energy when going the opposite direction from gas to liquid). 4.4 Calculations of Enthalpies of Reaction at \\(T \\neq 298 \\; \\text{K}\\) Standard enthalpies of formation are usually reported at room temperature (\\(T\\) = 298 K), but enthalpies of formation at any temperature \\(T&#39;\\) can be calculated from the values at 298 K using eqs. (2.4) and (3.13): \\[\\begin{equation} \\begin{aligned} dH = C_P dT \\rightarrow &amp; \\int_{H_{T=298}^{-\\kern-6pt{\\ominus}\\kern-6pt-}}^{H_{T&#39;}} dH = \\int_{T=298}^{T&#39;} C_P dT \\\\ &amp; H_{T&#39;}^{-\\kern-6pt{\\ominus}\\kern-6pt-}- H_{T=298}^{-\\kern-6pt{\\ominus}\\kern-6pt-}= \\int_{T=298}^{T&#39;} C_P dT \\\\ &amp; H_{T&#39;}^{-\\kern-6pt{\\ominus}\\kern-6pt-}= H_{T=298}^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ \\int_{T=298}^{T&#39;} C_P dT, \\end{aligned} \\tag{4.9} \\end{equation}\\] which, in conjunction with Hess’s Law (eq. (4.8)), results in: \\[\\begin{equation} \\Delta_{\\text{rxn}} H_{T&#39;}^{-\\kern-6pt{\\ominus}\\kern-6pt-}= \\Delta_{\\text{rxn}} H_{T=298}^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ \\int_{T=298}^{T&#39;} \\Delta C_P dT, \\tag{4.10} \\end{equation}\\] with \\(\\Delta C_P = \\sum_i \\nu_i C_{P,i}\\). Exercise 4.2 Calculate \\(\\Delta_{\\text{rxn}}H\\) of the following reaction at 398 K, knowing that \\(\\Delta_{\\text{rxn}}H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) at 298 K is -283.0 kJ/mol, and the following \\(C_P\\) values: \\(\\mathrm{CO}_{(g)}\\) = 29 J/(mol K), \\(\\mathrm{O}_{2(g)}\\) = 30 J/(mol K), \\(\\mathrm{CO}_{2(g)}\\) = 38 J/(mol K): \\[ \\mathrm{CO}_{(g)}+\\frac{1}{2}\\mathrm{O}_{2(g)} \\rightarrow \\mathrm{CO}_{2(g)}, \\] Solution: Using eq. (4.10) we obtain: \\[ \\Delta_{\\text{rxn}} H^{398} = \\overbrace{-283.0}^{\\Delta_{\\text{rxn}}H^{-\\kern-6pt{\\ominus}\\kern-6pt-}} + \\int_{298}^{398} ( \\overbrace{38}^{C_P^{\\mathrm{CO}_2}} -\\overbrace{29}^{C_P^{\\mathrm{CO}}} -\\frac{1}{2}\\overbrace{30}^{C_P^{\\mathrm{O}_2}} ) \\times 10^{3} dT, \\] which, assuming that the heat capacities does not depend on the temperature, becomes: \\[\\begin{equation} \\begin{aligned} \\Delta_{\\text{rxn}} H^{398} &amp;= -283.0 + \\left(38-29-\\frac{1}{2}30 \\right) \\times 10^{-3} (398-298) \\\\ &amp;= -283.6 \\; \\text{kJ/mol}. \\end{aligned} \\end{equation}\\] As we notice from this result, a difference in temperature of 100 K translates into a change in \\(\\Delta_{\\text{rxn}}H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) of this reaction of only 0.6 kJ/mol. This is a trend that is often observed, and values of \\(\\Delta_{\\text{rxn}}H\\) are very weakly dependent on changes in temperature for most chemical reactions. This numerical result can also be compared with the amount that is experimentally measured for \\(\\Delta_{\\text{rxn}}H^{398}\\) of this reaction, which is –283.67 kJ/mol. This comparison strongly supports the assumption that we used to solve the integral in eq. (4.10), confirming that the heat capacities are mostly independent of temperature. An example of a known absolute zero for a scale is the zero of the temperature scale, a temperature that can be approached only as a limit from above. No such thing exists for the enthalpy.↩︎ prior to 1982 the value of \\(P^{{-\\kern-6pt{\\ominus}\\kern-6pt-}} = 1.0 \\mathrm{ atm}\\) was used. The two values of \\(P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) are within 1% of each other, since 1 atm = 101.325 kPa.↩︎ There are some exception, such as phosphorus, for which the most stable form at 1 bar is black phosphorus, but white phosphorus is chosen as the standard reference state for zero enthalpy of formation. For the purposes of this course, however, we can safely ignore them.↩︎ "],
["ThermodynamicCycles.html", "5 Thermodynamic Cycles 5.1 Carnot Cycle 5.2 Energy, Heat, and Work in the Carnot Cycle 5.3 Efficiency of a Carnot Cycle", " 5 Thermodynamic Cycles The first law of thermodynamics places no restrictions on the conversion of energy from one form to another. For example, let’s consider once again the Joule experiment (Figure 3.1). If we design a cycle that goes from the gas on the left chamber only to the gas equilibrated in both chambers and backward, as in Figure 5.1, there are no restrictions imposed on this hypothetical cycle by the first law. Figure 5.1: Closing the Cycle in The Joule Expansion Experiment. As we saw in section 3.1.1, states 1 and 2 have exactly the same energy at constant temperature. Restricting the analysis to the information contained in the first law, the ideal gas could hypothetically go from state 1 (all gas in the left chamber) to state 2 (gas in both chambers), as well as spontaneously close the cycle back from state 2 to state 1, without external intervention. While the transformation from 1 \\(\\rightarrow\\) 2 is intuitively spontaneous (it’s the same transformation that we considered in section 3.1.1), the backward transformation from 2 \\(\\rightarrow\\) 1 is clearly not as intuitive. In this case, the gas should spontaneously compress back to the left side, leaving a vacuum on the right chambers, without interventions from the outside. This transformation is clearly never observed. A gas just does not spontaneously concentrate on one side of a room, leaving a vacuum on the other side. In fact, when we need to create a vacuum, a lot of energy must be spent. Suppose we use exclusively information contained in the first law. In this case, there is nothing that might suggest a system’s preference to perform the transformation 1 \\(\\rightarrow\\) 2, while restricting the 2 \\(\\rightarrow\\) 1 from happening spontaneously. Both states have the same energy, and \\[\\begin{equation} \\oint dU=0, \\tag{5.1} \\end{equation}\\] James Joule himself was indeed convinced that this must be the case and that we don’t observe the backward transformation in practice only because we cannot build ideal machines.15 Another scientist of that era was not convinced. William Thomson, the 1st Baron Kelvin (1824–1907), was unsure about this idea, and invested substantial resources to try to prove Joule’s wrong.16 A few years later, the controversy between Joule and Kelvin was redeemed in favor of the latter, thanks to the experiments of French military engineer Nicolas Léonard Sadi Carnot (1796–1832). The work of Carnot began in France several years before Joule and Kelvin’s time.17 At that time, the importance of steam engines was growing for industrial applications, but a theoretical perspective was lacking. Carnot was convinced that a scientific understanding of heat engines was necessary to improve their efficiency. 5.1 Carnot Cycle The main contribution of Carnot to thermodynamics is his abstraction of the steam engine’s essential features into a more general and idealized heat engine. The definition of Carnot’s idealized cycle is as follows: Definition 5.1 A Carnot cycle is an idealized process composed of two isothermal and two adiabatic transformations. Each transformation is either an expansion or a compression of an ideal gas. All transformations are assumed to be reversible, and no energy is lost to mechanical friction. A Carnot cycle connects two “heat reservoirs” at temperatures \\(T_h\\) (hot) and \\(T_l\\) (low), respectively. The reservoirs have a large thermal capacity so that their temperatures are unaffected by the cycle. The system is composed exclusively by the ideal gas, which is the only substance that changes temperature throughout the cycle. If we report the four transformations of a Carnot cycle on a \\(PV\\) diagram, we obtain the following plot: Figure 5.2: PV-Diagram of a Carnot Cycle. 5.1.1 Stage 1: isothermal expansion \\(A \\rightarrow B\\) Starting the analysis of the cycle from point \\(A\\) in Figure 5.2,18 the first transformation we encounter is an isothermal expansion at \\(T_h\\). Since the transformation is isothermal: \\[\\begin{equation} \\Delta U_1 = \\overbrace{W_1}^{&lt;0} + \\overbrace{Q_1}^{&gt;0} = 0 \\Rightarrow Q_1 = -W_1, \\tag{5.2} \\end{equation}\\] and heat and work can be calculated for this stage using eq. (2.19): \\[\\begin{equation} \\begin{aligned} Q_1 &amp; = \\left| Q_h \\right| = nRT_h \\overbrace{\\ln \\frac{V_B}{V_A}}^{&gt;0 \\text{ since } V_B&gt;V_A} &gt; 0, \\\\ W_1 &amp; = -Q_1 = - nRT_h \\ln \\frac{V_B}{V_A} &lt; 0, \\end{aligned} \\tag{5.3} \\end{equation}\\] where we denoted \\(\\left| Q_h \\right|\\) the absolute value of the heat that gets into the system from the hot reservoir. 5.1.2 Stage 2: adiabatic expansion \\(B \\rightarrow C\\) The second transformation is an adiabatic expansion between \\(T_h\\) and \\(T_l\\). Since we are at adiabatic conditions: \\[\\begin{equation} Q_2 = 0 \\Rightarrow \\Delta U_2 = W_2, \\tag{5.4} \\end{equation}\\] and the negative energy (expansion work) can be calculated using: \\[\\begin{equation} \\Delta U_2 = W_2 = n \\underbrace{\\int_{T_h}^{T_l} C_V dT}_{&lt;0 \\text{ since } T_\\mathrm{l}&lt;T_\\mathrm{h}} &lt; 0. \\tag{5.5} \\end{equation}\\] 5.1.3 Stage 3: isothermal compression \\(C \\rightarrow D\\) The third transformation is an isothermal compression at \\(T_l\\). The formulas are the same as those used for stage 1, but they will results in heat and work with reversed signs (since this is a compression): \\[\\begin{equation} \\Delta U_3 = \\overbrace{W_3}^{&gt;0} + \\overbrace{Q_3}^{&lt;0} = 0 \\Rightarrow Q_3 = -W_3, \\tag{5.6} \\end{equation}\\] and: \\[\\begin{equation} \\begin{aligned} Q_3 &amp; = \\left| Q_l \\right| = nRT_l \\overbrace{\\ln \\frac{V_D}{V_C}}^{&lt;0 \\text{ since } V_D&lt;V_C} &lt; 0 , \\\\ W_3 &amp; = -Q_3 = - nRT_l \\ln \\frac{V_D}{V_C} &gt; 0, \\end{aligned} \\tag{5.7} \\end{equation}\\] where \\(\\left| Q_l \\right|\\) is the absolute value of the heat that gets out of the system to the cold reservoir (\\(\\left| Q_l \\right|\\) being the heat entering the system). 5.1.4 Stage 4: adiabatic compression \\(D \\rightarrow A\\) The fourth and final transformation is an adiabatic comprssion that restores the system to point \\(A\\), bringing it from \\(T_l\\) to \\(T_h\\). Similarly to stage 3: \\[\\begin{equation} Q_4 = 0 \\Rightarrow \\Delta U_4 = W_4, \\tag{5.8} \\end{equation}\\] Since we are at adiabatic conditions. The energy associated with this process is now positive (compression work), and can be calculated using: \\[\\begin{equation} \\Delta U_4 = W_4 = n \\underbrace{\\int_{T_l}^{T_h} C_V dT}_{&gt;0 \\text{ since } T_\\mathrm{h}&gt;T_\\mathrm{l}} &gt; 0. \\tag{5.9} \\end{equation}\\] Notice how \\(\\Delta U_4 = - \\Delta U_2\\) because \\(\\int_x^y=-\\int_y^x\\). 5.2 Energy, Heat, and Work in the Carnot Cycle Summarizing the results of the previous sections, the total amount of energy for a Carnot cycle is: \\[\\begin{equation} \\begin{aligned} \\Delta U_{\\text{TOT}} &amp; = \\Delta U_1+\\Delta U_2+\\Delta U_3+\\Delta U_4 \\\\ &amp; = 0 + n \\int_{T_h}^{T_l} C_V dT + 0 + n \\int_{T_l}^{T_h} C_V dT \\\\ &amp; = n \\int_{T_h}^{T_l} C_V dT - n \\int_{T_h}^{T_l} C_V dT = 0 \\\\ \\end{aligned} \\tag{5.10} \\end{equation}\\] which is obviously zero, since \\(\\oint dU=0\\). The amounts of work and heat, however, are not zero, since \\(Q\\) and \\(W\\) are path functions. Therefore: \\[\\begin{equation} \\begin{aligned} W_{\\text{TOT}} &amp; = W_1+W_2+W_3+W_4 \\\\ &amp; = - nRT_h \\ln \\frac{V_B}{V_A} + n \\int_{T_h}^{T_l} C_V dT - nRT_l \\ln \\frac{V_D}{V_C} + n \\int_{T_l}^{T_h} C_V dT \\\\ &amp; = - nRT_h \\ln \\frac{V_B}{V_A} - nRT_l \\ln \\frac{V_D}{V_C}, \\\\ \\end{aligned} \\tag{5.11} \\end{equation}\\] which, considering that \\(V_C/V_D=V_B/V_A\\), reduces to: \\[\\begin{equation} W_{\\text{TOT}} = - nR \\left( T_h-T_l \\right) \\ln \\frac{V_B}{V_A} &lt; 0, \\tag{5.12} \\end{equation}\\] which is negative, because \\(T_h&gt;T_l\\) and \\(V_B&gt;V_A\\). Negative work means that the work is done by the system. In other words, the system is performing \\(PV\\)-work by transferring heat from a hot reservoir to a cold one via a Carnot cycle. On the other hand, for the heat: \\[\\begin{equation} \\begin{aligned} Q_{\\text{TOT}} &amp; = Q_1+Q_2+Q_3+Q_4 \\\\ &amp; = Q_h + 0 + Q_l + 0 \\\\ &amp; = nRT_h \\ln \\frac{V_B}{V_A} + nRT_l \\ln \\frac{V_D}{V_C} \\\\ &amp; = nR \\left( T_h-T_l \\right) \\ln \\frac{V_B}{V_A} = -W_{\\text{TOT}}, \\end{aligned} \\tag{5.13} \\end{equation}\\] which, simplifies to: \\[\\begin{equation} W_{\\text{TOT}}=-(Q_1+Q_3), \\tag{5.14} \\end{equation}\\] and, replacing \\(Q_1\\) and \\(Q_3\\) with the absolute values of the heats drawn from the hot and cold reservoirs, \\(\\left| Q_h \\right|\\), and \\(\\left| Q_l \\right|\\) respectively: \\[\\begin{equation} \\left| W_{\\text{TOT}} \\right| = \\left| Q_h \\right| - \\left| Q_l \\right|, \\tag{5.15} \\end{equation}\\] or, in other words, more heat is extracted from the hot reservoir than it is put into the cold one. The difference between the absolute value of these amounts of heat gives the total work of the cycle. This process is depicted in Figure 5.3. Figure 5.3: Carnot Cycle Diagram. Exercise 5.1 Up to this point, we have discussed Carnot cycles working in the hot \\(\\rightarrow\\) cold direction (\\(A\\) \\(\\rightarrow\\) \\(B\\) \\(\\rightarrow\\) \\(C\\) \\(\\rightarrow\\) \\(D\\) \\(\\rightarrow\\) \\(A\\)), since this is the primary mode of operation of heat engines that produce work. However, a heat engine could also—in principle—work in the reversed cold \\(rightarrow\\) hot direction (\\(A\\) \\(\\rightarrow\\) \\(D\\) \\(\\rightarrow\\) \\(C\\) \\(\\rightarrow\\) \\(B\\) \\(\\rightarrow\\) \\(A\\)). Write the equations for heat, work, and energy of each stage of a Carnot cycle going the opposite direction than the one discussed in sections 5.1 and 5.2. Solution: When the heat engine works in reverse order, the formulas remain the same, but all the signs in front of \\(Q\\), \\(W\\), and \\(U\\) will be reversed. In this case, the total work would get into the systems, and heat would be transferred from the cold reservoir to the hot one. Figure 5.3 would be modified as: This reversed mode of operation is the basic principle behind refrigerators and air conditioning. 5.3 Efficiency of a Carnot Cycle The efficiency (\\(\\varepsilon\\)) of a cycle is defined as the ratio between the absolute value of the work extracted from the cycle (\\(\\left| W_{\\text{TOT}} \\right|\\)) and the heat that gets into the system (\\(\\left| Q_h \\right|\\)): \\[\\begin{equation} \\varepsilon = \\frac{\\left| W_{\\text{TOT}} \\right|}{\\left| Q_h \\right|} =\\frac{-W_{\\text{TOT}}}{Q_1} \\tag{5.16} \\end{equation}\\] where the minus sign in front of the work is necessary because the efficiency is defined as a positive number. Replacing eq. (5.14) into (5.16), we obtain: \\[\\begin{equation} \\varepsilon = \\frac{Q_3+Q_1}{Q_1} = 1+\\frac{Q_3}{Q_1}. \\tag{5.17} \\end{equation}\\] If we go back to eq. (5.16) and we replace eq. (5.12) for \\(W_{\\mathrm{TOT}}\\) and eq. (5.3) for \\(Q_1\\), we obtain: \\[\\begin{equation} \\varepsilon = \\frac{nR \\left( T_h - T_l \\right) \\ln V_B/V_A}{nRT_h \\ln V_B/V_A} = \\frac{T_h-T_l}{T_h}=1-\\frac{T_l}{T_h }&lt;1, \\tag{5.18} \\end{equation}\\] which proves that the efficiency of a Carnot cycle is strictly smaller than 1.19 In other words, no cycle can convert 100% of the heat into work it extracts from a hot reservoir. This finding had remarkable consequences on the entire thermodynamics field and set the foundation for the introduction of entropy. We will use eqs. (5.16) and (5.18) for this purpose in the next chapter, but we conclude the discussion on Carnot cycles by returning back to Lord Kelvin. In 1851 he used this finding to state his statement “It is impossible for a self-acting machine, unaided by any external agency, to convey heat from one body to another at a higher temperature. It is impossible, by means of inanimate material agency, to derive mechanical effect from any portion of matter by cooling it below the temperature of the coldest of the surrounding objects.”20 This statement conclusively disproved Joule’s original theories and demonstrated that there is some fundamental principle to govern the flow of heat beyond the first law of thermodynamics. Either because we don’t really have ideal gases, or because we are unable to construct mechanical devices without loss, or in general because of other experimental factors↩︎ Interestingly enough, both Joule and Lord Kelvin are now recognized as key figures in the development of thermodynamics and science in general. So much so, that the energy unit and the temperature unit in the SI system are named after them.↩︎ Carnot’s lone book, the Réflexions sur la Puissance Motrice du Feu (“Reflections on the Motive Power of Fire”) was published in France in 1824, the same year Kelvin was born and just 6 years after Joule’s birth.↩︎ The stages of a Carnot depicted at the beginning of each of this section and the following three ones are genetaken from Wikipedia, and have been generated and distributed by Author BlyumJ under CC-BY-SA license.↩︎ Eq. (5.18) can be equal to 1 only if \\(T_l=0 \\; \\text{K}\\) or \\(T_h=\\infty\\), two conditions that are both equally impossible.↩︎ Thomson W. Transactions of the Royal Society of Edinburgh. 1851 XX 261–268, 289–298..↩︎ "],
["SecondLaw.html", "6 Second Law of Thermodynamics 6.1 Entropy 6.2 Irreversible Cycles 6.3 The Second Law of Thermodynamics", " 6 Second Law of Thermodynamics In the previous chapter, we have discussed heat engines as a means of understanding how some processes are spontaneous while others are not. Carnot’s findings did not just simply inspire Lord Kelvin on this subject, but they also motivated Rudolf Clausius (1822–1888) to introduce the concept of entropy. 6.1 Entropy Let’s return to the definition of efficiency of a Carnot cycle and bring together eqs. (5.17) and (5.18): \\[\\begin{equation} \\varepsilon = 1+\\frac{Q_3}{Q_1} = 1-\\frac{T_l}{T_h}. \\tag{6.1} \\end{equation}\\] Simplifying this equality, we obtain: \\[\\begin{equation} \\frac{Q_3}{T_l} = -\\frac{Q_1}{T_h}, \\tag{6.2} \\end{equation}\\] or alternatively: \\[\\begin{equation} \\frac{Q_3}{T_l} + \\frac{Q_1}{T_h} = 0. \\tag{6.3} \\end{equation}\\] The left hand side of eq. (6.3) contains the sum of two quantities around the Carnot cycle, each calculated as \\(\\frac{Q_{\\mathrm{REV}}}{T}\\), with \\(Q_{\\mathrm{REV}}\\) being the heat exchanged at reversible conditions (recall that according to Definition 5.1 each transformation in a Carnot cycle is reversible). Eq. (6.2) can be generalized to a sequence of connected Carnot cycles joining more than two isotherms by taking the summation across different temperatures: \\[\\begin{equation} \\sum_i \\frac{Q_{\\mathrm{REV}}}{T_i} = 0, \\tag{6.4} \\end{equation}\\] where the summation happens across a sequence of Carnot cycles that connects different temperatures. Eqs. (6.3) and (6.4) show that for a Carnot cycle—or a series of connected Carnot cycles—there exists a conserved quantity obtained by dividing the heat associated with each reversible stage and the temperature at which such heat is exchanged. If a quantity is conserved around a cycle, it must be independent on the path, and therefore it is a state function. Looking at similar equations, Clausius introduced in 1865 a new state function in thermodynamics, which he decided to call entropy and indicate with the letter \\(S\\): Definition 6.1 Entropy: \\[\\begin{equation} S = \\frac{Q_{\\mathrm{REV}}}{T}. \\end{equation}\\] We can use the new state function to generalize eq. (6.4) to any reversible cycle in a \\(PV\\)-diagram by using the rules of calculus. First, we will slice \\(S\\) into an infinitesimal quantity: \\[\\begin{equation} dS = \\frac{đQ_{\\mathrm{REV}}}{T}, \\tag{6.5} \\end{equation}\\] then we can extend the summation across temperatures of eq. (6.4) to a sum over infinitesimal quantities—that is the integral—around the cycle: \\[\\begin{equation} \\oint dS = \\oint \\frac{đQ_{\\mathrm{REV}}}{T} = 0. \\tag{6.6} \\end{equation}\\] 6.2 Irreversible Cycles Up to this point, we have discussed reversible cycles only. Notice that the heat that enters the definition of entropy (Definition 6.1 is the heat exchanged at reversible conditions since it is only at those conditions that the right-hand side of eq. (6.5) becomes a state function. What happens when we face an irreversible cycle? The efficiency of a Carnot cycle in eq. (5.18) is the maximum efficiency that an idealized thermodynamic cycle can reach. As such, any irreversible cycle will incontrovertibly have an efficiency smaller than the maximum efficiency of the idealized Carnot cycle. Therefore, eq. (6.1) for an irreversible cycle will not hold anymore and must be rewritten as: \\[\\begin{equation} \\overbrace{1+\\frac{Q_3}{Q_1}}^{\\varepsilon_{\\mathrm{IRR}}} &lt; \\overbrace{1-\\frac{T_l}{T_h}}^{\\varepsilon_{\\mathrm{REV}}}, \\tag{6.7} \\end{equation}\\] and, following the same procedure used in section 6.1, we can rewrite eq. (6.7) as: \\[\\begin{equation} \\frac{Q^{\\text{IRR}}_3}{Q^{\\text{IRR}}_1} &lt; - \\frac{T_l}{T_h} \\longrightarrow \\frac{Q^{\\text{IRR}}_3}{T_l} + \\frac{Q^{\\text{IRR}}_1}{T_h} &lt; 0 \\longrightarrow \\sum_i \\frac{Q_{\\text{IRR}}}{T_i} &lt; 0, \\tag{6.8} \\end{equation}\\] which can be generalized using calculus to: \\[\\begin{equation} \\oint \\frac{đQ_{\\mathrm{IRR}}}{T} &lt; 0. \\tag{6.9} \\end{equation}\\] Putting eqs. (6.6) and (6.9) together, we obtain: \\[\\begin{equation} \\oint \\frac{đQ}{T} \\leq 0, \\tag{6.10} \\end{equation}\\] where the equal sign holds for reversible transformations exclusively, while the inequality sign holds for irreversible ones. Eq. (6.10) is known as Clausius inequality. 6.3 The Second Law of Thermodynamics Now we can consider an isolated system undergoing a cycle composed of an irreversible forward transformation (1 \\(\\rightarrow\\) 2) and a reversible backward transformation (2 \\(\\rightarrow\\) 1), as in Figure 6.1. Figure 6.1: Spontaneous and Non-Spontaneous Transformations in a Cycle. This cycle is similar to the cycle depicted in Figure 5.1 for the Joule’s expansion experiment. In this case, we have an intuitive understanding of the spontaneity of the irreversible expansion process, while the non-spontaneity of the backward compression. Since the cycle has at least one irreversible step, it is overall irreversible, and we can calculate: \\[\\begin{equation} \\oint \\frac{đQ_{\\mathrm{IRR}}}{T} = \\int_1^2 \\frac{đQ_{\\mathrm{IRR}}}{T} + \\int_2^1 \\frac{đQ_{\\mathrm{REV}}}{T}. \\tag{6.11} \\end{equation}\\] We can then use Clausius inequality (eq. (6.10)) to write: \\[\\begin{equation} \\begin{aligned} \\int_1^2 \\frac{đQ_{\\mathrm{IRR}}}{T} + \\int_2^1 \\frac{đQ_{\\mathrm{REV}}}{T} &lt; 0, \\end{aligned} \\tag{6.12} \\end{equation}\\] which can be rearranged as: \\[\\begin{equation} \\underbrace{\\int_1^2 \\frac{đQ_{\\mathrm{REV}}}{T}}_{\\int_1^2 dS = \\Delta S} &gt; \\underbrace{\\int_1^2 \\frac{đQ_{\\mathrm{IRR}}}{T}}_{=0}, \\tag{6.13} \\end{equation}\\] where we have used the fact that, for an isolated system (the universe), \\(đQ_{\\mathrm{IRR}}=0\\). Eq. (6.13) can be rewritten as: \\[\\begin{equation} \\Delta S &gt; 0, \\tag{6.14} \\end{equation}\\] which proves that for any irreversible process in an isolated system, the entropy is increasing. Using eq. (6.14) and considering that the only system that is truly isolated is the universe, we can write a concise statement for a new fundamental law of thermodynamics: Definition 6.2 Second Law of Thermodynamics: for any spontaneous process, the entropy of the universe is increasing. "],
["thirdlaw.html", "7 Calculation of Entropy and the Third Law of Thermodynamics 7.1 Calculation of \\(\\Delta S^{\\mathrm{sys}}\\) 7.2 Calculation of \\(\\Delta S^{\\mathrm{surr}}\\) 7.3 Clausius Theorem 7.4 The Third Law of Thermodynamics", " 7 Calculation of Entropy and the Third Law of Thermodynamics The Second Law can be used to infer the spontaneity of a process, as long as the entropy of the universe is considered. To do so, we need to remind ourselves that the universe can be divided into a system and its surroundings (environment). When we calculate the entropy of the universe as an indicator of the spontaneity of a process, we need to always consider changes in entropy in both the system (sys) and its surroundings (surr): \\[\\begin{equation} \\Delta S^{\\mathrm{universe}} = \\Delta S^{\\mathrm{sys}} + \\Delta S^{\\mathrm{surr}}, \\tag{7.1} \\end{equation}\\] or, in differential form: \\[\\begin{equation} d S^{\\mathrm{universe}} = d S^{\\mathrm{sys}} + d S^{\\mathrm{surr}}, \\tag{7.2} \\end{equation}\\] 7.1 Calculation of \\(\\Delta S^{\\mathrm{sys}}\\) In general \\(\\Delta S^{\\mathrm{sys}}\\) can be calculated using either its Definition 6.1, or its differential formula, eq. (6.5). In practice, it is always convenient to keep in mind that entropy is a state function, and as such it does not depend on the path. For this reason, we can break every transformation into elementary steps, and calculate the entropy on any path that goes from the initial state to the final state, such as, for example: \\[\\begin{equation} \\begin{aligned} P_i, T_i &amp; \\quad \\xrightarrow{ \\Delta_{\\text{TOT}} S_{\\text{sys}} } \\quad P_f, T_f \\\\ \\scriptstyle{\\Delta_1 S^{\\text{sys}}} &amp; \\searrow \\qquad \\qquad \\nearrow \\; \\scriptstyle{\\Delta_2 S^{\\text{sys}}} \\\\ &amp; \\qquad P_i, T_f \\\\ \\\\ \\Delta_{\\text{TOT}} S^{\\text{sys}} &amp; = \\Delta_1 S^{\\text{sys}} + \\Delta_2 S^{\\text{sys}}, \\end{aligned} \\tag{7.3} \\end{equation}\\] with \\(\\Delta_1 S^{\\text{sys}}\\) calculated at constant \\(P\\), and \\(\\Delta_2 S^{\\text{sys}}\\) at constant \\(T\\). The most important elementary steps from which we can calculate the entropy resemble the prototypical processes for which we calculated the energy in section 3.1. 7.1.1 Entropy in isothermal processes For an ideal gas at constant temperature \\(\\Delta U =0\\), and \\(Q_{\\mathrm{REV}} = -W_{\\mathrm{REV}}\\). Using the formula for \\(W_{\\mathrm{REV}}\\) in either eq. (??) or eq. (??), we obtain: \\[\\begin{equation} \\Delta S^{\\mathrm{sys}} = \\int_i^f \\frac{đQ_{\\mathrm{REV}}}{T} = \\frac{-W_{\\mathrm{REV}}}{T} = \\frac{nRT \\ln \\frac{V_f}{V_i}}{T} = nR \\ln \\frac{V_f}{V_i}, \\tag{7.4} \\end{equation}\\] or, similarly: \\[\\begin{equation} \\Delta S^{\\mathrm{sys}} = nR \\ln \\frac{P_i}{P_f}. \\tag{7.5} \\end{equation}\\] A phase change is a particular case of an isothermal process that does not follow the formulas introduced above since an ideal gas never liquefies. The entropy associated with a phase change at constant pressure can be calculated from its definition, remembering that \\(Q_{\\mathrm{rev}}= \\Delta H\\). For example for vaporizations: \\[\\begin{equation} \\Delta_{\\mathrm{vap}} S = \\frac{\\Delta_{\\mathrm{vap}}H}{T_B}, \\tag{7.6} \\end{equation}\\] with \\(\\Delta_{\\mathrm{vap}}H\\) being the enthalpy of vaporization of a substance, and \\(T_B\\) its boiling temperature. It is experimentally observed that the entropies of vaporization of many liquids have almost the same value of: \\[\\begin{equation} \\Delta_{\\mathrm{vap}} S \\approx 10.5 R, \\tag{7.7} \\end{equation}\\] which corresponds in SI to the range of about 85–88 J/(mol K). This simple rule is named Trouton’s rule, after the French scientist that discovered it, Frederick Thomas Trouton (1863-1922). Exercise 7.1 Calculate the standard entropy of vaporization of water knowing \\(\\Delta_{\\mathrm{vap}} H_{\\mathrm{H}_2\\mathrm{O}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}= 44 \\ \\text{kJ/mol}\\), as calculated in Exercise 4.1. Solution: Using eq. (7.7)—and knowing that at standard conditions of \\(P^{-\\kern-6pt{\\ominus}\\kern-6pt-}= 1 \\ \\text{bar}\\) the boiling temperature of water is 373 K—we calculate: \\[\\begin{equation} \\Delta_{\\mathrm{vap}} S_{\\mathrm{H}_2\\mathrm{O}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}= \\frac{44 \\times 10^3 \\text{J/mol}}{373 \\ \\text{K}} = 118 \\ \\text{J/(mol K)}. \\tag{7.8} \\end{equation}\\] The entropy of vaporization of water is far from Trouton’s rule range of 85–88 J/(mol K) because of the hydrogen bond interactions between its molecules. Other similar exceptions are ethanol, formic acid, and hydrogen fluoride. 7.1.2 Entropy in adiabatic processes Since adiabatic processes happen without the exchange of heat, \\(đQ=0\\), it would be tempting to think that \\(\\Delta S^{\\mathrm{sys}} = 0\\) for every one of them. A transformation at constant entropy (isentropic) is always, in fact, a reversible adiabatic process. However, the opposite case is not always true, and an irreversible adiabatic transformation is usually associated with a change in entropy. To explain this fact, we need to recall that the definition of entropy includes the heat exchanged at reversible conditions only. Therefore, for irreversible adiabatic processes \\(\\Delta S^{\\mathrm{sys}} \\neq 0\\). The calculation of the entropy change for an irreversible adiabatic transformation requires a substantial effort, and we will not cover it at this stage. The situation for adiabatic processes can be summarized as follows: \\[\\begin{equation} \\begin{aligned} \\text{reversible:} \\qquad &amp; \\frac{đQ_{\\mathrm{REV}}}{T} = 0 \\longrightarrow \\Delta S^{\\mathrm{sys}} = 0 \\quad \\text{(isentropic),}\\\\ \\text{irreversible:} \\qquad &amp; \\frac{đQ_{\\mathrm{IRR}}}{T} = 0 \\longrightarrow \\Delta S^{\\mathrm{sys}} \\neq 0. \\\\ \\end{aligned} \\tag{7.9} \\end{equation}\\] 7.1.3 Entropy in isochoric processes We can calculate the heat exchanged in a process that happens at constant volume, \\(Q_V\\), using eq. (2.2). Since the heat exchanged at those conditions equals the energy (eq. (3.7)), and the energy is a state function, we can use \\(Q_V\\) regardless of the path (reversible or irreversible). The entropy associated with the process will then be: \\[\\begin{equation} \\Delta S^{\\mathrm{sys}} = \\int_i^f \\frac{đQ_{\\mathrm{REV}}}{T} = \\int_i^f nC_V \\frac{dT}{T}, \\tag{7.10} \\end{equation}\\] which, assuming \\(C_V\\) independent of temperature and solving the integral on the right-hand side, becomes: \\[\\begin{equation} \\Delta S^{\\mathrm{sys}} \\approx n C_V \\ln \\frac{T_f}{T_i}. \\tag{7.11} \\end{equation}\\] 7.1.4 Entropy in isobaric processes Similarly to the constant volume case, we can calculate the heat exchanged in a process that happens at constant pressure, \\(Q_P\\), using eq. (2.4). Again, similarly to the previous case, \\(Q_P\\) equals a state function (the enthalpy), and we can use it regardless of the path to calculate the entropy as: \\[\\begin{equation} \\Delta S^{\\mathrm{sys}} = \\int_i^f \\frac{đQ_{\\mathrm{REV}}}{T} = \\int_i^f nC_P \\frac{dT}{T}, \\tag{7.12} \\end{equation}\\] which, assuming \\(C_P\\) independent of temperature and solving the integral on the right-hand side, becomes: \\[\\begin{equation} \\Delta S^{\\mathrm{sys}} \\approx n C_P \\ln \\frac{T_f}{T_i}. \\tag{7.13} \\end{equation}\\] 7.2 Calculation of \\(\\Delta S^{\\mathrm{surr}}\\) While the entropy of the system can be broken down into simple cases and calculated using the formulas introduced above, the entropy of the surroundings does not require such a complicated treatment, and it can always be calculated as: \\[\\begin{equation} \\Delta S^{\\mathrm{surr}} = \\frac{Q_{\\text{surr}}}{T_{\\text{surr}}}=\\frac{-Q_{\\text{sys}}}{T_{\\text{surr}}}, \\tag{7.14} \\end{equation}\\] or, in differential form: \\[\\begin{equation} d S^{\\mathrm{surr}} = \\frac{đQ_{\\text{surr}}}{T_{\\text{surr}}}=\\frac{-đQ_{\\text{sys}}}{T_{\\text{surr}}}, \\tag{7.15} \\end{equation}\\] where the substitution \\(Q_{\\text{surr}}=-Q_{\\text{sys}}\\) can be performed regardless of whether the transformation is reversible or not. In other words, the surroundings always absorb heat reversibly. To justify this statement, we need to restrict the analysis of the interaction between the system and the surroundings to just the vicinity of the system itself. Outside of a generally restricted region, the rest of the universe is so vast that it remains untouched by anything happening inside the system.21 To facilitate our comprehension, we might consider a system composed of a beaker on a workbench. We can then consider the room that the beaker is in as the immediate surroundings. To all effects, the beaker+room combination behaves as a system isolated from the rest of the universe. The room is obviously much larger than the beaker itself, and therefore every energy production that happens in the system will have minimal effect on the parameters of the room. For example, an exothermal chemical reaction occurring in the beaker will not affect the overall temperature of the room substantially. When we study our reaction, \\(T_{\\text{surr}}\\) will be constant, and the transfer of heat from the reaction to the surroundings will happen at reversible conditions. Exercise 7.2 Calculate the changes in entropy of the universe for the process of 1 mol of supercooled water, freezing at –10°C, knowing the following data: \\(\\Delta_{\\mathrm{fus}}H = 6 \\; \\text{kJ/mol}\\), \\(C_P^{\\mathrm{H}_2 \\mathrm{O}_{(l)}}=76 \\; \\text{J/(mol K)}\\), \\(C_P^{\\mathrm{H}_2 \\mathrm{O}_{(s)}}=38 \\; \\text{J/(mol K)}\\), and assuming both \\(C_P\\) to be independent on temperature. Solution: \\(\\Delta S^{\\mathrm{sys}}\\) for the process under consideration can be calculated using the following cycle: \\[\\begin{equation} \\begin{aligned} \\mathrm{H}_2 \\mathrm{O}_{(l)} &amp; \\quad \\xrightarrow{\\quad \\Delta S_{\\text{sys}} \\quad} \\quad \\mathrm{H}_2 \\mathrm{O}_{(s)} \\qquad \\quad T=263\\;K\\\\ \\scriptstyle{\\Delta S_1} \\; \\bigg\\downarrow \\quad &amp; \\qquad \\qquad \\qquad \\qquad \\scriptstyle{\\bigg\\uparrow \\; \\Delta S_3} \\\\ \\mathrm{H}_2 \\mathrm{O}_{(l)} &amp; \\quad \\xrightarrow{\\quad \\Delta S_2 \\qquad} \\quad \\mathrm{H}_2\\mathrm{O}_{(s)} \\qquad \\; T=273\\;K\\\\ \\\\ \\Delta S^{\\text{sys}} &amp; = \\Delta S_1 + \\Delta S_2 + \\Delta S_3 \\end{aligned} \\tag{7.16} \\end{equation}\\] \\(\\Delta S_1\\) and \\(\\Delta S_3\\) are the isochoric heating and cooling processes of liquid and solid water, respectively, and can be calculated filling the given data into eq. (7.12). \\(\\Delta S_2\\) is a phase change (isothermal process) and can be calculated translating eq. (7.6) to the freezing transformation. Overall: \\[\\begin{equation} \\begin{aligned} \\Delta S^{\\text{sys}} &amp; = \\int_{263}^{273} \\frac{C_P^{\\mathrm{H}_2 \\mathrm{O}_{(l)}}}{T}dT+\\frac{-\\Delta_{\\mathrm{fus}}H}{273}+\\int_{273}^{263} \\frac{C_P^{\\mathrm{H}_2 \\mathrm{O}_{(s)}}}{T}dT \\\\ &amp; = 76 \\ln \\frac{273}{263} - \\frac{6 \\times 10^3}{273} + 38 \\ln \\frac{263}{273}= -20.6 \\; \\text{J/K}. \\end{aligned} \\tag{7.17} \\end{equation}\\] Don’t be confused by the fact that \\(\\Delta S^{\\text{sys}}\\) is negative. This is not the entropy of the universe! Hence it tells nothing about spontaneity! We can now calculate \\(\\Delta S^{\\text{surr}}\\) from \\(Q_{\\text{sys}}\\), noting that we can calculate the enthalpy around the same cycle in eq. (7.16). To do that, we already have \\(\\Delta_{\\mathrm{fus}}H\\) from the given data, and we can calculate \\(\\Delta H_1\\) and \\(\\Delta H_3\\) using eq. (2.4). \\[\\begin{equation} \\begin{aligned} Q^{\\text{sys}} &amp; = \\Delta H = \\int_{263}^{273} C_P^{\\mathrm{H}_2 \\mathrm{O}_{(l)}} dT + (-\\Delta_{\\mathrm{fus}}H) + \\int_{273}^{263} C_P^{\\mathrm{H}_2 \\mathrm{O}_{(s)}}dT \\\\ &amp; = 76 \\times 10^{-3} (273-263) - 6 + 38 \\times 10^{-3} (263-273) \\\\ &amp;= -5.6 \\; \\text{kJ}. \\\\ \\\\ \\Delta S^{\\text{surr}} &amp; = \\frac{-Q_{\\text{sys}}}{T}=\\frac{5.6 \\times 10^3}{263} = + 21.3 \\; \\text{J/K}. \\\\ \\end{aligned} \\tag{7.18} \\end{equation}\\] Bringing (7.16) and (7.18) results together, we obtain: \\[\\begin{equation} \\Delta S^{\\text{universe}}=\\Delta S^{\\text{sys}} + \\Delta S^{\\text{surr}} = -20.6+21.3=+0.7 \\; \\text{J/K}. \\tag{7.19} \\end{equation}\\] Since the entropy changes in the universe are positive, the process is spontaneous, as expected. 7.3 Clausius Theorem By replacing eq. (7.15) into (7.2) we can write the differential change in the entropy of the system as: \\[\\begin{equation} d S^{\\mathrm{sys}} = d S^{\\mathrm{universe}} - d S^{\\mathrm{surr}} = d S^{\\mathrm{universe}} + \\frac{đQ_{\\text{sys}}}{T}. \\tag{7.20} \\end{equation}\\] According to the second law, for any spontaneous process \\(d S^{\\mathrm{universe}}\\geq0\\), and therefore, replacing it into eq. (7.20): \\[\\begin{equation} d S^{\\mathrm{sys}} \\geq \\frac{đQ}{T}, \\tag{7.21} \\end{equation}\\] which is the mathematical expression of the so-called Clausius theorem. Eq. (7.21) distinguishes between three conditions: \\[\\begin{equation} \\begin{aligned} d S^{\\mathrm{sys}} &gt; \\frac{đQ}{T} \\qquad &amp;\\text{spontaneous, irreversible transformation} \\\\ d S^{\\mathrm{sys}} = \\frac{đQ}{T} \\qquad &amp;\\text{reversible transformation} \\\\ d S^{\\mathrm{sys}} &lt; \\frac{đQ}{T} \\qquad &amp;\\text{non-spontaneous, irreversible transformation}, \\end{aligned} \\tag{7.22} \\end{equation}\\] Clausius theorem provides a useful criterion to infer the spontaneity of a process, especially in cases where it’s hard to calculate \\(\\Delta S^{\\mathrm{universe}}\\). Eq. (7.21) requires knowledge of quantities that are dependent on the system exclusively, such as the difference in entropy, the amount of heat that crosses the boundaries, and the temperature at which the process happens.22 If a process produces more entropy than the amount of heat that crosses the boundaries divided by the absolute temperature, it will be spontaneous. Vice versa, if the entropy produced is smaller than the amount of heat crossing the boundaries divided by the absolute temperature, the process will be non-spontaneous. The equality holds for systems in equilibrium with their surroundings, or for reversible processes since they happen through a series of equilibrium states. Measuring or calculating these quantities might not always be the simplest of calculations. We will return to the Clausius theorem in the next chapter when we seek more convenient indicators of spontaneity. 7.4 The Third Law of Thermodynamics In chapter 4, we have discussed how to calculate reaction enthalpies for any reaction, given the formation enthalpies of reactants and products. In this section, we will try to do the same for reaction entropies. In this case, however, our task is simplified by a fundamental law of thermodynamics, introduced by Walther Hermann Nernst (1864–1941) in 1906.23 The statement that was initially known as Nernst’s Theorem is now officially recognized as the third fundamental law of thermodynamics, and it has the following definition: Definition 7.1 Third Law of Thermodynamics: The entropy of a perfectly ordered, pure, crystalline substance is zero at \\(T=0 \\; \\text{K}\\). This law sets an unambiguous zero of the entropy scale, similar to what happens with absolute zero in the temperature scale. The absolute value of the entropy of every substance can then be calculated in reference to this unambiguous zero. As such, absolute entropies are always positive. This is in stark contrast to what happened for the enthalpy. An unambiguous zero of the enthalpy scale is lacking, and standard formation enthalpies (which might be negative) must be agreed upon to calculate relative differences. In simpler terms, given a substance \\(i\\), we are not able to measure absolute values of its enthalpy \\(H_i\\) (and we must resort to known enthalpy differences, such as \\(\\Delta_{\\mathrm{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) at standard pressure). At the same time, for entropy, we can measure \\(S_i\\) thanks to the third law, and we usually report them as \\(S_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\). A comprehensive list of standard entropies of inorganic and organic compounds is reported in appendix 16. Reaction entropies can be calculated from the tabulated standard entropies as differences between products and reactants, using: \\[\\begin{equation} \\Delta_{\\text{rxn}} S^{-\\kern-6pt{\\ominus}\\kern-6pt-}= \\sum_i \\nu_i S_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}, \\tag{7.23} \\end{equation}\\] with \\(\\nu_i\\) being the usual stoichiometric coefficients with their signs given in Definition 4.2. The careful wording in the definition of the third law 7.1 allows for the fact that some crystal might form with defects (i.e., not as a perfectly ordered crystal). In this case, a residual entropy will be present even at \\(T=0 \\; \\text{K}\\). However, this residual entropy can be removed, at least in theory, by forcing the substance into a perfectly ordered crystal.24 An interesting corollary to the third law states that it is impossible to find a procedure that reduces the temperature of a substance to \\(T=0 \\; \\text{K}\\) in a finite number of steps. Even if we think at the most energetic event that we could imagine happening here on earth—such as the explosion of an atomic bomb or the hit of a meteorite from outer space—such an event will not modify the average temperature of the universe by the slightest degree.↩︎ In cases where the temperature of the system changes throughout the process, \\(T\\) is just the (constant) temperature of its immediate surroundings, \\(T_{\\text{surr}}\\), as explained in section 7.2.↩︎ Walther Nernst was awarded the 1920 Nobel Prize in Chemistry for his work in thermochemistry.↩︎ A procedure that—in practice—might be extremely difficult to achieve.↩︎ "],
["Potentials.html", "8 Thermodynamic Potentials 8.1 Fundamental Equation of Thermodynamics 8.2 Thermodynamic Potentials 8.3 Free Energies 8.4 Maxwell Relations", " 8 Thermodynamic Potentials 8.1 Fundamental Equation of Thermodynamics Let’s summarize some of the results from the first and second law of thermodynamics that we have seen so far. For reversible processes in closed systems: \\[\\begin{equation} \\begin{aligned} \\text{From 1}^{\\text{st}} \\text{ Law:} \\qquad \\quad &amp; dU = đQ_{\\mathrm{REV}}-PdV \\\\ \\text{From The Definition of Entropy:} \\qquad \\quad &amp; dS = \\frac{đQ_{\\mathrm{REV}}}{T} \\rightarrow đQ_{\\mathrm{REV}} = TdS \\\\ \\\\ \\Rightarrow \\quad &amp; dU = TdS - PdV. \\end{aligned} \\tag{8.1} \\end{equation}\\] Eq. (8.1) is called the fundamental equation of thermodynamics since it combines the first and the second laws. Even though we started the derivation above by restricting to reversible transformations only, if we look carefully at eq. (8.1), we notice that it exclusively involves state functions. As such, it applies to both reversible and irreversible processes. The fundamental equation, however, remains constrained to closed systems. This fact restricts its utility for chemistry, since when a chemical reaction happens, the mass in the system will change, and the system is no longer closed. At the end of the 19th century, Josiah Willard Gibbs (1839–1903) proposed an important addition to the fundamental equation to account for chemical reactions. Gibbs was able to do so by introducing a new quantity that he called the chemical potential: Definition 8.1 The chemical potential is the amount of energy absorbed or released due to a change of the particle number of a given chemical species. The chemical potential of species \\(i\\) is usually abbreviated as \\(\\mu_i\\), and it enters the fundamental equation of thermodynamics as: \\[\\begin{equation} dU = TdS-PdV+\\sum_i\\mu_i dn_i, \\tag{8.2} \\end{equation}\\] where \\(dn_i\\) is the differential change in the number of moles of substance \\(i\\), and the summation extends over all chemical species in the system. According to the fundamental equation, the internal energy of a system is a function of the three variables entropy, \\(S\\), volume, \\(V\\), and the numbers of moles \\(\\{n_i\\}\\).25 Because of their importance in determining the internal energy, these three variables are crucial in thermodynamics. Under several circumstances, however, they might not be the most convenient variables to use.26 To emphasize the important connections given by the fundamental equation, we can use the notation \\(U(S,V,\\{n_i\\})\\) and we can term \\(S\\), \\(V\\), and \\(\\{n_i\\}\\) natural variables of the energy. 8.2 Thermodynamic Potentials Starting from the fundamental equation, we can define new thermodynamic state functions that are more convenient to use under certain specific conditions. The new functions are determined by using a mathematical procedure called the Legendre transformation. A Legendre transformation is a linear change in variables that brings from an initial mathematical function to a new function obtained by subtracting one or more products of conjugate variables.27 Taking the internal energy as defined in eq. (8.1), we can perform such procedure by subtracting products of the following conjugate variables pairs: \\(T \\text{ and } S\\) or \\(-P \\text{ and } V\\). This procedure aims to define new state functions that depend on more convenient natural variables.28 The new functions are called “thermodynamic potential energies,” or simply thermodynamic potentials.29 An example of this procedure is given by the definition of enthalpy that we have already seen in section 3.1.4. If we take the internal energy and subtract the product of two conjugate variables (\\(-P\\) and \\(V\\)), we obtain a new state function called enthalpy, as we did in eq. (3.9)). Taking the differential of this definition, we obtain: \\[\\begin{equation} dH = dU +VdP +PdV, \\tag{8.3} \\end{equation}\\] and using the fundamental equation, eq. (8.2), to replace \\(dU\\), we obtain: \\[\\begin{equation} \\begin{aligned} dH &amp; = TdS -PdV +\\sum_i\\mu_i dn_i +VdP +PdV \\\\ &amp; = TdS +VdP +\\sum_i\\mu_i dn_i. \\end{aligned} \\tag{8.4} \\end{equation}\\] which is the fundamental equation for enthalpy. The natural variables of the enthalpy are \\(S\\), \\(P\\), and \\(\\{n_i\\}\\). The Legendre transformation has allowed us to go from \\(U(S,V,\\{n_i\\})\\) to \\(H(S,P,\\{n_i\\})\\) by replacing the dependence on the extensive variable, \\(V\\), with an intensive one, \\(P\\). Following the same procedure, we can perform another Legendre transformation to replace the entropy with a more convenient intensive variable such as the temperature. This can be done by defining a new function called the Helmholtz free energy, \\(A\\), as: \\[\\begin{equation} A = U -TS \\tag{8.5} \\end{equation}\\] which, taking the differential and using the fundamental equation (eq. (8.2)) becomes: \\[\\begin{equation} \\begin{aligned} dA &amp;= dU -SdT -TdS = TdS - PdV +\\sum_i \\mu_i dn_i -SdT -TdS \\\\ &amp;= -SdT -PdV +\\sum_i \\mu_i dn_i. \\end{aligned} \\tag{8.6} \\end{equation}\\] The Helmholtz free energy is named after Hermann Ludwig Ferdinand von Helmholtz (1821—1894), and its natural variables are temperature, volume, and the number of moles. Finally, suppose we perform a Legendre transformation on the internal energy to replace both the entropy and the volume with intensive variables. In that case, we can define a new function called the Gibbs free energy, \\(G\\), as: \\[\\begin{equation} G = U -TS +PV \\tag{8.7} \\end{equation}\\] which, taking again the differential and using eq. (8.2) becomes: \\[\\begin{equation} \\begin{aligned} dG &amp;= dU -SdT -TdS +VdP +PdV \\\\ &amp;= TdS - PdV +\\sum_i\\mu_i dn_i -SdT -TdS +VdP +PdV \\\\ &amp;= VdP -SdT +\\sum_i\\mu_i dn_i. \\end{aligned} \\tag{8.8} \\end{equation}\\] The Gibbs free energy is named after Willard Gibbs himself, and its natural variables are temperature, pressure, and number of moles. A summary of the four thermodynamic potentials is given in the following table. Name Symbol Fundamental Equation Natural Variables Energy \\(U\\) \\(dU=TdS-PdV+\\sum_i\\mu_i dn_i\\) \\(S,V,\\{n_i\\}\\) Enthalpy \\(H\\) \\(dH=TdS+VdP+\\sum_i\\mu_i dn_i\\) \\(S,P,\\{n_i\\}\\) Helmholtz Free Energy \\(A\\) \\(dA=-SdT-PdV+\\sum_i\\mu_i dn_i\\) \\(T,V,\\{n_i\\}\\) Gibbs Free Energy \\(G\\) \\(dG=VdP-SdT+\\sum_i\\mu_i dn_i\\) \\(T,P,\\{n_i\\}\\) The thermodynamic potentials are the analog of the potential energy in classical mechanics. Since the potential energy is interpreted as the capacity to do work, the thermodynamic potentials assume the following interpretations: Internal energy (\\(U\\)) is the capacity to do work plus the capacity to release heat. Enthalpy (\\(H\\)) is the capacity to do non-mechanical work plus the capacity to release heat. Gibbs free energy (\\(G\\)) is the capacity to do non-mechanical work. Helmholtz free energy (\\(A\\)) is the capacity to do mechanical plus non-mechanical work.30 Where non-mechanical work is defined as any type of work that is not expansion or compression (\\(PV\\)–work). A typical example of non-mechanical work is electrical work. 8.3 Free Energies The Legendre transformation procedure translates all information contained in the original function to the new one. Therefore, \\(H(S,P,\\{n_i\\})\\), \\(A(T,V,\\{n_i\\})\\), and \\(G(T,P,\\{n_i\\})\\) all contain the same information that is in \\(U(S,V,\\{n_i\\})\\). However, the new functions depend on different natural variables, and they are useful at different conditions. For example, when we want to study chemical changes, we are interested in studying the term \\(\\sum_i\\mu_i dn_i\\) that appears in each thermodynamic potential. To do so, we need to isolate the chemical term by keeping all other natural variables constant. For example, changes in the chemical term will correspond to changes in the internal energy at constant \\(S\\) and constant \\(V\\): \\[\\begin{equation} dU(S,V,\\{n_i\\}) = \\sum_i\\mu_i dn_i \\quad \\text{if} \\quad dS=dV=0. \\tag{8.9} \\end{equation}\\] Similarly: \\[\\begin{equation} \\begin{aligned} dH(S,P,\\{n_i\\}) = \\sum_i\\mu_i dn_i \\quad \\text{if} \\quad dS=dP=0, \\\\ dA(T,V,\\{n_i\\}) = \\sum_i\\mu_i dn_i \\quad \\text{if} \\quad dT=dV=0, \\\\ dG(T,P,\\{n_i\\}) = \\sum_i\\mu_i dn_i \\quad \\text{if} \\quad dT=dP=0. \\end{aligned} \\tag{8.10} \\end{equation}\\] The latter two cases are particularly interesting since most of chemistry happens at either constant volume,31 or constant pressure.32 Since \\(dS=0\\) is not a requirement for both free energies to describe chemical changes, we can apply either of them to study non-isentropic processes. If a process is not isentropic, it either increases the entropy of the universe, or it decreases it. Therefore—according to the second law—it is either spontaneous or not. Using this concept in conjunction with Clausius theorem, we can devise new criteria for inferring the spontaneity of a process that depends exclusively on the free energies. Recalling Clausius theorem: \\[\\begin{equation} d S^{\\mathrm{sys}} \\geq \\frac{đQ}{T_{\\text{surr}}} \\quad \\longrightarrow \\quad TdS \\geq đQ, \\tag{8.11} \\end{equation}\\] we can consider the two cases: constant \\(V\\) (\\(đQ_V=dU\\), left), and constant \\(P\\) (\\(đQ_P=dH\\), right): \\[\\begin{equation} \\begin{aligned} \\text{constant} &amp; \\; V: &amp; \\qquad \\qquad &amp; \\qquad \\qquad &amp; \\text{constant} &amp; \\; P: \\\\ \\\\ TdS &amp; \\geq dU &amp; &amp; &amp; TdS &amp; \\geq dH \\\\ \\\\ TdS -dU &amp; \\geq 0 &amp; &amp; &amp; TdS -dH &amp; \\geq 0 \\\\ \\end{aligned} \\tag{8.12} \\end{equation}\\] we can then simplify the definition of free energies, eqs. (8.6) and (8.8): \\[\\begin{equation} \\begin{aligned} \\text{constant} &amp; \\; T,V: &amp; \\qquad &amp; \\qquad &amp; \\text{constant} &amp; \\; T,P: \\\\ \\\\ (dA)_{T,V} &amp;= dU -TdS &amp; &amp; &amp; (dG)_{T,P} &amp;= dH - TdS \\\\ \\\\ dU = (dA)_{T,V} &amp;+TdS &amp; &amp; &amp; dH = (dG)_{T,P} &amp;+TdS \\end{aligned} \\tag{8.13} \\end{equation}\\] and by merging \\(dU\\) and \\(dH\\) from eqs. (8.13) into Clausius theorem expressed using eqs. (8.12), we obtain: \\[\\begin{equation} \\begin{aligned} TdS -(dA)_{T,V} &amp;- TdS \\geq 0 &amp; \\qquad &amp; \\qquad &amp; TdS -(dG)_{T,P} &amp;- TdS \\geq 0 \\\\ \\\\ (dA)_{T,V} &amp; \\leq 0 &amp; \\qquad &amp; \\qquad &amp; (dG)_{T,P} &amp; \\leq 0. \\\\ \\end{aligned} \\tag{8.14} \\end{equation}\\] These equations represent the conditions on \\(dA\\) and \\(dG\\) for inferring the spontaneity of a process, and can be summarized as follows: Definition 8.2 \\(\\;\\) During a spontaneous process at constant temperature and volume, the Helmholtz free energy will decrease \\((dA&lt;0)\\), until it reaches a stationary point at which the system will be at equilibrium \\((dA=0)\\). During a spontaneous process at constant temperature and pressure, the Gibbs free energy will decrease \\((dG&lt;0)\\), until it reaches a stationary point at which the system will be at equilibrium \\((dG=0)\\). Figure 8.1: Behavior of Helmholtz (red) and Gibbs (blue) Free Energies for Spontaneous Processes at Constant \\(T,V\\) (left) and Constant \\(T,P\\) (right). 8.4 Maxwell Relations Let’s consider the fundamental equations for the thermodynamic potentials that we have derived in section 8.1: \\[\\begin{equation} \\begin{aligned} dU(S,V,\\{n_i\\}) &amp;= \\enspace T dS -P dV + \\sum_i \\mu_i dn_i \\\\ dH(S,P,\\{n_i\\}) &amp;= \\enspace T dS + V dP + \\sum_i \\mu_i dn_i \\\\ dA(T,V,\\{n_i\\}) &amp;= -S dT -P dV + \\sum_i \\mu_i dn_i \\\\ dG(T,P,\\{n_i\\}) &amp;= -S dT + V dP + \\sum_i \\mu_i dn_i\\;. \\end{aligned} \\tag{8.15} \\end{equation}\\] From the knowledge of the natural variable of each potential, we could reconstruct these formulas by using the total differential formula: \\[\\begin{equation} \\begin{aligned} dU &amp;= \\underbrace{\\left(\\frac{\\partial U}{\\partial S} \\right)_{V,\\{n_i\\}}}_{T} dS + \\underbrace{\\left(\\frac{\\partial U}{\\partial V} \\right)_{S,\\{n_i\\}}}_{-P} dV + \\sum_i \\underbrace{\\left(\\frac{\\partial U}{\\partial n_i} \\right)_{S,V,\\{n_{j \\neq i}\\}}}_{\\mu_i} dn_i \\\\ dH &amp;= \\underbrace{\\left(\\frac{\\partial H}{\\partial S} \\right)_{P,\\{n_i\\}}}_{T} dS + \\underbrace{\\left(\\frac{\\partial H}{\\partial P} \\right)_{S,\\{n_i\\}}}_{V} dP + \\sum_i \\underbrace{\\left(\\frac{\\partial H}{\\partial n_i} \\right)_{S,P,\\{n_{j \\neq i}\\}}}_{\\mu_i} dn_i \\\\ dA &amp;= \\underbrace{\\left(\\frac{\\partial A}{\\partial T} \\right)_{V,\\{n_i\\}}}_{-S} dT + \\underbrace{\\left(\\frac{\\partial A}{\\partial V} \\right)_{T,\\{n_i\\}}}_{-P} dV + \\sum_i \\underbrace{\\left(\\frac{\\partial A}{\\partial n_i} \\right)_{T,V,\\{n_{j \\neq i}\\}}}_{\\mu_i} dn_i \\\\ dG &amp;= \\underbrace{\\left(\\frac{\\partial G}{\\partial T} \\right)_{V,\\{n_i\\}}}_{-S} dT + \\underbrace{\\left(\\frac{\\partial G}{\\partial P} \\right)_{T,\\{n_i\\}}}_{V} dP + \\sum_i \\underbrace{\\left(\\frac{\\partial G}{\\partial n_i} \\right)_{T,P,\\{n_{j \\neq i}\\}}}_{\\mu_i} dn_i\\;, \\end{aligned} \\tag{8.16} \\end{equation}\\] we can derive the following new definitions: \\[\\begin{equation} \\begin{aligned} T &amp;= \\left(\\frac{\\partial U}{\\partial S} \\right)_{V,\\{n_i\\}} = \\left(\\frac{\\partial H}{\\partial S} \\right)_{P,\\{n_i\\}} \\\\ -P &amp;= \\left(\\frac{\\partial U}{\\partial V} \\right)_{S,\\{n_i\\}} = \\left(\\frac{\\partial A}{\\partial V} \\right)_{T,\\{n_i\\}} \\\\ V &amp;= \\left(\\frac{\\partial H}{\\partial P} \\right)_{S,\\{n_i\\}} = \\left(\\frac{\\partial G}{\\partial P} \\right)_{T,\\{n_i\\}} \\\\ -S &amp;= \\left(\\frac{\\partial A}{\\partial T} \\right)_{V,\\{n_i\\}} = \\left(\\frac{\\partial G}{\\partial T} \\right)_{V,\\{n_i\\}} \\\\ \\text{and:} \\\\ \\mu_i &amp;= \\left(\\frac{\\partial U}{\\partial n_i} \\right)_{S,V,\\{n_{j \\neq i}\\}} = \\left(\\frac{\\partial H}{\\partial n_i} \\right)_{S,P,\\{n_{j \\neq i}\\}} \\\\ &amp;= \\left(\\frac{\\partial A}{\\partial n_i} \\right)_{T,V,\\{n_{j \\neq i}\\}} = \\left(\\frac{\\partial G}{\\partial n_i} \\right)_{T,P,\\{n_{j \\neq i}\\}}\\;. \\end{aligned} \\tag{8.17} \\end{equation}\\] Since \\(T\\), \\(P\\), \\(V\\), and \\(S\\) are now defined as partial first derivatives of a thermodynamic potential, we can now take a second partial derivation with respect to a separate variable, and rely on Schwartz’s theorem to derive the following relations: \\[\\begin{equation} \\begin{aligned} \\frac{\\partial^2 U }{\\partial S \\partial V} &amp;=&amp; +\\left(\\frac{\\partial T}{\\partial V}\\right)_{S,\\{n_{j \\neq i}\\}} &amp;=&amp; -\\left(\\frac{\\partial P}{\\partial S}\\right)_{V,\\{n_{j \\neq i}\\}} \\\\ \\frac{\\partial^2 H }{\\partial S \\partial P} &amp;=&amp; +\\left(\\frac{\\partial T}{\\partial P}\\right)_{S,\\{n_{j \\neq i}\\}} &amp;=&amp; +\\left(\\frac{\\partial V}{\\partial S}\\right)_{P,\\{n_{j \\neq i}\\}} \\\\ -\\frac{\\partial^2 A }{\\partial T \\partial V} &amp;=&amp; +\\left(\\frac{\\partial S}{\\partial V}\\right)_{T,\\{n_{j \\neq i}\\}} &amp;=&amp; +\\left(\\frac{\\partial P}{\\partial T}\\right)_{V,\\{n_{j \\neq i}\\}} \\\\ \\frac{\\partial^2 G }{\\partial T \\partial P} &amp;=&amp; -\\left(\\frac{\\partial S}{\\partial P}\\right)_{T,\\{n_{j \\neq i}\\}} &amp;=&amp; +\\left(\\frac{\\partial V}{\\partial T}\\right)_{P,\\{n_{j \\neq i}\\}} \\end{aligned} \\tag{8.18} \\end{equation}\\] The relations in (8.18) are called Maxwell relations,33 and are useful in experimental settings to relate quantities that are hard to measure with others that are more intuitive. Exercise 8.1 Derive the last Maxwell relation in eq. (8.18). Solution: We can start our derivation from the definition of \\(V\\) and \\(S\\) as a partial derivative of \\(G\\): \\[\\begin{equation} V = \\left(\\frac{\\partial G}{\\partial P} \\right)_{T,\\{n_i\\}} \\qquad \\text{and:} \\qquad -S = \\left(\\frac{\\partial G}{\\partial T} \\right)_{V,\\{n_i\\}}, \\end{equation}\\] and then take a second partial derivative of each quantity with respect to the second variable: \\[\\begin{equation} \\begin{aligned} \\left(\\frac{\\partial V}{\\partial T} \\right)_{P,\\{n_i\\}} &amp;=\\frac{\\partial}{\\partial T}\\left[ \\left(\\frac{\\partial G}{\\partial P} \\right)_{T,\\{n_i\\}} \\right]_{P,\\{n_i\\}} \\\\ \\\\ -\\left(\\frac{\\partial S}{\\partial P} \\right)_{T,\\{n_i\\}} &amp;=\\frac{\\partial}{\\partial P}\\left[ \\left(\\frac{\\partial G}{\\partial T} \\right)_{P,\\{n_i\\}} \\right]_{T,\\{n_i\\}} \\;. \\end{aligned} \\end{equation}\\] These two derivatives are mixed partial second derivatives of \\(G\\) with respect to \\(T\\) and \\(P\\), and therefore, according to Schwartz’s theorem, they are equal to each other: \\[\\begin{equation} \\begin{aligned} \\frac{\\partial}{\\partial T}\\left[ \\left(\\frac{\\partial G}{\\partial P} \\right)_{T,\\{n_i\\}} \\right]_{P,\\{n_i\\}} &amp;= \\frac{\\partial}{\\partial P}\\left[ \\left(\\frac{\\partial G}{\\partial T} \\right)_{P,\\{n_i\\}} \\right]_{T,\\{n_i\\}}, \\\\ \\\\ \\text{hence:} \\\\ \\\\ \\left(\\frac{\\partial V}{\\partial T} \\right)_{P,\\{n_i\\}} &amp;= -\\left(\\frac{\\partial S}{\\partial P} \\right)_{T,\\{n_i\\}}, \\end{aligned} \\end{equation}\\] which is the last of Maxwell relations, as defined in eq. (8.18). This relation is particularly useful because it connects the quantity \\(\\left(\\frac{\\partial S}{\\partial P} \\right)_{T,\\{n_i\\}}\\)—which is impossible to measure in a lab—with the quantity \\(\\left(\\frac{\\partial V}{\\partial T} \\right)_{P,\\{n_i\\}}\\)—which is easier to measure from an experiment that determines isobaric volumetric thermal expansion coefficients. In the case of the numbers of moles we include them in curly brackets to indicate that there might be more than one, depending on how many species undergo chemical reactions.↩︎ For example, we don’t always have a simple way to calculate or to measure the entropy.↩︎ The mathematical condition that is fulfilled when performing a Legendre transformation is that the first derivatives of the original function and its transformation are inverse functions of each other.↩︎ The rigorous mathematical definition of conjugate variables is unimportant at this stage. However, we can relate the variables in a pair with basic physics by noticing how the first variable in a pair is always intensive (\\(T\\) and \\(-P\\)), while the second one is always extensive (\\(S\\) and \\(V\\)). The intensive variables represent thermodynamic drivinng forces (as compared with mechanical forces in classical mechanics), while the extensive ones are the thermodynamic displacements (as compared with spatial displacements in classical mechanics). Similarly to classical mechanics, the product of two conjugate variables in a pair yields an energy. The minus sign in front of \\(P\\) is explained by the fact that an increase in the force should always correspond to an increase in the displacement (while \\(P\\) and \\(V\\) are inversely related).↩︎ Even if we introduced both concepts in the same chapter, it is important to never confuse the thermodynamic potentials—which are potential energy functions—with the chemical potential—which have been introduced by Gibbs to study heat in chemical reactions.↩︎ For the mathematically inclined, an entertaining method to summarize the same thermodynamic potentials is the thermodynamic square.↩︎ for example, several industrial processes in chemical plants.↩︎ for example, most processes in a chemistry lab.↩︎ Maxwell relations should not be confused with the Maxwell equations of electromagnetism.↩︎ "],
["GibbsFree.html", "9 Gibbs Free Energy 9.1 Gibbs Equation 9.2 Temperature Dependence of \\(\\Delta G\\) 9.3 Pressure Dependence of \\(\\Delta G\\) 9.4 Composition Dependence of \\(\\Delta G\\)", " 9 Gibbs Free Energy In this chapter, we will concentrate on chemical processes that happen at constant \\(T\\) and constant \\(P\\).34 As such, we will focus our attention on the Gibbs free energy. 9.1 Gibbs Equation Recalling from the previous chapter, the definition of \\(G\\) is: \\[\\begin{equation} G = U -TS +PV = H-TS, \\tag{9.1} \\end{equation}\\] which, taking the differential at constant \\(T\\) and \\(P\\), becomes: \\[\\begin{equation} dG = dH \\; \\overbrace{-SdT}^{=0} -TdS = dH -TdS. \\tag{9.2} \\end{equation}\\] Integrating eq. (9.2) between the initial and final states of a process results in: \\[\\begin{equation} \\begin{aligned} \\int_i^f dG &amp;= \\int_i^f dH -T \\int_i^f dS \\\\ \\\\ \\Delta G &amp;= \\Delta H -T \\Delta S \\end{aligned} \\tag{9.3} \\end{equation}\\] which is the famous Gibbs equation for \\(\\Delta G\\). Using Definition 8.2, we can use \\(\\Delta G\\) to infer the spontaneity of a chemical process that happens at constant \\(T\\) and \\(P\\) using \\(\\Delta G \\leq 0\\). If we set ourselves at standard conditions, we can calculate the standard Gibbs free energy of formation, \\(\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\), for any reaction as: \\[\\begin{equation} \\begin{aligned} \\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}&amp;= \\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}-T \\Delta_{\\text{rxn}} S^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\\\ \\\\ &amp;= \\sum_i \\nu_i \\Delta_{\\mathrm{f}} H_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ T \\sum_i \\nu_i S_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}, \\end{aligned} \\tag{9.4} \\end{equation}\\] where \\(\\Delta_{\\mathrm{f}} H_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) are the standard enthalpies of formation, \\(S_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) are the standard entropies, and \\(\\nu_i\\) are the stoichiometric coefficients for every species \\(i\\) involved in the reaction. All these quantities are commonly available, and we have already discussed their usage in chapters 4 and 7, respectively.35 The following four options are possible for \\(\\Delta G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) of a chemical reaction: \\(\\Delta G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) \\(\\Delta H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) \\(\\Delta S^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) Spontaneous? – if – + Always + if + – Never –/+ if – – Depends on \\(T\\): \\(\\scriptstyle{\\text{spontaneous at low } T}\\) +/– if + + Depends on \\(T\\): \\(\\scriptstyle{\\text{spontaneous at high } T}\\) Or, in other words: Exothermic reactions that increase the entropy are always spontaneous. Endothermic reactions that reduce the entropy are always non-spontaneous. For the other two cases, the spontaneity of the reaction depends on the temperature: Exothermic reactions that reduce the entropy are spontaneous at low \\(T\\). Endothermic reactions that increase the entropy are spontaneous at high \\(T\\). A simple criterion to evaluate the entropic contribution of a reaction is to look at the total number of moles of the reactants and the products (as the sum of the stoichiometric coefficients). If the reaction is producing more molecules than it destroys \\(\\left( \\left| \\sum_\\text{products} \\nu_i \\right| &gt; \\left| \\sum_\\text{reactants} \\nu_i \\right| \\right)\\), it will increase the entropy. Vice versa, if the total number of moles in a reaction is reducing \\(\\left( \\left| \\sum_\\text{products} \\nu_i \\right| &lt; \\left| \\sum_\\text{reactants} \\nu_i \\right| \\right)\\), the entropy will also reduce. As we saw in section 8.2, the natural variables of the Gibbs free energy are the temperature, \\(T\\), the pressure, \\(P\\), and chemical composition, as the number of moles \\(\\{n_i\\}\\). The Gibbs free energy can therefore be expressed using the total differential as (see also, last formula in eq. (8.16)): \\[\\begin{equation} dG(T,P,\\{n_i\\}) = \\mkern-18mu \\underbrace{\\left(\\frac{\\partial G}{\\partial T} \\right)_{P,\\{n_i\\}}}_{\\text{temperature dependence}} \\mkern-36mu dT + \\underbrace{\\left(\\frac{\\partial G}{\\partial P} \\right)_{T,\\{n_i\\}}}_{\\text{pressure dependence}} \\mkern-36mu dP + \\sum_i \\underbrace{\\left(\\frac{\\partial G}{\\partial n_i} \\right)_{T,P,\\{n_{j \\neq i}\\}}}_{\\text{composition dependence}} \\mkern-36mu dn_i. \\tag{9.5} \\end{equation}\\] If we know the behavior of \\(G\\) as we vary each of the three natural variables independently of the other two, we can reconstruct the total differential \\(dG\\). Each of these terms represents a coefficient in eq. (9.5), which are given in eq. (8.17). 9.2 Temperature Dependence of \\(\\Delta G\\) \\[ \\left(\\frac{\\partial G}{\\partial T} \\right)_{P,\\{n_i\\}}=-S \\] Let’s analyze the first coefficient that gives the dependence of the Gibbs energy on temperature. Since this coefficient is equal to \\(-S\\) and the entropy is always positive, \\(G\\) must decrease when \\(T\\) increases at constant \\(P\\) and \\(\\{n_i\\}\\), and vice versa. If we replace this coefficient for \\(-S\\) in the Gibbs equation, eq. (9.3), we obtain: \\[\\begin{equation} \\Delta G = \\Delta H + T \\left(\\frac{\\partial \\Delta G}{\\partial T} \\right)_{P,\\{n_i\\}}, \\tag{9.6} \\end{equation}\\] and since eq. (9.6) includes both \\(\\Delta G\\) and its partial derivative with respect to temperature \\(\\left(\\frac{\\partial \\Delta G}{\\partial T} \\right)_{P,\\{n_i\\}}\\) we need to rearrange it to include the temperature derivative only. To do so, we can start by evaluating the partial derivative of \\(\\left( \\frac{\\Delta G}{T} \\right)\\) using the chain rule: \\[\\begin{equation} \\left[ \\frac{\\partial\\left( \\frac{\\Delta G}{T} \\right)}{\\partial T} \\right]_{P,\\{n_i\\}} = \\frac{1}{T} \\left(\\frac{\\partial \\Delta G}{\\partial T} \\right)_{P,\\{n_i\\}} - \\frac{1}{T^2}\\Delta G, \\tag{9.7} \\end{equation}\\] which, replacing \\(\\Delta G\\) from eq. (9.6) into eq. (9.7), becomes: \\[\\begin{equation} \\begin{aligned} \\left[ \\frac{\\partial\\left( \\frac{\\Delta G}{T} \\right)}{\\partial T} \\right]_{P,\\{n_i\\}} &amp;= \\frac{1}{T} \\left(\\frac{\\partial \\Delta G}{\\partial T} \\right)_{P,\\{n_i\\}} - \\frac{1}{T^2} \\left[ \\Delta H + T \\left(\\frac{\\partial \\Delta G}{\\partial T} \\right)_{P,\\{n_i\\}} \\right] \\\\ &amp;= \\frac{1}{T} \\left(\\frac{\\partial \\Delta G}{\\partial T} \\right)_{P,\\{n_i\\}}- \\frac{\\Delta H}{T^2}-\\frac{1}{T} \\left(\\frac{\\partial \\Delta G}{\\partial T} \\right)_{P,\\{n_i\\}}, \\end{aligned} \\tag{9.8} \\end{equation}\\] which simplifies to: \\[\\begin{equation} \\begin{aligned} \\left[ \\frac{\\partial\\left( \\frac{\\Delta G}{T} \\right)}{\\partial T} \\right]_{P,\\{n_i\\}} &amp;= - \\frac{\\Delta H}{T^2}. \\end{aligned} \\tag{9.9} \\end{equation}\\] Equation (9.9) is known as the Gibbs–Helmholtz equation, and is useful in its integrated form to calculate the Gibbs free energy for a chemical reaction at any temperature \\(T\\) by knowing just the standard Gibbs free energy of formation and the standard enthalpy of formation for the individual species, which are usually reported at \\(T=298\\;\\text{K}\\). The integration is performed as follows: \\[\\begin{equation} \\begin{aligned} \\int_{T_i=298 \\;\\text{K}}^{T_f=T} \\frac{\\partial\\left( \\frac{\\Delta_{\\text{rxn}} G}{T} \\right)}{\\partial T} &amp;= - \\int_{T_i=298 \\;\\text{K}}^{T_f=T} \\frac{\\Delta_{\\text{rxn}} H}{T^2} \\\\ \\\\ \\frac{\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}(T)}{T} &amp;= \\frac{\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{298 \\;\\text{K}} + \\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\left( \\frac{1}{T^2} -\\frac{1}{(298 \\;\\text{K})^2} \\right), \\end{aligned} \\tag{9.10} \\end{equation}\\] giving the integrated Gibbs–Helmholtz equation: \\[\\begin{equation} \\frac{\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}(T)}{T} = \\frac{\\sum_i \\nu_i \\Delta_{\\text{f}} G_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{298 \\;\\text{K}} + \\sum_i \\nu_i \\Delta_{\\text{f}} H_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\left( \\frac{1}{T^2} -\\frac{1}{(298 \\;\\text{K})^2} \\right) \\tag{9.11} \\end{equation}\\] 9.3 Pressure Dependence of \\(\\Delta G\\) \\[ \\left(\\frac{\\partial G}{\\partial P} \\right)_{T,\\{n_i\\}}=V \\] We can now turn the attention to the second coefficient that gives how the Gibbs free energy changes when the pressure change. To do this, we put the system at constant \\(T\\) and \\(\\{n_i\\}\\), and then we consider infinitesimal variations of \\(G\\). From eq. (8.8): \\[\\begin{equation} dG = VdP -SdT +\\sum_i\\mu_i dn_i \\quad \\xrightarrow{\\text{constant}\\; T,\\{n_i\\}} \\quad dG = VdP, \\tag{9.12} \\end{equation}\\] which is the differential equation that we were looking for. To study changes of \\(G\\) for macroscopic changes in \\(P\\), we can integrate eq. (9.12) between initial and final pressures, and considering an ideal gas, we obtain: \\[\\begin{equation} \\begin{aligned} \\int_i^f dG &amp;= \\int_i^f VdP \\\\ \\Delta G &amp;= nRT \\int_i^f \\frac{dP}{P} = nRT \\ln \\frac{P_f}{P_i}. \\end{aligned} \\tag{9.13} \\end{equation}\\] If we take \\(P_i = P^{-\\kern-6pt{\\ominus}\\kern-6pt-}= 1 \\, \\text{bar}\\), we can rewrite eq. (9.13) as: \\[\\begin{equation} G = G^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ nRT \\ln \\frac{P_f}{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}}, \\tag{9.14} \\end{equation}\\] which is useful to convert standard Gibbs free energies of formation at pressures different than standard pressure, using: \\[\\begin{equation} \\Delta_{\\text{f}} G = \\Delta_{\\text{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ nRT \\ln \\frac{P_f}{\\underbrace{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}}_{=1 \\; \\text{bar}}} = \\Delta_{\\text{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ nRT \\ln P_f \\tag{9.15} \\end{equation}\\] For liquids and solids, \\(V\\) is essentially independent of \\(P\\) (liquids and solids are incompressible), and eq. (9.12) can be integrated as: \\[\\begin{equation} \\Delta G = \\int_i^f VdP = V \\int_i^f dP = V \\Delta P. \\tag{9.16} \\end{equation}\\] The plots in Figure 9.1 show the remarkable difference in the behaviors of \\(\\Delta_{\\text{f}} G\\) for a gas and for a liquid, as obtained from eqs. (9.13) and (9.16). Figure 9.1: Dependence of the Gibbs Free Energiy of Formation of Liquid and Gaseous Ethanol at T = 310 K. The Curves Cross at the Vapor Pressure of Liquid Ethanol at this Temperature, which is 0.1 bar. 9.4 Composition Dependence of \\(\\Delta G\\) \\[ \\left(\\frac{\\partial G}{\\partial n_i} \\right)_{T,P}=\\mu_i \\] The third and final coefficient gives the chemical potential as the dependence of \\(G\\) on the chemical composition at constant \\(T\\) and \\(P\\). Similarly to the previous cases, we can take the definition of the coefficient and integrate it directly between the initial and final stages of a reaction. If we consider a reaction product, pure substance \\(i\\), at the beginning of the reaction there will be no moles of it \\(n_i=0\\), and consequently \\(G=0\\).36 We can then integrate the left-hand side between zero and the number of moles of product at the end of the reaction, \\(n\\), and the right-hand side between zero and the Gibbs free energy of the product, \\(G\\). The integral will become: \\[\\begin{equation} \\int_0^G d G = \\int_0^n \\mu^* dn, \\tag{9.17} \\end{equation}\\] where \\(\\mu^*\\) indicates the chemical potential of a pure substance, which is independent on the number of moles by definition. As such, eq. (9.17) becomes: \\[\\begin{equation} \\int_0^G d G = \\mu^* \\int_0^n dn \\quad \\rightarrow \\quad G = \\mu^* n \\quad \\rightarrow \\quad \\mu^* = \\frac{G}{n}, \\tag{9.18} \\end{equation}\\] which gives a straightforward interpretation of the chemical potential of a pure substance as the molar Gibbs free energy. We can start from eq. (9.14) and write for a pure substance that is brought from \\(P_i=P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) to \\(P_f=P\\) at constant \\(T\\): \\[\\begin{equation} G - G^{-\\kern-6pt{\\ominus}\\kern-6pt-}= nRT \\ln \\frac{P}{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}}, \\tag{9.19} \\end{equation}\\] dividing both sides by \\(n\\), we obtain: \\[\\begin{equation} \\frac{G}{n} - \\frac{G^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{n} = RT \\ln \\frac{P}{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}}, \\tag{9.20} \\end{equation}\\] which, for a pure substance at \\(P^{-\\kern-6pt{\\ominus}\\kern-6pt-}= 1 \\;\\text{bar}\\), becomes: \\[\\begin{equation} \\mu^* - \\mu^{-\\kern-6pt{\\ominus}\\kern-6pt-}= RT \\ln P. \\tag{9.21} \\end{equation}\\] Notice that, while we use the pressure of the gas inside the logarithm in eq. (9.21), the quantity is formally divided by the standard pressure \\(P^{-\\kern-6pt{\\ominus}\\kern-6pt-}= 1 \\;\\text{bar}\\), and therefore it is a dimensionless quantity, as it should be. For simplicity of notation, however, we will omit the division by \\(P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) in the remaining of this textbook, especially wherever it does not create confusion. Let’s now consider a mixture of ideal gases, and let’s try to find out whether the chemical potential of a pure gas inside the mixture, \\(\\mu_i^{\\text{mixture}}\\), is the same as its chemical potential outside the mixture, \\(\\mu^*\\). To do so, we can use eq. (9.21) and replace the pressure \\(P\\) with the partial pressure \\(P_i\\): \\[\\begin{equation} \\mu_i^{\\text{mixture}} = \\mu_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ RT \\ln P_i, \\tag{9.22} \\end{equation}\\] where the partial pressure \\(P_i\\) can be obtained from the simple relation that is known as Dalton’s Law: \\[\\begin{equation} P_i = y_i P, \\tag{9.23} \\end{equation}\\] with \\(y_i\\) being the concentration of gas \\(i\\) measured as a mole fraction in the gas phase \\(y_i=\\frac{n_i}{n_{\\text{TOT}}} &lt; 1\\). Replacing eq. (9.23) into eq. (9.22), we obtain: \\[\\begin{equation} \\begin{aligned} \\mu_i^{\\text{mixture}} &amp;= \\mu_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ RT \\ln (y_i P) \\\\ &amp;= \\underbrace{\\mu_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ RT \\ln P}_{\\mu_i^*} + RT \\ln y_i, \\end{aligned} \\tag{9.24} \\end{equation}\\] which then reduces to the following equation: \\[\\begin{equation} \\mu_i^{\\text{mixture}} = \\mu_i^* + RT \\ln y_i. \\tag{9.25} \\end{equation}\\] Analyzing eq. (9.25), we can immediately see that, since \\(y_i &lt; 1\\): \\[\\begin{equation} \\mu_i^{\\text{mixture}} &lt; \\mu_i^*, \\tag{9.26} \\end{equation}\\] or, in other words, the chemical potential of a substance in the mixture is always lower than the chemical potential of the pure substance. If we consider a process where we start from two separate pure ideal gases and finish with a mixture of the two, we can calculate the change in Gibbs free energy due to the mixing process with: \\[\\begin{equation} \\Delta_{\\text{mixing}} G = \\sum n_i \\left( \\mu_i^{\\text{mixture}} - \\mu_i^* \\right) &lt; 0, \\tag{9.27} \\end{equation}\\] or, in other words, the process is spontaneous under all circumstances, and pure ideal gases will always mix. The majority of chemical reactions in a lab happens at those conditions, and all biological functions happen at those conditions as well.↩︎ It is not uncommon to see values of \\(\\Delta_{\\text{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) tabulated alongside \\(\\Delta_{\\mathrm{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) and \\(S_i^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\), which simplifies even further the calculation. In fact, a comprehensive list of standard Gibbs free energy of formation of inorganic and organic compounds is reported in the appendix of this book 16. For cases where \\(\\Delta_{\\text{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) are not reported, they can always be calculated by their constituents.↩︎ For reactants, the same situation usually applies but in reverse. More complicated cases where the reaction does not consume all reactants are possible, but insignificant for the following treatment.↩︎ "],
["ChemicalEquilibrium.html", "10 Chemical Equilibrium 10.1 Reaction Quotient and Equilibrium Constant 10.2 Temperature Dependence of \\(K_{\\text{eq}}\\) 10.3 Pressure and Composition Dependence of \\(K_{\\text{eq}}\\)", " 10 Chemical Equilibrium 10.1 Reaction Quotient and Equilibrium Constant Let’s consider a prototypical reaction at constant \\(T,P\\): \\[\\begin{equation} a\\mathrm{A} + b\\mathrm{B} \\rightarrow c\\mathrm{C} + d\\mathrm{D} \\tag{10.1} \\end{equation}\\] The Gibbs free energy of the reaction is defined as: \\[\\begin{equation} \\Delta_{\\text{rxn}} G = G_{\\text{products}} - G_{\\text{reactants}} = G^{\\text{C}} + G^{\\text{D}} - G^{\\text{A}}-G^{\\text{B}}, \\tag{10.2} \\end{equation}\\] and replacing the absolute Gibbs free energies with the chemical potentials \\(\\mu_i\\), we obtain: \\[\\begin{equation} \\Delta_{\\text{rxn}} G = c \\mu_{\\text{C}} + d \\mu_{\\text{D}} - a \\mu_{\\text{A}}- b\\mu_{\\text{B}}. \\tag{10.3} \\end{equation}\\] Assuming the reaction is happening in the gas phase, we can then use eq. (9.22) to replace the chemical potentials with their value in the reaction mixture, as: \\[\\begin{equation} \\begin{aligned} \\mkern-60mu \\Delta_{\\text{rxn}} G =&amp; \\; c (\\mu_{\\text{C}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}+RT \\ln P_{\\text{C}}) + d (\\mu_{\\text{D}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}+RT \\ln P_{\\text{D}}) +\\\\ &amp; - a (\\mu_{\\text{A}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}+RT \\ln P_{\\text{A}}) - b (\\mu_{\\text{B}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}+RT \\ln P_{\\text{B}}) \\\\ =&amp; \\; \\underbrace{c \\mu_{\\text{C}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ d \\mu_{\\text{D}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}- a \\mu_{\\text{A}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}- b\\mu_{\\text{B}}^{-\\kern-6pt{\\ominus}\\kern-6pt-}}_{\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}} +RT \\ln \\frac{P_{\\text{C}}^c \\cdot P_{\\text{D}}^d}{P_{\\text{A}}^a \\cdot P_{\\text{B}}^b}. \\end{aligned} \\tag{10.4} \\end{equation}\\] We can define a new quantity called the reaction quotient as a function of the partial pressures of each substance:37 \\[\\begin{equation} Q_P = \\frac{P_{\\text{C}}^c \\cdot P_{\\text{D}}^d}{P_{\\text{A}}^a \\cdot P_{\\text{B}}^b}, \\tag{10.5} \\end{equation}\\] and we can then simply rewrite eq. (10.4) using eq. (10.5) as: \\[\\begin{equation} \\Delta_{\\text{rxn}} G = \\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ RT \\ln Q_P. \\tag{10.6} \\end{equation}\\] This equation tells us that the sign of \\(\\Delta_{\\text{rxn}} G\\) is influenced by the reaction quotient \\(Q_P\\). For a spontaneous reaction at the beginning, the partial pressures of the reactants are much higher than the partial pressures of the products, therefore \\(Q_P \\ll 1\\) and \\(\\Delta_{\\text{rxn}} G &lt; 0\\), as we expect. As the reaction proceeds, the partial pressures of the products will increase, while the partial pressures of the reactants will decrease. Consequently, both \\(Q_P\\) and \\(\\Delta_{\\text{rxn}} G\\) will increase. The reaction will completely stop when \\(\\Delta_{\\text{rxn}} G = 0\\), which is the chemical equilibrium point. At the reaction equilibrium: \\[\\begin{equation} \\Delta_{\\text{rxn}} G = 0 = \\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ RT \\ln K_P, \\tag{10.7} \\end{equation}\\] where we have defined a new quantity called equilibrium constant, as the value the reaction quotient assumes when the reaction reaches equilibrium, and we have denoted it with the symbol \\(K_P\\).38 From eq. (10.7) we can derive the following fundamental equation on the standard Gibbs free energy of reaction: \\[\\begin{equation} \\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}= - RT \\ln K_P. \\tag{10.8} \\end{equation}\\] To extend the concept of \\(K_P\\) beyond the four species in the prototypical reaction (10.1), we can use the product of a series symbol \\(\\left( \\prod_i \\right)\\), and write: \\[\\begin{equation} K_P=\\prod_i P_{i,\\text{eq}}^{\\nu_i}, \\tag{10.9} \\end{equation}\\] where \\(P_{i,\\text{eq}}\\) are the partial pressure of each species at equilibrium. Eq. (10.9) is in principle valid for ideal gases only. However, reaction involving ideal gases are pretty rare. As such, we can further extend the concept of equilibrium constant and write: \\[\\begin{equation} K_{\\text{eq}} =\\prod_i a_{i,\\text{eq}}^{\\nu_i}, \\tag{10.10} \\end{equation}\\] where we have replaced the partial pressure at equilibrium, \\(P_{i,\\text{eq}}\\), with a new concept introduced initially by Gilbert Newton Lewis (1875–1946),39 that he termed activity, and represented by the letter \\(a\\). For ideal gases, it is clear that \\(a_i=P_i/P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\). For non-ideal gases, the activity is equal to the fugacity \\(a_i=f_i/P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\), a concept that we will investigate in the next chapter. For pure liquids and solids, the activity is simply \\(a_i=1\\). For diluted solutions, the activity is equal to a measured concentration (such as, for example, the mole fraction \\(x_i\\) in the liquid phase, and \\(y_i\\) in the gas phase, or the molar concentration \\([i]/[i]^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) with \\([i]^{-\\kern-6pt{\\ominus}\\kern-6pt-}= 1\\;\\text[mol/L]\\)). Finally for concentrated solutions, the activity is related to the measured concentration via an activity coefficient. We will return to the concept of activity in chapter 14, when we will specifically deal with solutions. For now, it is interesting to use the activity to write the definition of the following two constants: \\[\\begin{equation} K_y =\\prod_i \\left( y_{i,\\text{eq}} \\right)^{\\nu_i} \\qquad \\qquad \\qquad \\qquad K_C =\\left( \\prod_i [i]_{\\text{eq}}/[i]^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\right)^{\\nu_i}, \\tag{10.11} \\end{equation}\\] which can then be related with \\(K_P\\) for a mixture of ideal gases using: \\[\\begin{equation} P_i = y_i P \\qquad \\qquad \\qquad P_i=\\frac{n_i}{V}RT=[i]RT, \\tag{10.12} \\end{equation}\\] which then results in: \\[\\begin{equation} K_P = K_y\\cdot \\left(\\frac{P}{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}}\\right)^{\\Delta \\nu} \\qquad \\qquad K_P = K_C \\left( \\frac{[i]^{-\\kern-6pt{\\ominus}\\kern-6pt-}RT}{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}} \\right)^{\\Delta \\nu}, \\tag{10.13} \\end{equation}\\] with \\(\\Delta \\nu =\\sum_i \\nu_i\\). Using the general equilibrium constant, \\(K_{\\text{eq}}\\), we can also rewrite the fundamental equation on \\(\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) that we derived in eq. (10.8) to be applicable at most conditions, as: \\[\\begin{equation} \\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}= - RT \\ln K_{\\text{eq}}, \\tag{10.14} \\end{equation}\\] and since \\(\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) depends on \\(T,P\\) and \\(\\{n_i\\}\\), it is useful to explore how \\(K_{\\text{eq}}\\) depends on those variables as well. 10.2 Temperature Dependence of \\(K_{\\text{eq}}\\) To study the temperature dependence of \\(K_{\\text{eq}}\\) we can use eq. (10.14) for the general equilibrium constant and write: \\[\\begin{equation} \\ln K_{\\text{eq}} = -\\frac{\\Delta G^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{RT}, \\tag{10.15} \\end{equation}\\] which we can then differentiate with respect to temperature at constant \\(P,\\{n_i\\}\\) on both sides: \\[\\begin{equation} \\left( \\frac{\\partial \\ln K_{\\text{eq}}}{\\partial T} \\right)_{P,\\{n_i\\}} = -\\frac{1}{R} \\left[ \\frac{\\partial \\left( \\frac{\\Delta G^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{T} \\right)}{\\partial T} \\right]_{P,\\{n_i\\}}, \\tag{10.16} \\end{equation}\\] and, using Gibbs-Helmholtz equation (eq. (9.9)) to simplify the left hand side, becomes: \\[\\begin{equation} \\left( \\frac{\\partial \\ln K_{\\text{eq}}}{\\partial T} \\right)_{P,\\{n_i\\}} = -\\frac{1}{R} \\left( -\\frac{\\Delta H^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{T^2} \\right) = \\frac{\\Delta H^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{RT^2}, \\tag{10.17} \\end{equation}\\] which gives the dependence of \\(\\ln K_{\\text{eq}}\\) on \\(T\\) that we were looking for. Eq. (10.17) is also called van ’t Hoff equation,40 and it is the mathematical expression of Le Chatelier’s principle. The simplest interpretation is as follows: For an exothermic reaction (\\(\\Delta H^{-\\kern-6pt{\\ominus}\\kern-6pt-}&lt; 0\\)): \\(K_{\\text{eq}}\\) will decrease as the temperature increases. For an endothermic reaction (\\(\\Delta H^{-\\kern-6pt{\\ominus}\\kern-6pt-}&gt; 0\\)): \\(K_{\\text{eq}}\\) will increase as the temperature increases. If we integrate the van ’t Hoff equation between two arbitrary points at constant \\(P\\), and assuming constant \\(\\Delta H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\), we obtain the following: \\[\\begin{equation} \\int_1^2 d \\ln K_{\\text{eq}} = \\frac{\\Delta H^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{R} \\int_1^2 \\frac{dT}{T^2}, \\tag{10.18} \\end{equation}\\] which leads to the linear equation: \\[\\begin{equation} \\ln K_{\\text{eq}}(2) = \\ln K_{\\text{eq}}(1) - \\frac{\\Delta H^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{R} \\left( \\frac{1}{T_2}-\\frac{1}{T_1} \\right). \\tag{10.19} \\end{equation}\\] which is the equation that produces the so-called van ’t Hoff plots, from which \\(\\Delta H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) can be experimentally determined: Figure 10.1: Van ’t Hoff Plots for an Endothermic (Left, Blue) and an Exothermic (Right, Red) Reactions at Constant P. 10.3 Pressure and Composition Dependence of \\(K_{\\text{eq}}\\) While \\(K_P\\) is independent of both temperature and number of moles for an ideal gas, the same is not necessarily true for the other equilibrium constants. \\[\\begin{equation} \\left( \\frac{\\partial K_P}{\\partial P} \\right)_{T,\\{n_i\\}} = 0 \\qquad \\qquad \\left( \\frac{\\partial K_P}{\\partial n_i} \\right)_{T,P} =0. \\tag{10.20} \\end{equation}\\] For example, it is easy to look at eq. (10.13) and determine that \\(K_y\\) usually depends on \\(P\\).41 Using Dalton’s Law, eq. (9.23), we can also notice that the equilibrium partial pressures of the reactants and products in a gas-phase reaction can be expressed in terms of their equilibrium mole fractions \\(y_i\\) and the total pressure \\(P\\). As such, we can use \\(K_y\\) to demonstrate that the equilibrium mole fractions will change when \\(P\\) changes,42 as it is demonstrated by the following exercise. Exercise 10.1 Calculate the mole fraction change for the dissociation of \\(\\mathrm{Cl}_{2(g)}\\) when the pressure is increased from \\(P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) to \\(P_f=2.5 \\;\\text{bar}\\) at constant \\(T=2\\,298\\;\\mathrm{K}\\), knowing that \\(\\Delta_{\\mathrm{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{Cl}_{(g)}} = 105.3 \\;\\text{kJ/mol}\\) and \\(\\Delta_{\\mathrm{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\mathrm{Cl}_{(g)}} = 121.3 \\;\\text{kJ/mol}\\), and remembering that both of these values are tabulated at \\(T=298\\;\\text{K}\\). Solution: Let’s consider the reaction: \\[ \\mathrm{Cl}_{2(g)} \\rightleftarrows 2 \\mathrm{Cl}_{(g)} \\] We can divide the exercise into two parts. In the first one, we will deal with calculating the equilibrium constant at \\(T=2\\,298\\;\\mathrm{K}\\) from the data at \\(T=298\\;\\mathrm{K}\\). In the second one, we will calculate the change in mole fraction when the pressure is increased from \\(P^{-\\kern-6pt{\\ominus}\\kern-6pt-}=1\\;\\text{bar}\\) to \\(P_f=2.5 \\;\\text{bar}\\). Let’s begin the first part by calculating \\(\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) and \\(\\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) from: \\[\\begin{equation} \\begin{aligned} \\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}&amp;= 2 \\Delta_{\\text{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\text{Cl}_{(g)}} - \\Delta_{\\text{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\text{Cl}_{2(g)}} \\\\ \\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}&amp;= 2 \\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\text{Cl}_{(g)}} - \\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\text{Cl}_{2(g)}}, \\end{aligned} \\end{equation}\\] and since \\(\\text{Cl}_{2(g)}\\) is an element in its most stable form at \\(T=298\\;\\mathrm{K}\\), its standard enthalpy and Gibbs free energy of formation are \\(\\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\text{Cl}_{2(g)}} = \\Delta_{\\text{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}_{\\text{Cl}_{2(g)}} = 0\\). Therefore:43 \\[\\begin{equation} \\begin{aligned} \\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}&amp;= 2 \\cdot 105.3 - 0 = 210.6 \\;\\text{kJ/mol} \\\\ \\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}&amp;= 2 \\cdot 121.3 - 0 = 242.6\\;\\text{kJ/mol}. \\end{aligned} \\end{equation}\\] Using eq. (10.8) to calculate \\(K_P (P^{-\\kern-6pt{\\ominus}\\kern-6pt-},298\\;\\text{K})\\), we obtain:44 \\[\\begin{equation} \\ln [ K_P (P^{-\\kern-6pt{\\ominus}\\kern-6pt-},298\\;\\text{K}) ] = \\frac{ - \\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{RT} = \\frac{-210.6\\times10^3}{8.31 \\cdot 298} = - 85.0. \\end{equation}\\] We can now use the integrated van ’t Hoff equation, eq. (10.19), to calculate \\(K_P\\) at \\(T=2\\,298\\;\\text{K}\\): \\[\\begin{equation} \\begin{aligned} \\ln [K_P (P^{-\\kern-6pt{\\ominus}\\kern-6pt-},&amp;2\\,298\\;\\text{K})] = \\ln [K_P (P^{-\\kern-6pt{\\ominus}\\kern-6pt-},298\\;\\text{K})] \\;+ \\\\ &amp;-\\frac{\\Delta_{\\text{rxn}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{R} \\left(\\frac{1}{2\\,298}-\\frac{1}{298} \\right), \\end{aligned} \\end{equation}\\] which becomes: \\[\\begin{equation} \\begin{aligned} \\ln [K_P (P^{-\\kern-6pt{\\ominus}\\kern-6pt-},&amp;2\\,298\\;\\text{K})] = - 85.0 \\;+\\\\&amp;-\\frac{242.6\\times 10^{3}}{8.31} \\left(\\frac{1}{2\\,298}-\\frac{1}{298} \\right) = 0.262\\;, \\end{aligned} \\end{equation}\\] which corresponds to: \\[\\begin{equation} K_P (P^{-\\kern-6pt{\\ominus}\\kern-6pt-},2\\,298\\;\\text{K}) = \\exp (0.262)=1.30. \\end{equation}\\] Let’s now move to the second part of the exercise, where we increase the pressure from \\(1\\;\\text{bar}\\) to \\(2.5\\;\\text{bar}\\) at constant \\(T=2\\,298\\;\\text{K}\\). We start by writing the definition of \\(K_P\\) and \\(K_y\\): \\[\\begin{equation} K_P=\\frac{P_\\mathrm{Cl_{(g)}}^2}{P_{\\mathrm{Cl}_{2(g)}}} \\qquad \\qquad K_y=\\frac{y_\\mathrm{Cl_{(g)}}^2}{y_{\\mathrm{Cl}_{2(g)}}}, \\end{equation}\\] and using eq. (10.13): \\[\\begin{equation} \\begin{aligned} \\Delta \\nu &amp;= 2 - 1 = 1 \\\\ K_P &amp;= K_y \\cdot \\frac{P}{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}} \\quad \\xrightarrow \\qquad K_y=K_P \\left( \\frac{P}{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}} \\right)^{-1}, \\end{aligned} \\end{equation}\\] we can calculate the initial \\(K_y\\) at \\(P_i=P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\), using: \\[\\begin{equation} K_y (P^{-\\kern-6pt{\\ominus}\\kern-6pt-},2\\,298\\;\\text{K}) = 1.30 =\\frac{1.30}{1}. \\end{equation}\\] and calculate the initial concentration of \\(\\mathrm{Cl}_{(g)}\\) and \\(\\mathrm{Cl}_{(g)}\\) at \\(P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\), recalling that \\(y_{\\mathrm{Cl}_{2(g)}}=1-y_{\\mathrm{Cl}_{(g)}}:\\) \\[\\begin{equation} K_y (P_i,2\\,298\\;\\text{K})=\\frac{\\left(y^i_{\\mathrm{Cl}_{(g)}}\\right)^2}{y^i_{\\mathrm{Cl}_{(g)}}} = 1.30. \\end{equation}\\] Solving the quadratic equation, we obtain one negative answer—which is unphysical—,45 and: \\[\\begin{equation} y_{\\mathrm{Cl}_{(g)}}^i= 0.662 \\quad \\xrightarrow \\qquad y_{\\mathrm{Cl}_{2(g)}}^i=1-0.662 = 0.338. \\end{equation}\\] At the end of the process, \\(P_f=2.5\\;\\text{bar}\\), and we obtain: \\[\\begin{equation} K_y (P_f,2\\,298\\;\\text{K}) = 0.520 = K_P \\frac{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}}{P_f} = \\frac{1.30}{2.5}, \\end{equation}\\] and, using the same technique used before to solve the quadratic equation: \\[\\begin{equation} K_y (P_f,2\\,298\\;\\text{K})=\\frac{\\left(y^f_{\\mathrm{Cl}_{(g)}}\\right)^2}{y^f_{\\mathrm{Cl}_{(g)}}} = 0.520, \\end{equation}\\] gives: \\[\\begin{equation} y_{\\mathrm{Cl}_{(g)}}^f=0.507 \\quad \\xrightarrow \\qquad y_{\\mathrm{Cl}_{2(g)}}^i=1-0.507 = 0.493. \\end{equation}\\] To summarize, when we increase the pressure from \\(1\\;\\text{bar}\\) to \\(2.5\\;\\text{bar}\\) at \\(T=2\\,298\\;\\text{K}\\), the equilibrium constant in terms of the mole fraction decreases from \\(K_y(P^{-\\kern-6pt{\\ominus}\\kern-6pt-},2\\,298\\;\\text{K})=1.30\\) to \\(K_y(P_f=2.5\\;\\text{bar},2\\,298\\;\\text{K})=0.520\\). This reduction is causing a shift of the equilibrium towards the reactants, with the concentration of \\(\\text{Cl}_{2(g)}\\) increasing from \\(y_{\\text{Cl}_{2(g)}}^i = 0.338\\) to \\(y_{\\text{Cl}_{2(g)}}^f = 0.493\\) and the concentration of \\(\\text{Cl}_{(g)}\\) decreasing from \\(y_{\\text{Cl}_{2(g)}}^i = 0.662\\) to \\(y_{\\text{Cl}_{(g)}}^f = 0.507\\). The dependence of \\(K_{\\text{eq}}\\) on \\(P\\) highlighted above is another mathematical expression of Le Chatelier’s principle, on this occasion, for changes in pressure. The interpretation For a reaction happening in the gas phase is as follows: If the total pressure increases, the equilibrium will shift towards the side of the chemical equation that contains the smallest total amount of moles (the equilibrium in exercise 10.1 shifts toward the reactant). Notice that since we used eq. (9.21) to derive the reaction quotient, the partial pressures inside it are always dimensionless since they are divided by \\(P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\).↩︎ The subscript \\(P\\) refers to the fact that the equilibrium constant is measured in terms of partial pressures.↩︎ Gilber Lewis is the same scientist that invented the concept of Lewis Structures.↩︎ named after Jacobus Henricus “Henry” van ’t Hoff Jr. (1852–1911).↩︎ \\(K_y\\) becomes independent of \\(P\\) in the particular case where \\(\\Delta \\nu=0\\), i.e., for reactions where the total number of moles of reactants is the same as the total number of moles of the products.↩︎ Keep in mind that \\(K_P\\) will not change.↩︎ Notice how a positive \\(\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) indicates that the dissociation of \\(\\mathrm{CL}_{2(g)}\\) is non-spontaneous at \\(T=298\\;\\text{K}\\) and \\(P=1\\;\\text{bar}\\). As such, we should expect a very small value for \\(K_P\\).↩︎ The results corresponds to \\(K_P=1.2\\times 10^{-37}\\), an incredible miniscule number, as we should expect given the data of \\(\\Delta_{\\text{rxn}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\).↩︎ Concentration cannot be negative.↩︎ "],
["RealGases.html", "11 Ideal and Non-Ideal Gases 11.1 The Ideal Gas Equation 11.2 Behaviors of Non-Ideal Gases 11.3 Critical Phenomena 11.4 Fugacity", " 11 Ideal and Non-Ideal Gases 11.1 The Ideal Gas Equation The concept of an ideal gas is a theoretical construct that allows for straightforward treatment and interpretation of gases’ behavior. As such, the ideal gas is a simplified model that we use to understand nature, and it does not correspond to any real system. The following two assumptions define the ideal gas model: Definition 11.1 The particles that compose an ideal gas do not occupy any volume. The particles that compose an ideal gas do not interact with each other. Because of its simplicity, the ideal gas model has been the historical foundation of thermodynamics and of science in general. The first studies of the ideal gas behavior date back to the seventeenth century, and the scientists that performed them are among the founders of modern science. 11.1.1 Boyle’s Law In 1662 Robert Boyle (1627–1691) found that the pressure and the volume of an ideal gas are inversely related at constant temperature. Boyle’s Law has the following mathematical description: \\[\\begin{equation} P\\propto\\frac{1}{V}\\quad\\text{at const.}\\;T, \\tag{11.1} \\end{equation}\\] or, in other terms: \\[\\begin{equation} PV=k_1\\quad\\text{at const.}\\;T, \\tag{11.2} \\end{equation}\\] which results in the familiar \\(PV\\) plots of Figure 11.1. As we already discussed in chapter 2, each of the curves in Figure 11.1 is obtained at constant temperature, and it is therefore called “isotherm.” Figure 11.1: PV-Diagram of an ideal Gas. 11.1.2 Charles’s and Gay-Lussac’s Laws It took scientists more than a century to expand Boyle’s work and study the relationship between volume and temperature. In 1787 Jacques Alexandre César Charles (1746–1823) wrote the relationship known as Charles’s Law: \\[\\begin{equation} V\\propto T\\quad\\text{at const.}\\;P, \\tag{11.3} \\end{equation}\\] or, in other terms: \\[\\begin{equation} V=k_2 T\\quad\\text{at const.}\\;P, \\tag{11.4} \\end{equation}\\] which results in the plots of Figure 11.2. Each of the curves is obtained at constant pressure, and it is termed “isobar.” Figure 11.2: VT-Diagram of an ideal Gas. The interesting thing about isobars is that each line seems to converge to a specific point along the temperature line when we extrapolate them to \\(V\\rightarrow 0\\). This led to the introduction of the absolute temperature scale, suggesting that the temperature will never get smaller than \\(-273.15^\\circ\\mathrm{C}\\). It took an additional 21 years to write a formal relationship between pressure and temperature. The following relationships were proposed by Joseph Louis Gay-Lussac (1778–1850) in 1808: \\[\\begin{equation} P\\propto T\\quad\\text{at const.}\\;V, \\tag{11.5} \\end{equation}\\] or, in other terms: \\[\\begin{equation} P=k_3 T\\quad\\text{at const.}\\;V, \\tag{11.6} \\end{equation}\\] which results in the plots of Figure 11.3. Each of the curves is obtained at constant volume, and it is termed “isochor.” Figure 11.3: PT-Diagram of an ideal Gas. 11.1.3 Avogadro’s Law Ten years later, Amedeo Avogadro (1776–1856) discovered a seemingly unrelated principle by studying the composition of matter. His Avogadro’s Law encodes the relationship between the number of moles in an ideal gas and its volume as: \\[\\begin{equation} V\\propto n\\quad\\text{at const.}\\;P,T, \\tag{11.7} \\end{equation}\\] or in other terms: \\[\\begin{equation} V=k_4 n\\quad\\text{at const.}\\;P,T, \\tag{11.8} \\end{equation}\\] 11.1.4 The ideal gas Law Despite all of the ingredients being available for more than 20 years, it’s only in 1834 that Benoît Paul Émile Clapeyron (1799–1864) was finally able to combine them into what is now known as the ideal gas Law. Using the same formulas obtained above, we can write: \\[\\begin{equation} PV=\\underbrace{k_3 T}_{\\text{from Gay-Lussac&#39;s}} \\cdot \\underbrace{k_4 n,}_{\\text{from Avogadro&#39;s}} \\tag{11.9} \\end{equation}\\] which by renaming the product of the two constants \\(k_3\\) and \\(k_4\\) as \\(R\\), becomes: \\[\\begin{equation} PV=nRT \\tag{11.10} \\end{equation}\\] The value of the constant \\(R\\) can be determined experimentally by measuring the volume that 1 mol of an ideal gas occupies at a constant temperature (e.g., at \\(T=0^\\circ\\mathrm{C}\\)) and a constant pressure (e.g., atmospheric pressure \\(P=1\\;\\mathrm{atm}\\)). At those conditions, the volume is measured at 22.4 L, resulting in the following value of \\(R\\): \\[\\begin{equation} R=\\frac{VP}{nT}=\\frac{22.4 \\cdot 1}{1 \\cdot 273}=0.082 \\;\\frac{\\text{L atm}}{\\text{mol K}}, \\tag{11.11} \\end{equation}\\] which a simple conversion to SI units transforms into: \\[\\begin{equation} R=8.31\\;\\frac{\\text{J}}{\\text{mol K}}. \\tag{11.12} \\end{equation}\\] 11.2 Behaviors of Non-Ideal Gases Non-ideal gases (sometimes also referred to as “real gases”), do not behave as ideal gases because at least one of the assumptions in definition 11.1 is violated. What characterizes non-ideal gases is that there is no unique equation that we can use to describe their behavior. For this reason, we have a plethora of several experimental models, none of which is superior to the other. The van der Waals (vdW) equation is the only model that we will analyze in detail because of its simple interpretation. However, it is far from universal, and for several non-ideal gases, it is severely inaccurate. Other popular non-ideal gases equations are the Clausius equation, the virial equation, the Redlich–Kwong equation and several others.46 11.2.1 The van der Waals equation One of the simplest empirical equation that describes non-ideal gases was obtained in 1873 by Johannes Diderik van der Waals (1837–1923). The vdW equation includes two empirical parameters (\\(a\\) and \\(b\\)) with different values for different non-ideal gases. Each of the parameters corresponds to a correction for the breaking of one of the two conditions that define the ideal gas behavior (definition 11.1). The vdW equation is obtained from the ideal gas equation performing the following simple substitutions: \\[\\begin{equation} \\begin{aligned} P &amp; \\;\\rightarrow\\;\\left( P + \\frac{a}{\\overline{V}^2} \\right)\\\\ \\overline{V} &amp; \\;\\rightarrow\\;\\left( \\overline{V} - b\\right),\\\\ \\end{aligned} \\tag{11.13} \\end{equation}\\] which results in: \\[\\begin{equation} \\begin{aligned} P\\overline{V} &amp;=RT \\; \\rightarrow \\; \\left( P + \\frac{a}{\\overline{V}^2} \\right)\\left( \\overline{V} - b\\right)=RT\\\\ P &amp;=\\frac{RT}{\\overline{V} - b}-\\frac{a}{\\overline{V}^2}. \\end{aligned} \\tag{11.14} \\end{equation}\\] The parameter \\(a\\) accounts for the presence of intermolecular interactions, while the parameter \\(b\\) accounts for the non-negligible volume of the gas molecules. Despite the parameters having simple interpretations, their values for each gas must be determined experimentally. Values for these parameters for some significant non-ideal gas are reported below: \\(a \\left[ \\frac{\\mathrm{L}^2\\mathrm{bar}}{\\mathrm{mol}^2} \\right]\\) \\(b \\left[ \\frac{\\mathrm{L}}{\\mathrm{mol}} \\right]\\) Ammonia 4.225 0.0371 Argon 1.355 0.03201 Carbon dioxide 3.640 0.04267 Carbon monoxide 1.505 0.03985 Chlorine 6.579 0.05622 Freon 10.78 0.0998 Helium 0.0346 0.0238 Hydrogen 0.2476 0.02661 Mercury 8.200 0.01696 Methane 2.283 0.04278 Neon 0.2135 0.01709 Nitrogen 1.370 0.0387 Oxygen 1.382 0.03186 Radon 6.601 0.06239 Xenon 4.250 0.05105 11.2.2 Joule–Thomson effect Figure 11.4: The Joule–Thomson Experiment. We have already met William Thomson, also known as Lord Kelvin, and his seminal work on the second law of thermodynamics. In conjunction with that work, Thomson is famous for developing a sensitive method for measuring the temperature changes related to the expansion of a gas. These experiments improved on the earlier work by James Joule, and Lord Kelvin’s improved instrument depicted in Figure 11.4 is named the Joule–Thomson apparatus. The apparatus is composed of two chambers, each with its own mobile piston. The chambers are connected via a valve or a porous plug. The entire equipment is also thermally isolated from the surroundings. This instrument is a more sensitive version of the Joule expansion apparatus that we already described in section 3 (compare with Figure 3.1). Thomson realized that a gas flowing through an obstruction experience a drop in pressure. If the entire apparatus is insulated, it will not exchange heat with its surroundings (\\(Q=0\\)), and each transformation will happen at adiabatic conditions. Let’s consider an initial condition with 1 mol of gas in the left chamber, occupying a volume \\(V_l\\), and a completely closed right chamber, for which \\(V_r^i=0\\). After the process completes, the volume of the right chamber will reduce to \\(V_l^f=0\\), while the volume of the right chamber will be \\(V_r\\). Using the first law of thermodynamics, we can write: \\[\\begin{equation} \\Delta U=U_r-U_l=\\underbrace{Q}_{=0}+W=W_l+W_r, \\tag{11.15} \\end{equation}\\] with: \\[\\begin{equation} \\begin{aligned} W_l &amp;=-\\int_{V_l}^0 P_l dV = P_l V_l\\\\ W_r &amp;=-\\int_0^{V_r} P_r dV = - P_r V_r. \\end{aligned} \\tag{11.16} \\end{equation}\\] Replacing (11.16) into eq. (11.15), results in: \\[\\begin{equation} \\begin{aligned} U_r-U_l &amp;=P_l V_l-P_r V_r \\\\ \\underbrace{U_r+P_r V_r}_{H_r} &amp;= \\underbrace{U_l + P_l V_l}_{H_l}, \\end{aligned} \\tag{11.17} \\end{equation}\\] which, replacing the definition of enthalpy \\(H=U+PV\\), we obtain: \\[\\begin{equation} \\begin{aligned} H_r &amp;=H_l \\\\ \\Delta H &amp;=0, \\end{aligned} \\tag{11.18} \\end{equation}\\] or, in other words, the process is isenthalpic. Using the total differential of \\(H\\): \\[\\begin{equation} dH=\\left(\\frac{\\partial H}{\\partial T} \\right)_P dT + \\left(\\frac{\\partial H}{\\partial P} \\right)_T dP = C_P dT + \\left(\\frac{\\partial H}{\\partial P} \\right)_T dP, \\tag{11.19} \\end{equation}\\] we obtain: \\[\\begin{equation} \\Delta H=\\int dH = \\int C_P dT + \\int \\left(\\frac{\\partial H}{\\partial P} \\right)_T dP =0, \\tag{11.20} \\end{equation}\\] or, in purely differential form: \\[\\begin{equation} dH = C_P dT + \\left(\\frac{\\partial H}{\\partial P} \\right)_T dP =0, \\tag{11.21} \\end{equation}\\] From eq. (11.21) we can define a new coefficient, called the Joule–Thomson coefficient, \\(\\mu_{\\mathrm{JT}}\\), that measures the rate of change of temperature of a gas with respect to pressure in the Joule–Thomson process: \\[\\begin{equation} \\mu_{\\mathrm{JT}}=\\left( \\frac{\\partial T}{\\partial P} \\right)_H=-\\frac{1}{C_P} \\left( \\frac{\\partial H}{\\partial T} \\right)_P \\tag{11.22} \\end{equation}\\] The value of \\(\\mu_{\\mathrm{JT}}\\) depends on the type of gas, the temperature and pressure before expansion, and the heat capacity at constant pressure of the gas. The temperature at which \\(\\mu_{\\mathrm{JT}}\\) changes sign is called the “Joule–Thomson inversion temperature.” Since the pressure decreases during an expansion, \\(\\partial P\\) is negative by definition, and the following possibilities are available for \\(\\mu_{\\mathrm{JT}}\\): Gas temperature: \\(\\partial P\\) \\(\\mu_{\\mathrm{JT}}\\) \\(\\partial T\\) The gas will: Below the inversion temperature – + – cool Above the inversion temperature – – + warm For example, helium has a very low Joule–Thomson inversion temperatures at standard pressure \\((T=45\\;\\text{K})\\), and it warms when expanded at constant enthalpy at typical room temperatures. The only other gases that have standard inversion temperature lower than room temperature are hydrogen and neon. On the other hand, nitrogen and oxygen have high inversion temperatures (\\(T=621\\;\\text{K}\\) and \\(T=764\\;\\text{K}\\), respectively), and they both cool when expanded at room temperature. Therefore, it is possible to use the Joule–Thomson effect in refrigeration processes such as air conditioning.47 As we already discussed in chapter 3, the temperature of an ideal gases stays constant in an adiabatic expansion, therefore its Joule–Thomson coefficient is always equal to zero. 11.3 Critical Phenomena 11.3.1 Compressibility factors The compressibility factor is a correction coefficient that describes the deviation of a real gas from ideal gas behaviour. It is usually represented with the symbol \\(z\\), and is calculated as: \\[\\begin{equation} z=\\frac{\\overline{V}}{\\overline{V}_{\\text{ideal}}} = \\frac{P \\overline{V}}{RT}. \\tag{11.23} \\end{equation}\\] It is evident from eq. (11.23) that the compressibility factor is dependent on the pressure, and for an ideal gas \\(z=1\\) always. For a non-ideal gas at any given pressure, \\(z\\) can be higher or lower than one, separating the behavior of non-ideal gases into two possibilities. The dependence of the compressibility factor against pressure is represented for \\(\\mathrm{H}_2\\) and \\(\\mathrm{CO}_2\\) in Figure 11.5. Figure 11.5: Non-Ideal Gases Behaviors. The two types of possible behaviors are differentiated based on the compressibility factor at \\(P\\rightarrow 0\\). To analyze these situations we can use the vdW equation to calculate the compressibility factor as: \\[\\begin{equation} z= \\frac{\\overline{V}}{RT} \\left( \\frac{RT}{\\overline{V}-b} -\\frac{a}{\\overline{V}^2} \\right). \\tag{11.24} \\end{equation}\\] and then we can differentiate this equation at constant temperature with respect to changes in the pressure near \\(P=0\\), to obtain: \\[\\begin{equation} \\left. \\left( \\frac{\\partial z}{\\partial P}\\right)_T \\right|_{P=0} = \\frac{1}{RT} \\left( b -\\frac{a}{RT} \\right). \\tag{11.25} \\end{equation}\\] which is then interpreted as follows: Type I gases: \\(b&gt;\\frac{a}{RT} \\; \\Rightarrow \\; \\frac{\\partial z}{\\partial P} &gt; 0\\) molecular size dominates (\\(\\mathrm{H}_2-\\)like behavior). Type II gases: \\(b&lt;\\frac{a}{RT} \\; \\Rightarrow \\; \\frac{\\partial z}{\\partial P} &lt; 0\\) attractive forces dominates (\\(\\mathrm{CO}_2-\\)like behavior). The dependence of the compressibility factor as a function of temperature (Figure 11.6) results in different plots for each of the two types of behavior. Figure 11.6: Temperature Dependence of the Compressibility Factor. Both type I and type II non-ideal gases will approach the ideal gas behavior as \\(T\\rightarrow \\infty\\), because \\(\\frac{1}{RT}\\rightarrow 0\\) as \\(T\\rightarrow \\infty\\). For type II gases, there are three interesting situations: At low \\(T\\): \\(b&lt;\\frac{a}{RT} \\; \\Rightarrow \\; \\frac{\\partial z}{\\partial P} &lt; 0,\\) which is the behavior described above. At high \\(T\\): \\(b&gt;\\frac{a}{RT} \\; \\Rightarrow \\; \\frac{\\partial z}{\\partial P} &gt; 0,\\) which is the same behavior of type I gases. At a very specific temperature, inversion will occur (i.e., at \\(T=713 \\; \\mathrm{K}\\) for \\(\\mathrm{CO}_2\\)). This temperature is called the Boyle temperature, \\(T_{\\mathrm{B}}\\), and is the temperature at which the attractive and repulsive forces balance out. It can be calculated from the vdW equation, since \\(b-\\frac{a}{RT_{\\mathrm{B}}}=0 \\; \\Rightarrow \\; T_{\\mathrm{B}}=\\frac{a}{bR}.\\) At the Boyle’s temperature a type II gas shows ideal gas behavior over a large range of pressure. 11.3.2 Phase diagram of a non-ideal gas Figure 11.7: The Pressure–Volume Diagram of a Non-Ideal Gas. Let’s now turn our attention to the \\(PV\\) phase diagram of a non-ideal gas, reported in Figure 11.7. We can start the analysis from an isotherm at a high temperature. Since every gas will behave as an ideal gas at those conditions, the corresponding isotherms will look similar to those of an ideal gas (\\(T_5\\) and \\(T_4\\) in Figure 11.7). Lowering the temperature, we start to see the deviation from ideality getting more prominent (\\(T_3\\) in Figure 11.7) until we reach a particular temperature called the critical temperature, \\(T_c\\). Definition 11.2 Critical Temperature: The temperature above which no appearance of a second phase is observed, regardless of how high the pressure becomes. At the critical temperature and below, the gas liquefies when the pressure is increased. For this reason, the liquefaction of a gas is called a critical phenomenon. The critical temperature is the coordinate of a unique point, called the critical point, that can be visualized in the three-dimensional \\(T,P,V\\) diagram of each gas (Figure 11.848). Figure 11.8: The three-dimensional diagram. The critical point has coordinates \\({T_c,P_c, \\overline{V}_c}\\). These critical coordinates can be determined from the vdW equation at \\(T_c\\), as: \\[\\begin{equation} T_c=\\frac{8a}{27Rb} \\qquad P_c=\\frac{a}{27b^2} \\qquad \\overline{V}_c=3b, \\tag{11.26} \\end{equation}\\] These relations are used, in practice, to determine the vdW constants \\(a,b\\) from the experimentally measured critical isotherms. The critical compressibility factor, \\(z_c\\), is predicted from the vdW equation at: \\[\\begin{equation} z_c=\\frac{P_c \\overline{V}_c}{R T_c}=\\left( \\frac{a}{27b^2} \\right) \\left( \\frac{3b}{R} \\right) \\left( \\frac{27Rb}{8a} \\right) = \\frac{3}{8} = 0.375, \\tag{11.27} \\end{equation}\\] a value that is independent of the gas. Experimentally measured values of \\(z_c\\) for different non-ideal gases are in the range of 0.2–0.3. These values can be used to infer the accuracy of the vdW equation for each non-ideal gas. Since the experimental \\(z_c\\) is usually lower than the one calculated from the vdW equation, we can deduce that the vdW equation overestimates the critical molar volume. Notice how slicing the \\(PT\\overline{V}\\) diagram at constant \\(T\\) results in the \\(PV\\) diagram that we reported in Figure 11.8. On the other hand, slicing the \\(PT\\overline{V}\\) diagram at constant \\(P\\) results in the \\(PT\\) diagram that we will examine in detail in the next chapter. 11.4 Fugacity The chemical potential of a pure ideal gas can be calculated using eq. (9.21). Since we are not interested in mixture, we can drop the asterisk in \\(\\mu^*\\), and rewrite eq. (9.21) as: \\[\\begin{equation} \\mu_{\\text{ideal}} = \\mu^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ RT \\ln \\frac{P}{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}}. \\tag{11.28} \\end{equation}\\] For a non-ideal gas, the pressure cannot be used in eq. (11.28) because each gas response to changes in pressure is not universal. We can, however, define a new variable to replace the pressure in eq. (11.28) and call it fugacity (\\(f\\)). Definition 11.3 Fugacity: The effective pressure of a non-ideal gas that corresponds to the pressure of an ideal gas with the same temperature and chemical potential of the non-ideal one. Eq. (11.28) then becomes: \\[\\begin{equation} \\mu_{\\text{non-ideal}} = \\mu^{-\\kern-6pt{\\ominus}\\kern-6pt-}+ RT \\ln \\frac{f}{P^{-\\kern-6pt{\\ominus}\\kern-6pt-}}. \\tag{11.29} \\end{equation}\\] Since the chemical potential of a gas \\(\\mu\\) is equal to the standard chemical potential \\(\\mu^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) when \\(P=P^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\), it is easy to use eq. (11.29) to demonstrate that: \\[\\begin{equation} \\lim_{P\\rightarrow 0} \\frac{f}{P} = 1, \\tag{11.30} \\end{equation}\\] in other words, any non-ideal gas will approach the ideal gas behavior as \\(P\\rightarrow 0\\). This condition, in conjunction with the \\(T\\rightarrow \\infty\\) behavior obtained in the previous section, results in the following statement: The highest chances for any gas to behave ideally happen at high temperature and low pressure. We can now return our attention to the definition of fugacity. Remembering that the chemical potential is the molar Gibbs free energy of a substance, we can write: \\[\\begin{equation} d \\mu_{\\text{ideal}} = \\overline{V}_{\\text{ideal}}dP, \\tag{11.31} \\end{equation}\\] and: \\[\\begin{equation} d \\mu_{\\text{non-ideal}} = \\overline{V}_{\\text{non-ideal}}dP, \\tag{11.32} \\end{equation}\\] Subtracting eq. (11.31) from eq. (11.32), we obtain: \\[\\begin{equation} d \\mu_{\\text{non-ideal}}-d \\mu_{\\text{ideal}} = \\left(\\overline{V}_{\\text{non-ideal}}-\\overline{V}_{\\text{ideal}} \\right) dP, \\tag{11.33} \\end{equation}\\] which we can then integrate between \\(0\\) and \\(P\\): \\[\\begin{equation} \\mu_{\\text{non-ideal}}-\\mu_{\\text{ideal}} = \\int_0^P \\left(\\overline{V}_{\\text{non-ideal}}-\\overline{V}_{\\text{ideal}} \\right) dP. \\tag{11.34} \\end{equation}\\] Using eqs. (11.28) and (11.29) we can then replace the definition of chemical potentials, resulting into: \\[\\begin{equation} \\ln f - \\ln P = \\frac{1}{RT} \\int_0^P \\left(\\overline{V}_{\\text{non-ideal}} - \\overline{V}_{\\text{ideal}} \\right) dP, \\tag{11.35} \\end{equation}\\] which gives us a mathematical definition of the fugacity, as: \\[\\begin{equation} f = P \\cdot \\underbrace{\\exp\\left[ \\frac{1}{RT} \\int_0^P \\left(\\overline{V}_{\\text{non-ideal}}-\\overline{V}_{\\text{ideal}} \\right) dP \\right]}_{\\text{fugacity coefficient, }\\phi(T,P)}. \\tag{11.36} \\end{equation}\\] The exponential term in eq. (11.36) is complicated to write, but it can be interpreted as a coefficient—unique to each non-ideal gas—that can be measured experimentally. Such coefficients are dependent on pressure and temperature and are called the fugacity coefficients. Using letter \\(\\phi\\) to represent the fugacity coefficient, we can rewrite eq. (11.36) as: \\[\\begin{equation} f = \\phi P, \\tag{11.37} \\end{equation}\\] which gives us a straightforward interpretation of the fugacity as an effective pressure. As such, the fugacity will have the same unit as the pressure, while the fugacity coefficients will be adimensional. As we already saw in chapter 10, the fugacity can be used to replace the pressure in the definition of the equilibrium constant for reactions that involve non-ideal gases. The new constant is usually called \\(K_f\\), and is obtained from: \\[\\begin{equation} K_f=\\prod_i f_{i,\\text{eq}}^{\\nu_i} = K_P \\prod_i \\phi_{i}^{\\nu_i}. \\tag{11.38} \\end{equation}\\] For more information on empirical equations for non-ideal gases see this Wikipedia page.↩︎ Nitrogen and oxygen are the two most abundant gases in the air. A sequence of Joule–Thomson expansions are also used for the industrial liquefaction of air.↩︎ This diagram is taken from Wikipedia and distributed under CC-BY-SA license.↩︎ "],
["PhaseEquilibrium.html", "12 Phase Equilibrium 12.1 Phase Stability 12.2 Gibbs Phase Rule 12.3 \\(PT\\) Phase Diagrams 12.4 The Clausius–Clapeyron Equation", " 12 Phase Equilibrium 12.1 Phase Stability We have already encountered the gas, liquid, and solid phases and already discussed some of their properties. These terms are intuitive since these are the three most common states of matter.49 For this reason, we have previously used the terms without the necessity of formally defining their meaning. However, a formal definition of “phase” is necessary to discuss several concepts in this chapter and the following ones: Definition 12.1 Phase: A region of the system with homogeneous chemical composition and physical state. Let’s now use the total differential of the chemical potential and the definition of molar Gibbs free energy for one component: \\[\\begin{equation} \\begin{aligned} d\\mu &amp;= \\left( \\frac{\\partial \\mu}{\\partial T} \\right)_P dT + \\left( \\frac{\\partial \\mu}{\\partial P} \\right)_T dP \\\\ d\\mu &amp;= -SdT+\\overline{V}dP, \\end{aligned} \\tag{12.1} \\end{equation}\\] to write: \\[\\begin{equation} \\left( \\frac{\\partial \\mu}{\\partial T} \\right)_P=-S \\qquad \\left( \\frac{\\partial \\mu}{\\partial P} \\right)_T =\\overline{V}. \\tag{12.2} \\end{equation}\\] We can use these definitions to study the dependence of the chemical potential with respect to changes in pressure and temperature. If we plot \\(\\mu\\) as a function of \\(T\\) using the first coefficient in eq. (12.2), we obtain the diagram in Figure 12.1. The diagram presents three curves, each corresponding to one of the three most common states of matter – solid, liquid, and gas. As we saw in several previous chapters, the entropy of a phase is almost constant with respect to temperature,50 and therefore the three curves are essentially straight, with negative angular coefficients \\(-S\\). This also explains why the solid phase has a basically flat line since, according to the third law, the entropy of a perfect solid is zero and close to zero if the solid is not perfect. The difference between the three lines’ angular coefficients is explained by the fact that each of these states has a different value of entropy: \\[\\begin{equation} \\left( \\frac{\\partial \\mu_{\\text{solid}}}{\\partial T} \\right)_P =-S_{\\text{s}} \\qquad \\left( \\frac{\\partial \\mu_{\\text{liquid}}}{\\partial T} \\right)_P =-S_{\\text{l}} \\qquad \\left( \\frac{\\partial \\mu_{\\text{gas}}}{\\partial T} \\right)_P =-S_{\\text{g}}, \\tag{12.3} \\end{equation}\\] and since the entropy of a gas is always bigger than the entropy of a liquid, which in turn, is yet bigger than the entropy of a solid (\\(S_{\\text{g}} \\gg S_{\\text{l}}&gt;S_{\\text{s}}\\)), we obtain three lines with different angular coefficients that intersect each other. At each temperature, the phase with the lowest chemical potential will be the most stable (see red segments in Figure 12.1). At each intersection between two lines, the two phases have the same chemical potential, representing the temperature at which they coexist. This temperature is the temperature at which the phase change happens. Recalling from general chemistry, at the junction between the solid and the liquid lines, the fusion (fus) process occurs, and the corresponding temperature is called the melting point \\(T_{\\text{m}}\\). At the junction between the liquid and the gas lines, the vaporization (vap) process happens, and the corresponding temperature is called the boiling point \\(T_{\\text{b}}\\). Depending on the substance and the pressure at which the process happens, the solid line might intersect the gas line before the liquid line. When that occurs, the liquid phase is never observed, and only the sublimation (subl) process happens at the sublimation point \\(T_{\\text{subl}}\\). Figure 12.1: Dependence of the Chemical Potentials of Solid, Liquid, and Gas Phases on Temperature at Constant Pressure. The effects of pressure on this diagram can be studied using the second coefficient in eq. (12.2). For the majority of substances, \\(\\overline{V}_{\\text{g}} \\gg \\overline{V}_{\\text{l}} &gt; \\overline{V}_{\\text{s}}\\), hence the curves will shift to lower values when the pressure is reduced, as in Figure 12.2. Notice also that since \\(\\overline{V}_{\\text{l}} \\cong \\overline{V}_{\\text{s}}\\), the shifts for both the solid and liquid lines is much smaller than the shift for the gas line. These shifts also translate to different values of the junctions, which means the phase changes will occur at different temperatures. Therefore both the melting point and the boiling point in general increase when pressure is increased (and vice versa). Notice how the change for the melting point is always much smaller than the change for the boiling point. Water is a noticeable exception to these trend because \\(\\overline{V}_{\\mathrm{H}_2\\mathrm{O,l}} &lt; \\overline{V}_{\\text{ice}}\\). This explains the experimental observation that increasing the pressure on ice causes the ice to melt51 Figure 12.2: Effect of Pressure on the Chemical Potential Diagram. Considering the intersections between two lines, two phases are in equilibrium with each other at each of these points. Therefore their chemical potentials must be equal: For two or more phases to be in equilibrium, their chemical potential must be equal: \\[\\begin{equation} \\mu_{\\alpha} = \\mu_{\\beta}. \\tag{12.4} \\end{equation}\\] If we now change either the temperature or the pressure, the location of the intersection will be shifted (see again Figure 12.2 and the discussion above). For infinitesimal changes in variables, the new location will be: \\[\\begin{equation} \\mu_{\\alpha} + d\\mu_{\\alpha}= \\mu_{\\beta}+d\\mu_{\\beta}, \\tag{12.5} \\end{equation}\\] which using eq. (12.4), simply becomes: \\[\\begin{equation} d\\mu_{\\alpha}= d\\mu_{\\beta}. \\tag{12.6} \\end{equation}\\] Replacing the differential with the definition of chemical potential in eq. (12.1), we obtain: \\[\\begin{equation} \\begin{aligned} -S_{\\alpha}dT+\\overline{V}_{\\alpha} &amp;= -S_{\\beta}dT+\\overline{V}_{\\beta} \\\\ \\underbrace{\\left(S_{\\beta}-S_{\\alpha}\\right)}_{\\Delta S} dT &amp;= \\underbrace{\\left( \\overline{V}_{\\beta}-\\overline{V}_{\\alpha}\\right)}_{\\Delta \\overline{V}}, \\end{aligned} \\tag{12.7} \\end{equation}\\] which can be rearranged into: \\[\\begin{equation} \\frac{dP}{dT}=\\frac{\\Delta S}{\\Delta \\overline{V}}. \\tag{12.8} \\end{equation}\\] This equation is known as the Clapeyron equation, and it is the mathematical relation at the basis of the pressure-temperature phase diagrams. Plotting the results of eq. (12.8) on a \\(PT\\) phase diagram for common substances results in three lines representing the equilibrium between two different phases. These diagrams are useful to study the relationship between the phases of a substance. 12.2 Gibbs Phase Rule In chapter 1, we have already seen that the number of independent variables required to describe an ideal gas is two. This number was derived by counting the total number of variables \\((3: P,\\overline{V},T)\\), and reduce it by one because the ideal gas law constrains the value of one of them, once the other two are fixed. For a generic system potentially containing more than one chemical substance in several different phases, however, the number of independent variables can be different than two. For a system composed of \\(c\\) components (chemical substances) and \\(p\\) phases, the number of independent variables, \\(f\\), is given by the Gibbs phase rule: \\[\\begin{equation} f=c-p+2. \\tag{12.9} \\end{equation}\\] The Gibbs phase rule derives from the fact that different phases are in equilibrium with each other at some conditions, resulting in the reduction of the number of independent variables at those conditions. More rigorously, when two phases are in thermodynamic equilibrium, their chemical potentials are equal (see eq. (12.4)). For each equality, the number of independent variables—also called the number of degrees of freedom—is reduced by one. For example, the chemical potentials of the liquid and its vapor depend on both \\(T\\) and \\(P\\). But when these phases are in equilibrium with each other, their chemical potentials must be equal. If either the pressure or the temperature is fixed, the other variable will be uniquely determined by the equality relation. In other terms, when a liquid is in equilibrium with its vapor at a given pressure, the temperature is determined by the fact that the chemical potentials of the two phases is the same, and is denoted as the boiling temperature \\(T_{\\text{b}}\\). Similarly, at a given temperature, the pressure of the vapor is uniquely determined by the same equality relation and is denoted as the vapor pressure, \\(P^*\\). The Gibbs phase rule is obtained considering that the number of independent variables is given by the total number of variables minus the constraints. The total number of variables is given by temperature, pressure, plus all the variables required to describe each of the phases. The composition of each phase is determined by \\((c-1)\\) variables.52 The number of constraints is determined by the number of possible equilibrium relations, which is \\(c(p-1)\\) since the chemical potential of each component must be equal in all phases. The number of degrees of freedom \\(f\\) is then given by \\(f=(c-1)p+2-c(p-1)\\) \\(=c-p+2\\), which is the Gibbs phase rule, as in eq. (12.9). 12.3 \\(PT\\) Phase Diagrams Figure 12.3: The Pressure–Temperature Phase Diagram. Let’s now discuss the pressure–temperature diagram of a typical substance, as reported in Figure 12.3. Each of the lines reported in the diagram represents an equilibrium between two phases, and therefore it represents a condition that reduces the number of degrees of freedom to one. The lines can be determined using the Clapeyron equation, eq. (12.8). The interpretation of each line is as follows: 12.3.1 Liquid \\(\\rightleftarrows\\) Gas equilibrium For this equilibrium we can use Trouton’s rule, eq. (7.7), and write: \\[\\begin{equation} \\Delta_{\\text{vap}} S = S_{\\text{g}}-S_{\\text{l}} \\cong 88 \\; \\frac{\\text{kJ}}{\\text{mol}} &gt; 0\\quad \\text{always}, \\tag{12.10} \\end{equation}\\] where the entropy of vaporization is always positive, even for cases where the Trouton’s rule is violated. The difference in molar volumes is easily obtained, since the volume of the gas is always much greater than the volume of the liquid: \\[\\begin{equation} \\overline{V}_{\\text{g}} - \\overline{V}_{\\text{l}} \\cong \\overline{V}_{\\text{g}} = 22.4\\; \\frac{\\text{L}}{\\text{mol}} &gt;0\\quad \\text{always}. \\tag{12.11} \\end{equation}\\] Replacing these values in the Clapeyron equation, we obtain: \\[\\begin{equation} \\frac{dP}{dT}=\\frac{88}{22.4}\\left( \\frac{0.0831}{8.31} \\right) = 0.004\\;\\text{bar} &gt; 0 \\quad \\text{always}, \\tag{12.12} \\end{equation}\\] which is always positive,regardless of violations to the Trouton’s rule. Notice how small this value is, meaning that the liquid–gas equilibrium curve is mostly flat as \\(T\\rightarrow 0\\). 12.3.2 Solid \\(\\rightleftarrows\\) Gas equilibrium If we look at the signs of each quantity, this case is similar to the previous one: \\[\\begin{equation} \\begin{aligned} \\Delta_{\\text{subl}} S &amp;&gt; 0 \\quad \\text{always} \\\\ \\Delta_{\\text{subl}} \\overline{V }&amp;&gt; 0 \\quad \\text{always} \\\\ \\\\ \\frac{dP}{dT} &amp;&gt; 0 \\quad \\text{always}. \\end{aligned} \\tag{12.13} \\end{equation}\\] However, the Trouton’s rule is not valid for the solid–gas equilibrium, and \\(\\frac{dP}{dT}\\) will be larger than for the previous case. 12.3.3 Solid \\(\\rightleftarrows\\) Liquid equilibrium The final curve is for the solid-liquid equilibrium, for which we have: \\[\\begin{equation} \\Delta_{\\text{fus}} S = \\frac{\\Delta_{\\text{fusion}} H}{T_{\\text{m}}} &gt; 0 \\quad \\text{always}, \\tag{12.14} \\end{equation}\\] since fusion is always an exothermic process, \\((\\Delta_{\\text{fus}} H&gt;0)\\). On the other side: \\[\\begin{equation} \\Delta_{\\text{fusion}} \\overline{V} = \\overline{V}_{\\text{l}} - \\overline{V}_{\\text{s}} &gt; 0 \\quad \\text{generally}. \\end{equation}\\] In other words, the difference of the molar volume of the liquid and that of the solid is positive for most substances, but it might be negative (for example for \\(\\mathrm{H}_2\\mathrm{O}\\)). As such: \\[\\begin{equation} \\frac{dP}{dT} &gt; 0 \\quad \\text{generally}. \\tag{12.15} \\end{equation}\\] For \\(\\mathrm{H}_2\\mathrm{O}\\) and a few other substances, \\(\\frac{dP}{dT}&lt;0\\), an anomalous behavior that has crucial consequences for the existence of life on earth.53 For this importance, this behavior is also depicted in Figure 12.3 using a dashed green line. Since the differences in molar volumes between the solid and the liquid phases are usually small (changes are generally of the order of \\(10^{-3}\\;\\mathrm{L}\\)), \\(\\frac{dP}{dT}\\) is always much larger than for the previous two cases. The resulting lines for the solid–liquid equilibria are still almost vertical, regardless of the signs of their angular coefficients. 12.3.4 The triple point and the critical point The only point in the \\(PT\\) diagram where all the three phases coexist is called the triple point. The number of degrees of freedom at the triple point for every 1-component diagram is \\(f=1-3+2=0\\). The fact that the triple point has zero degrees of freedom means that its coordinates, \\({T_{\\text{tp}},P_{\\text{tp}},\\overline{V}_{\\text{tp}}}\\), are uniquely determined for each chemical substance. For this reason, the value of the triple point of water was fixed by definition—rather than measured—until 2019. This definition was necessary to establish the base unit of the thermodynamic temperature scale in the SI (the Kelvin).54 In addition to the triple point where the solid, liquid, and gas phases meet, a triple point may involve more than one condensed phase. Triple points are common for substances with multiple solid phases (polymorphs), involving either two solid phases and a liquid one or three solid phases. Helium is a special case that presents a triple point involving two different fluid phases, called the lambda point. Since the number of degrees of freedom cannot be negative, the Gibbs phase rule for a 1-component diagram sets the limit to how many phases can coexist to just three. Therefore, quadruple points (or higher coexistence points) are not possible for pure substances, even for polymorphs.55 Another point with a fixed position in the \\(PT\\) diagram is the critical point, \\({T_{\\text{c}},P_{\\text{c}},\\overline{V}_{\\text{c}}}\\). We have already given the definition of the critical temperature in 11.2. This point represents the end of the liquid–gas equilibrium curve. This point is also semantically important to define different regions of the phase diagram, as in Figure 12.3. A gas whose pressure and temperature are below the critical point is called a vapor. A gas whose temperature and pressure are above the critical point is called a supercritical fluid. Finally, a liquid whose pressure is above the critical point is called a compressible liquid.56 12.4 The Clausius–Clapeyron Equation Let’s now take a closer look at the equilibrium between a condensed phase and the gas phase. For both the vaporization and sublimation processes, Clausius showed that the Clapeyron equation can be simplified by using: \\[\\begin{equation} \\Delta_{\\text{vap}} S = \\frac{\\Delta_{\\text{vap}} H}{T} \\qquad \\Delta \\overline{V}= \\overline{V}_{\\mathrm{g}} -\\overline{V}_{\\mathrm{l}} \\cong \\overline{V}_{\\mathrm{g}}, \\tag{12.16} \\end{equation}\\] resulting in: \\[\\begin{equation} \\frac{dP}{dT} = \\frac{ \\Delta_{\\text{vap}} S}{\\Delta \\overline{V}} \\cong \\frac{ \\Delta_{\\text{vap}} H}{T \\overline{V}_{\\mathrm{g}}}. \\tag{12.17} \\end{equation}\\] Using the ideal gas law to replace the molar volume of the gas, we obtain: \\[\\begin{equation} \\frac{dP}{dT} = \\frac{P \\Delta_{\\text{vap}} H}{RT^2}, \\tag{12.18} \\end{equation}\\] which can be rearranged as: \\[\\begin{equation} \\frac{dP}{P} = \\frac{\\Delta_{\\text{vap}} H}{R} \\frac{dT}{T^2}. \\tag{12.19} \\end{equation}\\] Eq. (12.19) is known as the Clausius–Clapeyron equation, and it measures the dependence of the vapor pressure of a substance as a function of the temperature. The Clausius–Clapeyron equation can be integrated to obtain: \\[\\begin{equation} \\begin{aligned} \\int_{P_i}^{P_f} \\frac{dP}{P} &amp;= \\frac{\\Delta_{\\text{vap}} H}{R} \\int_{T_i}^{T_f} \\frac{dT}{T^2} \\\\ \\ln \\frac{P_f}{P_i} &amp;=-\\frac{\\Delta_{\\text{vap}} H}{R} \\left( \\frac{1}{T_f}-\\frac{1}{T_i} \\right). \\end{aligned} \\tag{12.20} \\end{equation}\\] The integrated Clausius–Clapeyron equation shows that the vapor pressure depends exponentially on the temperature. Thus, even a small change in the temperature will result in a significant change in the vapor pressure. In fact, we daily use the fact that the vapor pressure of water changes drastically when we increase its temperature for cooking most of our food. For example, at an external pressure of 1 bar, it rapidly grows from \\(P^*=0.02\\;\\text{bar}\\) to \\(P^*=1\\;\\text{bar}\\) when the temperature is increased from \\(T=293\\;\\mathrm{K}\\) (around room temperature) to \\(T=373\\;\\mathrm{K}\\) (boiling point). The integrated Clausius–Clapeyron equation is also often used to determine the enthalpy of vaporization from measurements of vapor pressure at different temperatures. Other states of matter—such as plasma—are possible, but they are not usually observed at the values of temperature and pressure that classical thermodynamics is usually applied to. Discussion of these extreme cases is beyond the scope of this textbook.↩︎ Think, for example, at the integral \\(\\int SdT\\), for which we can assume \\(S\\) independent of temperature to obtain \\(S\\Delta T\\). In practice, the entropy increases slightly with the temperature. Therefore the curves in Figure 12.1 are slightly concave downwards (remember that they are obtained from values of \\(-S\\), so if \\(S\\) increase with \\(T\\), the curves bend downwards.)↩︎ Despite the effect being minimal, it is one of the contributing causes to the fact that we can skate on ice, but we can’t on stone. If we increase our pressure on ice by reducing our footprints’ surface area using thin skates, ice will slightly melt under our own weight, creating a thin liquid film on which we can skate because of the reduced friction.↩︎ For a 1-component system \\(c-1=1-1=0\\), and no additional variable is required to determine the composition of each phase. For a 2-component system, however, each phase will contain both components, hence \\(c-1=2-1=1\\) additional variable will be required to describe it–the mole fraction.↩︎ As is well explained by Wikipedia: “The unusual density curve and lower density of ice than of water is vital to life—if water were most dense at the freezing point, then in winter the very cold water at the surface of lakes and other water bodies would sink, lakes could freeze from the bottom up, and all life in them would be killed. Furthermore, given that water is a good thermal insulator (due to its heat capacity), some frozen lakes might not completely thaw in summer.[34] The layer of ice that floats on top insulates the water below. Water at about 4 °C (39 °F) also sinks to the bottom, thus keeping the temperature of the water at the bottom constant.”↩︎ For more information on the 2019 redefinition of the SI units, see this Wikipedia page.↩︎ Notice that quadruple points are possible for 2-component diagrams.↩︎ Notice that the temperature of a liquid must be below the critical point, otherwise it is no longer a liquid but rather a supercritical fluid.↩︎ "],
["MCPhaseDiagrams.html", "13 Multi-Component Phase Diagrams 13.1 Raoult’s Law and Phase Diagrams of Ideal Solutions 13.2 Phase Diagrams of Non-Ideal Solutions 13.3 Phase Diagrams of 2-Components/2-Condensed Phases Systems", " 13 Multi-Component Phase Diagrams We now move from studying 1-component systems to multi-component ones. Systems that include two or more chemical species are usually called solutions. Solutions are possible for all three states of matter: Type: Solvent Solute Examples: Solid solutions Solid Solid Alloys: brass, bronze Solid Liquid Dental amalgam Solid Gas Hydrogen stored in Palladium Liquid solutions Liquid Solid Saltwater, bleach Liquid Liquid Alcoholic beverages, vinegar Liquid Gas Carbonated drinks Gaseous solutions Gas Solid Smoke, smog Gas Liquid Aerosols and perfumes Gas Gas Air The number of degrees of freedom for binary solutions (solutions containing two components) is calculated from the Gibbs phase rules at \\(f=2-p+2=4-p\\). When one phase is present, binary solutions require \\(4-1=3\\) variables to be described, usually temperature (\\(T\\)), pressure (\\(P\\)), and mole fraction (\\(y_i\\) in the gas phase and \\(x_i\\) in the liquid phase). Single-phase, 1-component systems require three-dimensional \\(T,P,x_i\\) diagram to be described. When two phases are present (e.g., gas and liquid), only two variables are independent: pressure and concentration. Thus, we can study the behavior of the partial pressure of a gas–liquid solution in a 2-dimensional plot. If the gas phase in a solution exhibits properties similar to those of a mixture of ideal gases, it is called an ideal solution. The obvious difference between ideal solutions and ideal gases is that the intermolecular interactions in the liquid phase cannot be neglected as for the gas phase. The main advantage of ideal solutions is that the interactions between particles in the liquid phase have similar mean strength throughout the entire phase. We will consider ideal solutions first, and then we’ll discuss deviation from ideal behavior and non-ideal solutions. 13.1 Raoult’s Law and Phase Diagrams of Ideal Solutions The behavior of the vapor pressure of an ideal solution can be mathematically described by a simple law established by François-Marie Raoult (1830–1901). Raoult’s law states that the partial pressure of each component, \\(i\\), of an ideal mixture of liquids, \\(P_i\\), is equal to the vapor pressure of the pure component \\(P_i^*\\) multiplied by its mole fraction in the mixture \\(x_i\\): \\[\\begin{equation} P_i=x_i P_i^*. \\tag{13.1} \\end{equation}\\] 13.1.1 One volatile component Raoult’s law applied to a system containing only one volatile component describes a line in the \\(Px_{\\text{B}}\\) plot, as in Figure 13.1. Figure 13.1: The Pressure–Composition Phase Diagram of an Ideal Solution Containing a Single Volatile Component at Constant Temperature. As emerges from Figure 13.1, Raoult’s law divides the diagram into two distinct areas, each with three degrees of freedom.57 Each area contains a phase, with the vapor at the bottom (low pressure), and the liquid at the top (high pressure). Raoult’s law acts as an additional constraint for the points sitting on the line. Therefore, the number of independent variables along the line is only two. Once the temperature is fixed, and the vapor pressure is measured, the mole fraction of the volatile component in the liquid phase is determined. 13.1.2 Two volatile components In an ideal solution, every volatile component follows Raoult’s law. Since the vapors in the gas phase behave ideally, the total pressure can be simply calculated using Dalton’s law as the sum of the partial pressures of the two components \\(P_{\\text{TOT}}=P_{\\text{A}}+P_{\\text{B}}\\). The corresponding diagram is reported in Figure 13.2. The total vapor pressure, calculated using Dalton’s law, is reported in red. The Raoult’s behaviors of each of the two components are also reported using black dashed lines. Figure 13.2: The Pressure–Composition Phase Diagram of an Ideal Solution Containing Two Volatile Components at Constant Temperature. Exercise 13.1 Calculate the mole fraction in the vapor phase of a liquid solution composed of 67% of toluene (\\(\\mathrm{A}\\)) and 33% of benzene (\\(\\mathrm{B}\\)), given the vapor pressures of the pure substances: \\(P_{\\text{A}}^*=0.03\\;\\text{bar}\\), and \\(P_{\\text{B}}^*=0.10\\;\\text{bar}\\). Solution: The data available for the systems are summarized as follwos: \\[\\begin{equation} \\begin{aligned} x_{\\text{A}}=0.67 \\qquad &amp; \\qquad x_{\\text{B}}=0.33 \\\\ P_{\\text{A}}^* = 0.03\\;\\text{bar} \\qquad &amp; \\qquad P_{\\text{B}}^* = 0.10\\;\\text{bar} \\\\ &amp; P_{\\text{TOT}} = ? \\\\ y_{\\text{A}}=? \\qquad &amp; \\qquad y_{\\text{B}}=? \\end{aligned} \\tag{13.2} \\end{equation}\\] The total pressure of the vapors can be calculated combining Dalton’s and Roult’s laws: \\[\\begin{equation} \\begin{aligned} P_{\\text{TOT}} &amp;= P_{\\text{A}}+P_{\\text{B}}=x_{\\text{A}} P_{\\text{A}}^* + x_{\\text{B}} P_{\\text{B}}^* \\\\ &amp;= 0.67\\cdot 0.03+0.33\\cdot 0.10 \\\\ &amp;= 0.02 + 0.03 = 0.05 \\;\\text{bar} \\end{aligned} \\tag{13.3} \\end{equation}\\] We can then calculate the mole fraction of the components in the vapor phase as: \\[\\begin{equation} \\begin{aligned} y_{\\text{A}}=\\frac{P_{\\text{A}}}{P_{\\text{TOT}}} &amp; \\qquad y_{\\text{B}}=\\frac{P_{\\text{B}}}{P_{\\text{TOT}}} \\\\ y_{\\text{A}}=\\frac{0.02}{0.05}=0.40 &amp; \\qquad y_{\\text{B}}=\\frac{0.03}{0.05}=0.60 \\end{aligned} \\tag{13.4} \\end{equation}\\] Notice how the mole fraction of toluene is much higher in the liquid phase, \\(x_{\\text{A}}=0.67\\), than in the vapor phase, \\(y_{\\text{A}}=0.40\\). As is clear from the results of Exercise 13.1, the concentration of the components in the gas and vapor phases are different. We can also report the mole fraction in the vapor phase as an additional line in the \\(Px_{\\text{B}}\\) diagram of Figure 13.2. When both concentrations are reported in one diagram—as in Figure 13.3—the line where \\(x_{\\text{B}}\\) is obtained is called the liquidus line, while the line where the \\(y_{\\text{B}}\\) is reported is called the Dew point line. Figure 13.3: The Pressure–Composition Phase Diagram of an Ideal Solution Containing Two Volatile Components at Constant Temperature. Both the Liquidus and Dew Point Line are Emphasized in this Plot. The liquidus and Dew point lines determine a new section in the phase diagram where the liquid and vapor phases coexist. Since the degrees of freedom inside the area are only 2, for a system at constant temperature, a point inside the coexistence area has fixed mole fractions for both phases. We can reduce the pressure on top of a liquid solution with concentration \\(x^i_{\\text{B}}\\) (see Figure 13.3) until the solution hits the liquidus line. At this pressure, the solution forms a vapor phase with mole fraction given by the corresponding point on the Dew point line, \\(y^f_{\\text{B}}\\). 13.1.3 \\(T_{\\text{B}}\\) phase diagrams and fractional distillation We can now consider the phase diagram of a 2-component ideal solution as a function of temperature at constant pressure. The \\(T_{\\text{B}}\\) diagram for two volatile components is reported in Figure 13.4. Figure 13.4: The Temperature–Composition Phase Diagram of an Ideal Solution Containing Two Volatile Components at Constant Pressure. Compared to the \\(Px_{\\text{B}}\\) diagram of Figure 13.3, the phases are now in reversed order, with the liquid at the bottom (low temperature), and the vapor on top (high Temperature). The liquidus and Dew point lines are curved and form a lens-shaped region where liquid and vapor coexists. Once again, there is only one degree of freedom inside the lens. As such, a liquid solution of initial composition \\(x_{\\text{B}}^i\\) can be heated until it hits the liquidus line. At this temperature the solution boils, producing a vapor with concentration \\(y_{\\text{B}}^f\\). As is clear from Figure 13.4, the mole fraction of the \\(\\text{B}\\) component in the gas phase is lower than the mole fraction in the liquid phase. This fact can be exploited to separate the two components of the solution. In particular, if we set up a series of consecutive evaporation and condensations, we can distill fractions of the solution with an increasingly lower concentration of the less volatile component \\(\\text{B}\\). This is exemplified in the industrial process of fractional distillation, as schematically depicted in Figure 13.5. Figure 13.5: The Fractional Distillation Process and Theoretical Plates Calculated on a Temperature–Composition Phase Diagram. Each of the horizontal lines in the lens region of the \\(Tx_{\\text{B}}\\) diagram of Figure 13.5 corresponds to a condensation/evaporation process and is called a theoretical plate. These plates are industrially realized on large columns with several floors equipped with condensation trays. The temperature decreases with the height of the column. A condensation/evaporation process will happen on each level, and a solution concentrated in the most volatile component is collected. The theoretical plates and the \\(Tx_{\\text{B}}\\) are crucial for sizing the industrial fractional distillation columns. 13.2 Phase Diagrams of Non-Ideal Solutions Non-ideal solutions follow Raoult’s law for only a small amount of concentrations. The typical behavior of a non-ideal solution with a single volatile component is reported in the \\(Px_{\\text{B}}\\) plot in Figure 13.6. Figure 13.6: The Pressure–Composition Phase Diagram of a Non-Ideal Solution Containing a Single Volatile Component at Constant Temperature. Raoult’s behavior is observed for high concentrations of the volatile component. This behavior is observed at \\(x_{\\text{B}} \\rightarrow 0\\) in Figure 13.6, since the volatile component in this diagram is \\(\\mathrm{A}\\). At low concentrations of the volatile component \\(x_{\\text{B}} \\rightarrow 1\\) in Figure 13.6, the solution follows a behavior along a steeper line, which is known as Henry’s law. William Henry (1774–1836) has extensively studied the behavior of gases dissolved in liquids. His studies resulted in a simple law that relates the vapor pressure of a solution to a constant, called Henry’s law solubility constants: \\[\\begin{equation} P_{\\text{B}}=k_{\\text{AB}} x_{\\text{B}}, \\tag{13.5} \\end{equation}\\] where \\(k_{\\text{AB}}\\) depends on the chemical nature of \\(\\mathrm{A}\\) and \\(\\mathrm{B}\\). The corresponding diagram for non-ideal solutions with two volatile components is reported on the left panel of Figure 13.7. The total pressure is once again calculated as the sum of the two partial pressures. Positive deviations on Raoult’s ideal behavior are not the only possible deviation from ideality, and negative deviation also exits, albeit slightly less common. An example of a negative deviation is reported in the right panel of Figure 13.7. Figure 13.7: The Pressure–Composition Phase Diagram of Non-Ideal Solutions Containing Two Volatile Components at Constant Temperature. If we move from the \\(Px_{\\text{B}}\\) diagram to the \\(Tx_{\\text{B}}\\) diagram, the behaviors observed in Figure 13.7 will correspond to the diagram in Figure 13.8. Figure 13.8: The Temperature–Composition Phase Diagram of Non-Ideal Solutions Containing Two Volatile Components at Constant Pressure. The minimum (left plot) and maximum (right plot) points in Figure 13.8 represent the so-called azeotrope. An azeotrope is a constant boiling point solution whose composition cannot be altered or changed by simple distillation. This happens because the liquidus and Dew point lines coincide at this point. Therefore, the liquid and the vapor phases have the same composition, and distillation cannot occur. Two types of azeotropes exist, representative of the two types of non-ideal behavior of solutions. The first type is the positive azeotrope (left plot in Figure 13.8). A notorious example of this behavior at atmospheric pressure is the ethanol/water mixture, with composition 95.63% ethanol by mass. This positive azeotrope boils at \\(T=78.2\\;^\\circ \\text{C}\\), a temperature that is lower than the boiling points of the pure constituents, since ethanol boils at \\(T=78.4\\;^\\circ \\text{C}\\) and water at \\(T=100\\;^\\circ \\text{C}\\). The second type is the negative azeotrope (right plot in Figure 13.8). An example of this behavior at atmospheric pressure is the hydrochloric acid/water mixture with composition 20.2% hydrochloric acid by mass. This negative azeotrope boils at \\(T=110\\;^\\circ \\text{C}\\), a temperature that is higher than the boiling points of the pure constituents, since hydrochloric acid boils at \\(T=-84\\;^\\circ \\text{C}\\) and water at \\(T=100\\;^\\circ \\text{C}\\). 13.3 Phase Diagrams of 2-Components/2-Condensed Phases Systems We now consider equilibria between two condensed phases: liquid/liquid, liquid/solid, and solid/solid. These equilibria usually occur in the low-temperature region of a phase diagram (or high pressure). Three situations are possible, depending on the constituents and concentration of the mixture. 13.3.1 Totally miscible We have already encountered the situation where the components of a solution mix entirely in the liquid phase. All the diagrams that we’ve discussed up to this point belong to this category. 13.3.2 Totally immiscible A more complicated case is that for components that do not mix in the liquid phase. The liquid region of the temperature–composition phase diagram for a solution with components that do not mix in the liquid phase below a specific temperature is reported in Figure 13.9. Figure 13.9: The Liquid Region of the Temperature–Composition Phase Diagram of Solutions Containing Two Components that are Completely Immiscible in the Liquid Phase. While the liquid 1+liquid 2 region (white area in Figure 13.9) might seem similar to the liquid region that sits on top of it (blue area in Figure 13.9), it is substantially different in nature. To prove this, we can calculate the degrees of freedom in each region using the Gibbs phase rule. For the liquid region at the top of the diagram, at constant pressure, we have \\(f=2-1+1=2\\). In other words, the temperature and the composition are independent, and their values can be changed regardless of each other. In the liquid 1+liquid 2 at the bottom, however, we have \\(f=2-2+1=1\\), which means that only one variable is independent of the others. The white region in Figure 13.9 is a 2-phase region, and it behaves similarly to the other 2-phases regions that we encountered before, such as the inner portion of the lens in Figure 13.4. In other words, since the two components are entirely immiscible, once we set the temperature at a value below the immiscibility line, the concentration of the two liquid will be determined by tracing a horizontal line and by reading the concentrations on the left and right of the diagram (corresponding to 100% \\(\\mathrm{A}\\) and 100% \\(\\mathrm{B}\\), respectively). 13.3.3 Partially miscible The third and final case is undoubtedly the most interesting since several behaviors are possible. In fact, there might be components that are partially miscible at low temperatures but totally miscible at higher temperatures, for which the diagram will assume the general shape depicted in Figure 13.10. A typical example of this behavior is the mixture between water and phenol, whose liquids are completely miscible at \\(T&gt;66\\;^\\circ \\text{C}\\), and only partially miscible below this temperature. The composition of the 2-phases region (white area in Figure 13.10) is determined by tracing a horizontal line and reading the mole fraction on the line that delimits the area, as for the previous case.58 Figure 13.10: The Liquid Region of the Temperature–Composition Phase Diagram of Solutions Containing Two Components that are Partially Immiscible at Low Temperature in the Liquid Phase, but Completely Miscible at High Temperatures On the opposite side of the spectrum, the diagram for a mixture whose components are partially miscible at high temperature, but completely miscible at lower temperatures is depicted in Figure 13.11. A typical example of this behavior is the mixture between water and triethylamine, whose liquids are completely miscible at \\(T&lt;18.5\\;^\\circ \\text{C}\\), and only partially miscible above this temperature. Figure 13.11: The Liquid Region of the Temperature–Composition Phase Diagram of Solutions Containing Two Components that are Partially Immiscible at High Temperature in the Liquid Phase, but Completely Miscible at Low Temperatures. Finally, both situations described above are possible simultaneously. For some particular solutions, there exists a range of temperature where the two components are only partially miscible. A typical example of this behavior is given by the water/nicotine mixture, whose liquids are completely miscible at \\(T&gt;210\\;^\\circ \\text{C}\\) and \\(T&lt;61\\;^\\circ \\text{C}\\), but only partially miscible in between these two temperatures, as in the diagram of Figure 13.12. Figure 13.12: The Liquid Region of the Temperature–Composition Phase Diagram of Solutions Containing Two Components that are Partially Immiscible Only Between Two Temperatures. 13.3.4 Eutectic systems For some particular mixture, the temperature of partial miscibility in the liquid/liquid region might be close to the azeotrope temperature. In some cases, these two regions might even overlap. These characteristic behaviors are reported in Figure 13.13. Figure 13.13: Interaction Between the Liquid/Gas and Liquid/Liquid Equilibria. When the azeotrope and partially miscibility temperature overlap, the system forms what is known as an eutectic. Eutectic diagrams are possible at the liquid/gas equilibrium. Still, they are widespread at the liquid/solid equilibrium, where two components are completely miscible in the liquid phase, but only partially miscible in the solid phase. Eutectics with completely immiscible components in the solid phase are also very common, as the diagram reported in Figure 13.14. Figure 13.14: Typical Eutectic System with Components that are Completely Miscible in the Liquid Phase and Completely Immiscible in the Solid Phase. Only two degrees of freedom are visible in the \\(Px_{\\text{B}}\\) diagram. Temperature represents the third independent variable.↩︎ The only noticeable difference, in this case, is that the two concentrations will be different than 0 and 100% since the component mix partially.↩︎ "],
["Solutions.html", "14 Solutions 14.1 Activity 14.2 Colligative Properties", " 14 Solutions In the previous chapter, we have qualitatively described the deviation of real solutions from ideal behavior. In this section, we are discussing it quantitatively. We will be able to do so by using a concept that we have already encountered in chapter 10: Lewis’s activity. 14.1 Activity For non-ideal gases, we introduced in chapter 11 the concept of fugacity as an effective pressure that accounts for non-ideal behavior. If we extend this concept to non-ideal solution, we can introduce the activity of a liquid or a solid, \\(a\\), as: \\[\\begin{equation} \\mu_{\\text{non-ideal}} = \\mu^{{-\\kern-6pt{\\ominus}\\kern-6pt-}} + RT \\ln a, \\tag{14.1} \\end{equation}\\] where \\(\\mu\\) is the chemical potential of the substance or the mixture, and \\(\\mu^{{-\\kern-6pt{\\ominus}\\kern-6pt-}}\\) is the chemical potential at standard state. Comparing this definition to eq. (11.29), it is clear that the activity is equal to the fugacity for a non-ideal gas (which, in turn, is equal to the pressure for an ideal gas). However, for a liquid and a liquid mixture, it depends on the chemical potential at standard state. This means that the activity is not an absolute quantity, but rather a relative term describing how “active” a compound is compared to standard state conditions. The choice of the standard state is, in principle, arbitrary, but conventions are often chosen out of mathematical or experimental convenience. We already discussed the convention that standard state for a gas is at \\(P^{{-\\kern-6pt{\\ominus}\\kern-6pt-}}=1\\;\\text{bar}\\), so the activity is equal to the fugacity. The standard state for a component in a solution is the pure component at the temperature and pressure of the solution. This definition is equivalent to setting the activity of a pure component, \\(i\\), at \\(a_i=1\\). For a component in a solution we can use eq. (11.29) to write the chemical potential in the gas phase as: \\[\\begin{equation} \\mu_i^{\\text{vapor}} = \\mu_i^{{-\\kern-6pt{\\ominus}\\kern-6pt-}} + RT \\ln \\frac{P_i}{P^{{-\\kern-6pt{\\ominus}\\kern-6pt-}}}. \\tag{14.2} \\end{equation}\\] If the gas phase is in equilibrium with the liquid solution, then: \\[\\begin{equation} \\mu_i^{\\text{solution}} = \\mu_i^{\\text{vapor}} = \\mu_i^*, \\tag{14.3} \\end{equation}\\] where \\(\\mu_i^*\\) is the chemical potential of the pure element. Subtracting eq. (14.3) from eq. (14.2), we obtain: \\[\\begin{equation} \\mu_i^{\\text{solution}} = \\mu_i^* + RT \\ln \\frac{P_i}{P^*_i}. \\tag{14.4} \\end{equation}\\] For an ideal solution, we can use Raoult’s law, eq. (13.1), to rewrite eq. (14.4) as: \\[\\begin{equation} \\mu_i^{\\text{solution}} = \\mu_i^* + RT \\ln x_i, \\tag{14.5} \\end{equation}\\] which relates the chemical potential of a component in an ideal solution to the chemical potential of the pure liquid and its mole fraction in the solution. For a non-ideal solution, the partial pressure in eq. (14.4) is either larger (positive deviation) or smaller (negative deviation) than the pressure calculated using Raoult’s law. The chemical potential of a component in the mixture is then calculated using: \\[\\begin{equation} \\mu_i^{\\text{solution}} = \\mu_i^* + RT \\ln \\left(\\gamma_i x_i\\right), \\tag{14.6} \\end{equation}\\] where \\(\\gamma_i\\) is a positive coefficient that accounts for deviations from ideality. This coefficient is either larger than one (for positive deviations), or smaller than one (for negative deviations). The activity of component \\(i\\) can be calculated as an effective mole fraction, using: \\[\\begin{equation} a_i = \\gamma_i x_i, \\tag{14.7} \\end{equation}\\] where \\(\\gamma_i\\) is defined as the activity coefficient. The partial pressure of the component can then be related to its vapor pressure, using: \\[\\begin{equation} P_i = a_i P_i^*. \\tag{14.8} \\end{equation}\\] Comparing eq. (14.8) with Raoult’s law, we can calculate the activity coefficient as: \\[\\begin{equation} \\gamma_i = \\frac{P_i}{x_i P_i^*} = \\frac{P_i}{P_i^{\\text{R}}}, \\tag{14.9} \\end{equation}\\] where \\(P_i^{\\text{R}}\\) is the partial pressure calculated using Raoult’s law. This result also proves that for an ideal solution, \\(\\gamma=1\\). Eq. (14.9) can also be used experimentally to obtain the activity coefficient from the phase diagram of the non-ideal solution. This is achieved by measuring the value of the partial pressure of the vapor of a non-ideal solution. Examples of this procedure are reported for both positive and negative deviations in Figure 14.1. Figure 14.1: Positive and Negative Deviation from Raoult’s Law in the Pressure–Composition Phase Diagram of Non-Ideal Solutions at Constant Temperature. As we already discussed in chapter 10, the activity is the most general quantity that we can use to define the equilibrium constant of a reaction (or the reaction quotient). The advantage of using the activity is that it’s defined for ideal and non-ideal gases and mixtures of gases, as well as for ideal and non-ideal solutions in both the liquid and the solid phase.59 14.2 Colligative Properties Colligative properties are properties of solutions that depend on the number of particles in the solution and not on the nature of the chemical species. More specifically, a colligative property depends on the ratio between the number of particles of the solute and the number of particles of the solvent. This ratio can be measured using any unit of concentration, such as mole fraction, molarity, and normality. For diluted solutions, however, the most useful concentration for studying colligative properties is the molality, \\(m\\), which measures the ratio between the number of particles of the solute (in moles) and the mass of the solvent (in kg): \\[\\begin{equation} m = \\frac{n_{\\text{solute}}}{m_{\\text{solvent}}}. \\tag{14.10} \\end{equation}\\] Colligative properties usually result from the dissolution of a nonvolatile solute in a volatile liquid solvent, and they are properties of the solvent, modified by the presence of the solute. They are physically explained by the fact that the solute particles displace some solvent molecules in the liquid phase, thereby reducing the concentration of the solvent. This explanation shows how colligative properties are independent of the nature of the chemical species in a solution only if the solution is ideal. For non-ideal solutions, the formulas that we will derive below are valid only in an approximate manner. We will discuss the following four colligative properties: relative lowering of the vapor pressure, elevation of the boiling point, depression of the freezing point, and osmotic pressure. 14.2.1 Vapor pressure lowering As we have already discussed in chapter 13, the vapor pressure of an ideal solution follows Raoult’s law. Its difference with respect to the vapor pressure of the pure solvent can be calculated as: \\[\\begin{equation} \\begin{aligned} P_{\\text{solvent}}^* &amp;- P_{\\text{solution}} = P_{\\text{solvent}}^* - x_{\\text{solvent}} P_{\\text{solvent}}^* \\\\ &amp; = \\left( 1-x_{\\text{solvent}}\\right)P_{\\text{solvent}}^* =x_{\\text{solute}} P_{\\text{solvent}}^*, \\end{aligned} \\tag{14.11} \\end{equation}\\] which shows that the vapor pressure lowering depends only on the concentration of the solute. As such, it is a colligative property. 14.2.2 Boiling point elevation and melting point depression The following two colligative properties are explained by reporting the changes due to the solute molecules in the plot of the chemical potential as a function of temperature (Figure 12.1). At the boiling point, the chemical potential of the solution is equal to the chemical potential of the vapor, and the following relation can be obtained: \\[\\begin{equation} \\begin{aligned} \\mu_{\\text{solution}} &amp;=\\mu_{\\text{vap}}=\\mu_{\\text{solvent}}^{{-\\kern-6pt{\\ominus}\\kern-6pt-}} + RT \\ln P_{\\text{solution}} \\\\ &amp;= \\mu_{\\text{solvent}}^{{-\\kern-6pt{\\ominus}\\kern-6pt-}} + RT \\ln \\left(x_{\\text{solution}} P_{\\text{solvent}}^* \\right)\\\\ &amp;= \\underbrace{\\mu_{\\text{solvent}}^{{-\\kern-6pt{\\ominus}\\kern-6pt-}} + RT \\ln P_{\\text{solvent}}^*}_{\\mu_{\\text{solvent}}^*} + RT \\ln x_{\\text{solution}} \\\\ &amp;= \\mu_{\\text{solvent}}^* + RT \\ln x_{\\text{solution}}, \\end{aligned} \\tag{14.12} \\end{equation}\\] and since \\(x_{\\text{solution}}&lt;1\\), the logarithmic term in the last expression is negative, and: \\[\\begin{equation} \\mu_{\\text{solution}} &lt; \\mu_{\\text{solvent}}^*. \\tag{14.13} \\end{equation}\\] Eq. (14.12) proves that the addition of a solute always stabilizes the solvent in the liquid phase, and lowers its chemical potential, as shown in Figure 14.2. Figure 14.2: Reduction of the Chemical Potential of the Liquid Phase Due to the Addition of a Solute. The elevation of the boiling point can be quantified using: \\[\\begin{equation} \\Delta T_{\\text{b}}=T_{\\text{b}}^{\\text{solution}}-T_{\\text{b}}^{\\text{solvent}}=iK_{\\text{b}}m, \\tag{14.14} \\end{equation}\\] where \\(i\\) is the van ’t Hoff factor, a coefficient that measures the number of solute particles for each formula unit, \\(K_{\\text{b}}\\) is the ebullioscopic constant of the solvent, and \\(m\\) is the molality of the solution, as introduced in eq. (14.10) above. For a solute that does not dissociate in solution, \\(i=1\\). For a solute that dissociates in solution, the number of particles in solutions depends on how many particles it dissociates into, and \\(i&gt;1\\). For example, the strong electrolyte \\(\\mathrm{Ca}\\mathrm{Cl}_2\\) completely dissociates into three particles in solution, one \\(\\mathrm{Ca}^{2+}\\) and two \\(\\mathrm{Cl}^-\\), and \\(i=3\\). For cases of partial dissociation, such as weak acids, weak bases, and their salts, \\(i\\) can assume non-integer values. If we assume ideal solution behavior,the ebullioscopic constant can be obtained from the thermodynamic condition for liquid-vapor equilibrium. At the boiling point of the solution, the chemical potential of the solvent in the solution phase equals the chemical potential in the pure vapor phase above the solution: \\[\\begin{equation} \\mu_{\\text{solution}} (T_{\\text{b}}) = \\mu_{\\text{solvent}}^*(T_b) + RT\\ln x_{\\text{solvent}}, \\tag{14.15} \\end{equation}\\] from which we can derive, using the Gibbs–Helmholtz equation, eq. (9.9): \\[\\begin{equation} K_{\\text{b}}=\\frac{RMT_{\\text{b}}^{2}}{\\Delta_{\\mathrm{vap}} H}, \\tag{14.16} \\end{equation}\\] where \\(R\\) is the ideal gas constant, \\(M\\) is the molar mass of the solvent, and \\(\\Delta_{\\mathrm{vap}} H\\) is its molar enthalpy of vaporization. The reduction of the melting point is similarly obtained by: \\[\\begin{equation} \\Delta T_{\\text{m}}=T_{\\text{m}}^{\\text{solution}}-T_{\\text{m}}^{\\text{solvent}}=-iK_{\\text{m}}m, \\tag{14.17} \\end{equation}\\] where \\(i\\) is the van ’t Hoff factor introduced above, \\(K_{\\text{m}}\\) is the cryoscopic constant of the solvent, \\(m\\) is the molality, and the minus sign accounts for the fact that the melting temperature of the solution is lower than the melting temperature of the pure solvent (\\(\\Delta T_{\\text{f}}\\) is defined as a negative quantity, while \\(i\\), \\(K_{\\text{f}}\\), and \\(m\\) are all positive). Similarly to the previous case, the cryoscopic constant can be related to the molar enthalpy of fusion of the solvent using the equivalence of the chemical potential of the solid and the liquid phases at the melting point, and employing the Gibbs–Helmholtz equation: \\[\\begin{equation} K_{\\text{m}}=\\frac{RMT_{\\text{m}}^{2}}{\\Delta_{\\mathrm{fus}}H}. \\tag{14.18} \\end{equation}\\] Notice from Figure 14.2 how the depression of the melting point is always smaller than the elevation of the boiling point. This is because the chemical potential of the solid is essentially flat, while the chemical potential of the gas is steep. Consequently, the value of the cryoscopic constant is always bigger than the value of the ebullioscopic constant. For example, for water \\(K_{\\text{f}} = 1.86\\; \\frac{\\text{K kg}}{\\text{mol}}\\), while \\(K_{\\text{b}} = 0.512\\; \\frac{\\text{K kg}}{\\text{mol}}\\). This is also proven by the fact that the enthalpy of vaporization is larger than the enthalpy of fusion. 14.2.3 Osmotic pressure The osmotic pressure of a solution is defined as the difference in pressure between the solution and the pure liquid solvent when the two are in equilibrium across a semi-permeable (osmotic) membrane. The osmotic membrane is made of a porous material that allows the flow of solvent molecules but blocks the flow of the solute ones. The osmosis process is depicted in Figure 14.3. Figure 14.3: Osmotic Pressure of a Solution. Starting from a solvent at atmospheric pressure in the apparatus depicted in Figure 14.3, we can add solute particles to the left side of the apparatus. The increase in concentration on the left causes a net transfer of solvent across the membrane. This flow stops when the pressure difference equals the osmotic pressure, \\(\\pi\\). The formula that governs the osmotic pressure was initially proposed by van ’t Hoff and later refined by Harmon Northrop Morse (1848–1920). The Morse formula reads: \\[\\begin{equation} \\pi = imRT, \\tag{14.19} \\end{equation}\\] where \\(i\\) is the van ’t Hoff factor introduced above, \\(m\\) is the molality of the solution, \\(R\\) is the ideal gas constant, and \\(T\\) the temperature of the solution. As with the other colligative properties, the Morse equation is a consequence of the equality of the chemical potentials of the solvent and the solution at equilibrium.60 Notice that, since the activity is a relative measure, the equilibrium constant expressed in terms of the activities is also a relative concept. In other words, it measures equilibrium relative to a standard state. This fact, however, should not surprise us, since the equilibrium constant is also related to \\(\\Delta_{\\text{rxn}} G^{{-\\kern-6pt{\\ominus}\\kern-6pt-}}\\) using Gibbs’ relation. This is why the definition of a universally agreed-upon standard state is such an essential concept in chemistry, and why it is defined by the International Union of Pure and Applied Chemistry (IUPAC) and followed systematically by chemists around the globe.↩︎ For a derivation, see the osmotic pressure Wikipedia page.↩︎ "],
["Kinetics.html", "15 Chemical Kinetics 15.1 Differential and integrated rate laws 15.2 Complex Rate Laws 15.3 Experimental Methods for Determination of Reaction Orders 15.4 Temperature Dependence of the Rate Coefficients", " 15 Chemical Kinetics From thermodynamics, we can determine the spontaneity of a reaction and its extent, using \\(\\Delta G\\) and \\(K\\), respectively. However, thermodynamics does not provide any information on how fast the reaction is going to happen. For example, while the reaction that converts solid carbon from its diamond allotropic form into hexagonal graphite is thermodynamically spontaneous, it is so slow as to be virtually non-existent. Diamond is effectively a meta-stable phase. The speed of a chemical reaction is the subject of a branch of physical chemistry called chemical kinetics. A chemical kinetics study aims to find the rate of a reaction and to find the microscopic steps that compose it, determining its mechanism. 15.1 Differential and integrated rate laws The rate law of a chemical reaction is an equation that links the initial rate with the concentrations (or pressures) of the reactants. Rate laws usually include a constant parameter, \\(k\\), called the rate coefficient, and several parameters found at the exponent of the concentrations of the reactants, and are called reaction orders. The rate coefficient depends on several conditions, including the reaction type, the temperature, the surface area of an adsorbent, light irradiation, and others. The reaction rate is usually represented with the lowercase letter \\(k\\), and it should not be confused with the thermodynamic equilibrium constant that is generally designated with the uppercase letter \\(K\\). Another useful concept in kinetics is the half-life, usually abbreviated with \\(t_{1/2}\\). The half-life is defined as the time required to reach half of the initial reactant concentration. A reaction that happens in one single microscopic step is called elementary. Elementary reactions have reaction orders equal to the (integer) stoichiometric coefficients for each reactant. As such, only a limited number of elementary reactions are possible (four types are commonly observed), and they are classified according to their overall reaction order. The global reaction order of a reaction is calculated as the sum of each reactant’s individual orders and is, at most, equal to three. We examine in detail the four most common reaction orders below. 15.1.1 Zeroth-order reaction For a zeroth-order reaction, the reaction rate is independent of the concentration of a reactant. In other words, if we have a reaction of the type: \\[\\begin{equation} \\text{A}\\longrightarrow\\text{products} \\end{equation}\\] the differential rate law can be written: \\[\\begin{equation} - \\frac{d[\\mathrm{A}]}{dt}=k_0 [\\mathrm{A}]^0 = k_0, \\tag{15.1} \\end{equation}\\] which shows that any change in the concentration of \\(\\mathrm{A}\\) will have no effect on the speed of the reaction. The minus sign at the right-hand-side is required because the rate is always defined as a positive quantity, while the derivative is negative because the concentration of the reactant is diminishing with time. Separating the variables \\([\\mathrm{A}]\\) and \\(t\\) of eq. (15.1) and integrating both sides, we obtain the integrated rate law for a zeroth-order reaction as: \\[\\begin{equation} \\begin{aligned} \\int_{[\\mathrm{A}]_0}^{[A]} d[\\mathrm{A}] &amp;= -k_0 \\int_{t=0}^{t} dt \\\\ [\\mathrm{A}]-[\\mathrm{A}]_0 &amp;= -k_0 t \\\\ \\\\ [\\mathrm{A}]&amp;=[\\mathrm{A}]_0 -k_0 t. \\end{aligned} \\tag{15.2} \\end{equation}\\] Using the integrated rate law, we notice that the concentration on the reactant diminishes linearly with respect to time. A plot of \\([\\mathrm{A}]\\) as a function of \\(t\\), therefore, will result in a straight line with an angular coefficient equal to \\(-k_0\\), as in the plot of Figure 15.1. Figure 15.1: Reaction Rate Plot for a Zeroth-Order Reaction. Eq. (15.2) also suggests that the units of the rate coefficient for a zeroth-order reaction are of concentration divided by time, typically \\(\\frac{\\mathrm{M}}{\\mathrm{s}}\\), with \\(\\mathrm{M}\\) being the molar concentration in \\(\\frac{\\mathrm{mol}}{\\mathrm{L}}\\) and \\(s\\) the time in seconds. The half-life of a zero order reaction can be calculated from eq. (15.2), by replacing \\([\\mathrm{A}]\\) with \\(\\frac{1}{2}[\\mathrm{A}]_0\\): \\[\\begin{equation} \\begin{aligned} \\frac{1}{2}[\\mathrm{A}]_0 &amp;=[\\mathrm{A}]_0 -k_0 t_{1/2} \\\\ t_{1/2} &amp;= \\frac{[\\mathrm{A}]_0}{2k_0}. \\end{aligned} \\tag{15.3} \\end{equation}\\] Zeroth-order reactions are common in several biochemical processes catalyzed by enzymes, such as the oxidation of ethanol to acetaldehyde in the liver by the alcohol dehydrogenase enzyme, which is zero-order in ethanol. 15.1.2 First-order reaction A first-order reaction depends on the concentration of only one reactant, and is therefore also called a unimolecular reaction. As for the previous case, if we consider a reaction of the type: \\[\\begin{equation} \\mathrm{A}\\rightarrow \\text{products} \\end{equation}\\] the differential rate law for a first-order reaction is: \\[\\begin{equation} - \\frac{d[\\mathrm{A}]}{dt}=k_1 [\\mathrm{A}]. \\tag{15.4} \\end{equation}\\] Following the usual blueprint of separating the variables, and integrating both sides, we obtain the integrated rate law as: \\[\\begin{equation} \\begin{aligned} \\int_{[\\mathrm{A}]_0}^{[A]} \\frac{d[\\mathrm{A}]}{[\\mathrm{A}]} &amp;= -k_1 \\int_{t=0}^{t} dt \\\\ \\ln \\frac{[\\mathrm{A}]}{[\\mathrm{A}]_0}&amp;=-k_1 t\\\\ \\\\ [\\mathrm{A}] &amp;= [\\mathrm{A}]_0 \\exp(-k_1 t). \\end{aligned} \\tag{15.5} \\end{equation}\\] Using the integrated rate law to plot the concentration of the reactant, \\([\\mathrm{A}]\\), as a function of time, \\(t\\), we obtain an exponential decay, as in Figure 15.2. Figure 15.2: Reaction Rate Plot for a First-Order Reaction. However, if we plot the logarithm of the concentration, \\(\\ln[\\mathrm{A}]\\), as a function of time, we obtain a line with angular coefficient \\(-k_1\\), as in the plot of Figure 15.3. From eq. (15.5), we can also obtain the units for the rate coefficient for a first-order reaction, which typically is \\(\\frac{1}{\\mathrm{s}}\\), independent of concentration. Since the rate coefficient for first-order reactions has units of inverse time, it is sometimes called the frequency rate. Figure 15.3: Linear Plot for a First-Order Reaction. Notice that the Quantity on the y Axes is ln[A]. The half-life of a first-order reaction is: \\[\\begin{equation} \\begin{aligned} \\ln \\frac{\\frac{1}{2}[\\mathrm{A}]_0}{[\\mathrm{A}]_0}&amp;=-k_1 t_{1/2}\\\\ t_{1/2} &amp;= \\frac{\\ln 2}{k_1}. \\end{aligned} \\tag{15.6} \\end{equation}\\] The half-life of a first-order reaction is independent of the initial concentration of the reactant. Therefore, the half-life can be used in place of the rate coefficient to describe the reaction rate. Typical examples of first-order reactions are radioactive decays. For radioactive isotopes, it is common to report their rate of decay in terms of their half-life. For example, the most stable uranium nucleotide, \\(^{238}\\mathrm{U}\\), has a half-life of \\(4.468\\times 10^9\\) years, while the most common fissile isotope of uranium, \\(^{235}\\mathrm{U}\\), has a half-life of \\(7.038\\times 10^8\\) years.61 Other examples of first-order reactions in chemistry are the class of SN1 nucleophilic substitution reactions in organic chemistry. 15.1.3 Second-order reaction A reaction is second-order when the sum of the reaction orders is two. Elementary second-order reactions are also called bimolecular reactions. There are two possibilities, a simple one, where the reaction order of one reagent is two, or a more complicated one, with two reagents having each a reaction order of one. For the simple case, we can write the reaction as: \\[\\begin{equation} 2\\mathrm{A}\\rightarrow \\text{products} \\end{equation}\\] the differential rate law for a first-order reaction is: \\[\\begin{equation} -\\frac{d[\\mathrm{A}]}{dt}=k_2 [\\mathrm{A}]^2. \\tag{15.7} \\end{equation}\\] Following the same procedure used for the two previous cases, we can obtain the integrated rate law as: \\[\\begin{equation} \\begin{aligned} \\int_{[\\mathrm{A}]_0}^{[A]} \\frac{d[\\mathrm{A}]}{[\\mathrm{A}]^2} &amp;= -k_2 \\int_{t=0}^{t} dt \\\\ \\frac{1}{[\\mathrm{A}]}-\\frac{1}{[\\mathrm{A}]_0} &amp;= k_2 t\\\\ \\\\ \\frac{1}{[\\mathrm{A}]}&amp;=\\frac{1}{[\\mathrm{A}]_0} + k_2 t. \\end{aligned} \\tag{15.8} \\end{equation}\\] As for first-order reactions, the plot of the concentration as a function of time shows a non-linear decay. However, if we plot the inverse of the concentration, \\(\\frac{1}{[\\mathrm{A}]}\\), as a function of time, \\(t\\), we obtain a line with angular coefficient \\(+k_2\\), as in the plot of Figure 15.4. Figure 15.4: Linear Plot for a Second-Order Reaction. Notice that the Quantity on the y Axes is 1/[A]. Notice that the line has a positive angular coefficient, in contrast with the previous two cases, for which the angular coefficients were negative. The units of \\(k\\) for a simple second order reaction are calculated from eq. (15.8) and typically are \\(\\frac{1}{\\mathrm{M}\\cdot \\mathrm{s}}\\). The half-life of a simple second-order reaction is: \\[\\begin{equation} \\begin{aligned} \\frac{1}{\\frac{1}{2}[\\mathrm{A}]_0}-\\frac{1}{[\\mathrm{A}]_0} &amp;= k_2 t_{1/2} \\\\ t_{1/2} &amp;= \\frac{1}{k_2 [\\mathrm{A}]_0}, \\end{aligned} \\tag{15.9} \\end{equation}\\] which, perhaps not surprisingly, depends on the initial concentration of the reactant, \\([\\mathrm{A}]_0\\). Therefore, if we start with a higher concentration of the reactant, the half-life will be shorter, and the reaction will be faster. An example of simple second-order behavior is the reaction \\(\\mathrm{NO}_2 + \\mathrm{CO} \\rightarrow \\mathrm{NO} + \\mathrm{CO}_2\\), which is second-order in \\(\\mathrm{NO}_2\\) and zeroth-order in \\(\\mathrm{CO}\\). For the complex second-order case, the reaction is: \\[\\begin{equation} \\mathrm{A}+\\mathrm{B}\\rightarrow \\text{products} \\end{equation}\\] and the differential rate law is: \\[\\begin{equation} -\\frac{d[\\mathrm{A}]}{dt}=k&#39;_2 [\\mathrm{A}][\\mathrm{B}]. \\tag{15.10} \\end{equation}\\] The differential equation in eq. (15.10) has two variables, and cannot be solved exactly unless an additional relationship is specified. If we assume that the initial concentration of the two reactants are equal, then \\([\\mathrm{A}]=[\\mathrm{B}]\\) at any time \\(t\\), and eq. (15.10) reduces to eq. (15.7). If the concentration of the reactants are different, then the integrated rate law will assume the following shape: \\[\\begin{equation} \\frac{\\mathrm{[A]}}{\\mathrm{[B]}} = \\frac{\\mathrm{[A]_0}}{\\mathrm{[B]_0}} \\exp \\left\\{ \\left(\\mathrm{[A]_0} - \\mathrm{[B]_0}\\right) k&#39;_2t \\right\\}. \\tag{15.11} \\end{equation}\\] The units of \\(k\\) for a complex second order reaction can be calculated from eq. (15.11), and are the same as those for the simple case, \\(\\frac{1}{\\mathrm{M}\\cdot \\mathrm{s}}\\). The half-life of a complex second-order reaction cannot be easily written since two different half-lives could, in principle, be defined for each of the corresponding reactants. 15.1.4 Third and higher orders reaction Although elementary reactions with order higher than two are possible, they are in practice infrequent, and only very few experimental third-order reactions are observed. Fourth-order or higher have never been observed because the probabilities for a simultaneous interaction between four molecules are essentially zero. Third-order elementary reactions are also called termolelucar reactions. While termolelucar reactions with three identical reactants are possible in principle, there is no known experimental example. Some complex third-order reactions are known, such as: \\[\\begin{equation} 2\\text{NO}_{(g)}+\\text{O}_{2(g)}\\longrightarrow 2\\text{NO}_{2(g)} \\end{equation}\\] for which the differential rate law can be written as: \\[\\begin{equation} -\\frac{dP_{\\mathrm{O}_2}}{dt}=k_3 P_{\\mathrm{NO}}^2 P_{\\mathrm{O}_2}. \\tag{15.12} \\end{equation}\\] 15.2 Complex Rate Laws It is essential to specify that the order of a reaction and its molecularity are equal only for elementary reactions. Reactions that follow complex laws are composed of several elementary steps, and they usually have non-integer reaction orders, for at least one of the reactants. 15.2.1 Consecutive reactions A reaction that happens following a sequence of two elementary steps can be written as follows: \\[\\begin{equation} \\text{A}\\xrightarrow{\\;k_1\\;}\\text{B}\\xrightarrow{\\;k_2\\;}\\text{C} \\end{equation}\\] Assuming that each of the steps follows a first order kinetic law, and that only the reagent \\(\\mathrm{A}\\) is present at the beginning of the reaction, we can write the differential change in concentration of each species with respect to infinitesimal time \\(dt\\), using the following formulas: \\[\\begin{equation} \\begin{aligned} -\\frac{d[\\mathrm{A}]}{dt}&amp;=k_1 [\\mathrm{A}] \\Rightarrow [\\mathrm{A}] = [\\mathrm{A}]_0 \\exp(-k_1 t) \\\\ \\frac{d[\\mathrm{B}]}{dt} &amp;=k_1 [\\mathrm{A}]-k_2 [\\mathrm{B}] \\\\ \\frac{d[\\mathrm{C}]}{dt} &amp;=k_2 [\\mathrm{B}]. \\end{aligned} \\tag{15.13} \\end{equation}\\] These three equations represent a system of differential equations with three unknown variables. Unfortunately, these equations are linearly dependent on each other, and they are not sufficient to solve the system for each variable. To do so, we need to include a fourth equation, coming from the conservation of mass: \\[\\begin{equation} [\\mathrm{A}]_0=[\\mathrm{A}]+[\\mathrm{B}]+[\\mathrm{C}]. \\tag{15.14} \\end{equation}\\] Using the first equation in eq. (15.13), we can now replace the concentration \\([\\mathrm{A}]\\) in the second equation and solve for \\([\\mathrm{B}]\\): \\[\\begin{equation} \\frac{d[\\mathrm{B}]}{dt}+k_2 [\\mathrm{B}]=k_1 [\\mathrm{A}]_0 \\exp(-k_1 t), \\tag{15.15} \\end{equation}\\] which can be simplified by multiplying both sides by \\(\\exp (k_2t)\\): \\[\\begin{equation} \\begin{aligned} \\left( \\frac{d[\\mathrm{B}]}{dt}+k_2 [\\mathrm{B}] \\right) \\exp (k_2t) &amp;= k_1 [\\mathrm{A}]_0 \\exp[(k_2-k_1) t] \\\\ \\Rightarrow \\frac{d\\left\\{[\\mathrm{B}]\\exp (k_2t)\\right\\}}{dt} &amp;= k_1 [\\mathrm{A}]_0 \\exp[(k_2-k_1) t], \\end{aligned} \\tag{15.16} \\end{equation}\\] which can then be integrated remembering that \\([B]_0=0\\), and \\(\\int \\exp(kx)=\\frac{1}{k}\\exp(kx)\\): \\[\\begin{equation} [\\mathrm{B}] = \\frac{k_1}{k_2-k_1} [\\mathrm{A}]_0 [\\exp(-k_1t)-\\exp(-k_2t)]. \\tag{15.17} \\end{equation}\\] We can then use both \\([\\mathrm{A}]\\), from eq. (15.13), and \\([\\mathrm{B}]\\), from eq. (15.17), in eq. (15.14) to solve for \\([\\mathrm{C}]\\): \\[\\begin{equation} \\begin{aligned} \\left[\\mathrm{C}\\right] &amp;= [\\mathrm{A}]_0-[\\mathrm{A}]-[\\mathrm{B}] \\\\ &amp;= [\\mathrm{A}]_0-[\\mathrm{A}]_0 \\exp(-k_1 t)-\\frac{k_1}{k_2-k_1} [\\mathrm{A}]_0 [\\exp(-k_1t)-\\exp(-k_2t)] \\\\ &amp;= [\\mathrm{A}]_0\\left\\{1+\\frac{-k_2 \\exp(-k_1t)+ k_1 \\exp(-k_2t)}{k_2-k_1} \\right\\}. \\end{aligned} \\tag{15.18} \\end{equation}\\] From these results, we can distinguish two extreme behaviors. The first one is observed when \\(k_1 \\cong k_2\\), and it produces a plot of the concentration of species with respect to time reported in Figure 15.5. This behavior is observed when a process undergoing a series of consecutive reactions present a rate-determining step in the middle of the sequence (the second reaction, in the simple case analyzed above). Once the process is established, its rate will equate the rate of the slowest step. Figure 15.5: Concentration Plot for a Process with Two Consecutive Reactions with the Second One Being the Rate-Determining Step. The second behavior is observed when \\(k_1\\ll k_2\\), and it produces the plot in Figure 15.6 In this case, the concentration of the intermediate species \\(B\\) is not relevant throughout the process, and the rate-determining step is the first reaction. As such, the process has the same rate law as an elementary reaction going directly from \\(A\\) to \\(C\\). Figure 15.6: Concentration Plot for a Process with Two Consecutive Reactions with the First One Being the Rate-Determining Step. Since the concentration of \\(B\\) is small and relatively constant throughout the process, \\(\\frac{d[\\mathrm{B}]}{dT}=0\\). We can then simplify the mathematical treatment of these reactions by eliminating it from the process altogether. This simplification is known as the steady-state approximation. It is used in chemical kinetics to study processes that undergo a series of reactions producing intermediate species whose concentrations are constants throughout the entire process. \\[\\begin{equation} \\begin{aligned} \\text{A} &amp;\\xrightarrow{\\;k_1\\;} \\text{I}_1 \\xrightarrow{\\;k_2\\;} \\text{I}_2 \\xrightarrow{\\quad} \\cdots \\xrightarrow{\\;k_n\\;}\\text{products} \\\\ &amp; \\text{Steady State Approximation:} \\\\ \\text{A}&amp;\\xrightarrow{\\qquad\\qquad\\qquad\\qquad\\quad\\quad\\;\\;}\\text{products} \\end{aligned} \\tag{15.19} \\end{equation}\\] 15.2.2 Competitive reactions A process where two elementary reactions happen in parallel, competing with each can be written as follows: \\[\\begin{equation} \\begin{matrix} &amp;_{k_1} &amp; B\\\\ &amp;\\nearrow &amp; \\\\ A &amp; &amp; \\\\ &amp;\\searrow&amp; \\\\ &amp;_{k_2} &amp; C \\end{matrix} \\end{equation}\\] Assuming that each step follows first order kinetic, we can write: \\[\\begin{equation} \\begin{aligned} -\\frac{d[\\mathrm{A}]}{dt} &amp;=k_1 [\\mathrm{A}]+k_2 [\\mathrm{A}] \\Rightarrow [\\mathrm{A}]=[\\mathrm{A}]_0\\exp \\left[ -(k_1+k_2)t \\right] \\\\ \\frac{d[\\mathrm{B}]}{dt} &amp;=k_1 [\\mathrm{A}] \\Rightarrow [\\mathrm{B}]=\\frac{k_1}{k_1+k_2}[\\mathrm{A}]_0 \\left\\{ 1-\\exp \\left[ -(k_1+k_2)t \\right] \\right\\} \\\\ \\frac{d[\\mathrm{C}]}{dt} &amp;=k_2 [\\mathrm{A}]\\Rightarrow [\\mathrm{C}]=\\frac{k_2}{k_1+k_2}[\\mathrm{A}]_0 \\left\\{ 1-\\exp \\left[ -(k_1+k_2)t \\right] \\right\\}. \\end{aligned} \\tag{15.13} \\end{equation}\\] The concentration of each of the species can then be plotted against time, obtaining the diagram reported in Figure 15.7. The final concentrations of the products, \\([\\mathrm{B}]_f\\) and \\([\\mathrm{C}]_f\\), will depend on the values of the two rate coefficients. For example, if \\(k_1&gt;k_2\\), \\([\\mathrm{B}]_f&gt;[\\mathrm{C}]_f\\), as in Figure 15.7, but if \\(k_1&lt;k_2\\), \\([\\mathrm{B}]_f&lt;[\\mathrm{C}]_f\\). Figure 15.7: Concentration Plot for a Process with Two Competitive Reactions. An important relationship that can be derived from eq. (15.13) is that: \\[\\begin{equation} \\frac{[\\mathrm{B}]}{[\\mathrm{C}]} =\\frac{k_1}{k_2}. \\tag{15.14} \\end{equation}\\] 15.2.3 Opposed reactions Another case of complex kinetic law happens when a pair of forward and reverse reactions occur simultaneously: \\[\\begin{equation} \\mathrm{A}\\ce{&lt;=&gt;[k_1][k_{-1}]}\\mathrm{B} \\end{equation}\\] where the rate coefficients for the forward and backwards reaction, \\(k_1\\) and \\(k_{-1}\\) respectively, are not necessarily equal to each other, but comparable in magnitude. We can write the rate laws for each of these elementary steps as: \\[\\begin{equation} \\begin{aligned} -\\frac{d[\\mathrm{A}]}{dt} &amp;=k_1 [\\mathrm{A}]-k_{-1} [\\mathrm{B}] = k_1 [\\mathrm{A}]-k_{-1}\\left([\\mathrm{A}]_0-[\\mathrm{A}]\\right) \\\\ \\frac{d[\\mathrm{A}]}{dt} &amp;=-(k_1+k_{-1})[\\mathrm{A}] + k_{-1}[\\mathrm{A}]_0, \\end{aligned} \\tag{15.20} \\end{equation}\\] which can then be integrated to: \\[\\begin{equation} \\begin{aligned} \\left[\\mathrm{A}\\right] &amp;=[\\mathrm{A}]_0\\frac{k_{-1}+k_1\\exp[-(k_1+k_{-1})t]}{k_1+k_{-1}} \\\\ \\left[\\mathrm{B}\\right] &amp;=[\\mathrm{A}]_0\\left\\{ 1-\\frac{k_{-1}+k_1\\exp[-(k_1+k_{-1})t]}{k_1+k_{-1}}\\right\\}. \\end{aligned} \\tag{15.21} \\end{equation}\\] These formulas can then be used to obtain the plots in Figure 15.8. Figure 15.8: Concentration Plot for a Process with Two Opposed Reactions. As can be seen from the plots in Figure 15.8, after a sufficiently long time, the systems reach a dynamic equilibrium, where the concentration of \\(\\mathrm{A}\\) and \\(\\mathrm{B}\\) don’t change. These equilibrium concentrations can be calculated replacing \\(t=\\infty\\) in eq. (15.20): \\[\\begin{equation} \\begin{aligned} \\left[\\mathrm{A} \\right] _{\\mathrm{eq}} &amp;= [\\mathrm{A}]_0 \\frac{k_{-1}}{k_1+k_{-1}} \\\\ [\\mathrm{B}]_{\\mathrm{eq}} &amp;= [\\mathrm{A}]_0 \\frac{k_{1}}{k_1+k_{-1}}. \\end{aligned} \\tag{15.22} \\end{equation}\\] Considering that the concentrations of the species don’t change at equilibrium: \\[\\begin{equation} \\begin{aligned} -\\frac{d[\\mathrm{A}]_{\\mathrm{eq}}}{dt} &amp;= \\frac{d[\\mathrm{B}]_{\\mathrm{eq}}}{dt} = 0\\\\ &amp; \\Rightarrow \\; k_1[\\mathrm{A}]_{\\mathrm{eq}} = k_{-1}[\\mathrm{B}]_{\\mathrm{eq}} \\\\ &amp; \\Rightarrow \\; \\frac{k_1}{k_{-1}} = \\frac{[\\mathrm{B}]_{\\mathrm{eq}}}{[\\mathrm{A}]_{\\mathrm{eq}}} = K_C, \\\\ \\end{aligned} \\tag{15.23} \\end{equation}\\] where \\(K_C\\) is the equilibrium constant as defined in chapter 10. This is a rare link between kinetics and thermodynamics and appears only for opposed reactions after sufficient time has passed so that the system can reach the dynamic equilibrium. 15.3 Experimental Methods for Determination of Reaction Orders To experimentally measure the reaction rate, we need a method to measure concentration changes with respect to time. The simplest way to determine the reaction rate is to monitor the entire reaction as it proceeds and then plot the resulting data differently until a linear plot is found. A summary of the results obtained in section 15.1 and that is useful for this task is reported in the following table: Zeroth-Order First-Order Simple Second-Order Complex Second-Order Differential Rate Law \\(-\\frac{d[\\mathrm{A}]}{dt}=k_0 [\\mathrm{A}]^0 = k_0\\) \\(-\\frac{d[\\mathrm{A}]}{dt}=k_1 [\\mathrm{A}]\\) \\(-\\frac{d[\\mathrm{A}]}{dt}=k_2 [\\mathrm{A}]^2\\) \\(-\\frac{d[\\mathrm{A}]}{dt}=k&#39;_2 [\\mathrm{A}][\\mathrm{B}]\\) Integrated Rate Law \\([\\mathrm{A}]=[\\mathrm{A}]_0 -k_0 t\\) \\([\\mathrm{A}]=[\\mathrm{A}]_0 e^{-k_1 t}\\) \\(\\frac{1}{[\\mathrm{A}]}=\\frac{1}{[\\mathrm{A}]_0} + k_2 t\\) \\(\\frac{\\mathrm{[A]}}{\\mathrm{[B]}}=\\frac{\\mathrm{[A]_0}}{\\mathrm{[B]_0}}e^{\\left(\\mathrm{[A]_0}-\\mathrm{[B]_0}\\right)k&#39;_2t}\\) Units of \\(k\\) \\(\\frac{\\mathrm{M}}{\\mathrm{s}}\\) \\(\\frac{1}{\\mathrm{s}}\\) \\(\\frac{1}{\\mathrm{M}\\cdot \\mathrm{s}}\\) \\(\\frac{1}{\\mathrm{M}\\cdot \\mathrm{s}}\\) Linear Plot vs. \\(t\\) \\([\\mathrm{A}]\\) \\(\\ln [\\mathrm{A}]\\) \\(\\frac{1}{[\\mathrm{A}]}\\) \\(\\ln \\frac{[\\mathrm{A}]_0[\\mathrm{B}]}{[\\mathrm{B}]_0[\\mathrm{A}]}\\) Half-life \\(t_{1/2}=\\frac{[\\mathrm{A}]_0}{2k_0}\\) \\(t_{1/2}=\\frac{\\ln 2}{k_1}\\) \\(t_{1/2}=\\frac{1}{k_2 [\\mathrm{A}]_0}\\) not easily defined However, this method works only if the reaction has few reactants, and it requires several measurements, each of which might be complicated to make. More useful methods to determine the reaction rate are the initial rate and the isolation methods that we describe below. 15.3.1 Initial rates method The initial rates method involves measuring the rate of a reaction as soon as it starts before any significant change in the concentrations of the reactants occurs. The initial rate method is practical only if the reaction is reasonably slow, but it can measure the rate unambiguously when more than one reactant is involved. For example, if we have a reaction with the following stoichiometry: \\[\\begin{equation} \\alpha \\mathrm{A} + \\beta \\mathrm{B} \\xrightarrow{k} \\text{products} \\end{equation}\\] the initial rate method can be used to determine the coefficients of the rate law: \\[\\begin{equation} \\text{Rate}=k[\\mathrm{A}]^{\\alpha}[\\mathrm{B}]^{\\beta} \\tag{15.24} \\end{equation}\\] by designing three experiment, where the initial concentrations of \\(\\mathrm{A}\\) and \\(\\mathrm{B}\\) are appropriately changed. For example, let’s consider the following experimental data from three different experiments: \\([\\mathrm{A}]_0 \\; (\\text{M})\\) \\([\\mathrm{A}]_0 \\; (\\text{M})\\) \\(\\text{initial rate}\\;\\left(\\frac{M}{s}\\right)\\) \\(\\text{Experiment 1:}\\) 0.10 0.10 4.32 \\(\\text{Experiment 2:}\\) 0.15 0.10 9.70 \\(\\text{Experiment 3:}\\) 0.10 0.20 4.29 we can calculate \\(\\alpha\\) by taking the ratio of the rates measured in experiment 1 and 2: \\[\\begin{equation} \\begin{aligned} \\frac{\\text{Rate}(1)}{\\text{Rate}(2)}&amp;=\\frac{k(0.10\\;\\text{M})^\\alpha(0.10\\;\\text{M})^\\beta}{k(0.15\\;\\text{M})^\\alpha(0.10\\;\\text{M})^\\beta} \\\\ \\frac{4.32}{9.70}&amp;=\\frac{(0.10\\;\\text{M})^\\alpha}{(0.15\\;\\text{M})^\\alpha} \\\\ 0.445&amp;=0.667^\\alpha \\;\\rightarrow\\; \\ln0.445=\\alpha \\ln0.667 \\\\ \\alpha &amp;= \\frac{-0.81}{-0.405}=2. \\end{aligned} \\tag{15.25} \\end{equation}\\] \\(\\beta\\) can be calculated similarly by taking the ratio between experiments 1 and 3. Alternatively, we can also notice that the reaction rate does not change when the initial concentration \\([\\mathrm{B}]_0\\) is doubled, therefore \\(\\beta=0\\). 15.3.2 Isolation method Another method that is widely used to determine reaction orders is the isolation method. This method is performed by using large excess concentrations of all reactants but one. For example, if we have the following reaction with three reagents and unknown rate law: \\[\\begin{equation} \\alpha \\mathrm{A} + \\beta \\mathrm{B} + \\gamma \\mathrm{C} \\xrightarrow{k} \\text{products} \\end{equation}\\] we can perform three different experiments, in each of which we use an excessive amount of one of the two reagents, such as: Experiment 1: \\([\\mathrm{A}]_0=1\\;\\text{M},\\quad [\\mathrm{B}]_0=1000\\;\\text{M}, \\quad [\\mathrm{C}]_0=1000\\;\\text{M},\\) in which the reaction order with respect to \\(\\mathrm{A}\\) is measured. Experiment 2: \\([\\mathrm{A}]_0=1000\\;\\text{M},\\quad [\\mathrm{B}]_0=1\\;\\text{M}, \\quad [\\mathrm{C}]_0=1000\\;\\text{M},\\) in which the reaction order with respect to \\(\\mathrm{B}\\) is measured. Experiment 3: \\([\\mathrm{A}]_0=1000\\;\\text{M},\\quad [\\mathrm{B}]_0=1000\\;\\text{M}, \\quad [\\mathrm{C}]_0=1\\;\\text{M},\\) in which the reaction order with respect to \\(\\mathrm{C}\\) is measured. From each experiment we can determine the pseudo-order of the reaction with respect to the reagent that is in minority concentration. For example, for the reaction above, we can write the rate law as: \\[\\begin{equation} \\text{Rate}=k[\\mathrm{A}]^{\\alpha}[\\mathrm{B}]^{\\beta}[\\mathrm{C}]^{\\gamma} \\tag{15.25} \\end{equation}\\] and we can write the initial concentrations, \\([X]_0\\), and the final concentrations, \\([X]_f\\), of each of the species in experiment 1, as: \\[\\begin{equation} \\begin{aligned} \\left[\\mathrm{A}\\right]_0 =1\\;\\text{M}\\;\\longrightarrow &amp;[\\mathrm{A}]_f=0\\;\\text{M} \\qquad &amp;\\text{(100\\% change)} \\\\ \\left[\\mathrm{B}\\right]_0 =1000\\;\\text{M}\\;\\longrightarrow &amp;[\\mathrm{B}]_f=1000-1=999\\;\\text{M}\\cong [\\mathrm{B}]_0\\qquad &amp;\\text{(0.1\\% change)}\\\\ \\left[\\mathrm{C}\\right]_0 =1000\\;\\text{M}\\;\\longrightarrow &amp;[\\mathrm{C}]_f=1000-1=999\\;\\text{M} \\cong \\left[\\mathrm{C}\\right]_0. \\qquad &amp;\\text{(0.1\\% change)} \\end{aligned} \\end{equation}\\] The coefficient \\(\\alpha\\) can then be determined by incorporating the concentration of the reactants in excess into the rate constant as: \\[\\begin{equation} \\begin{aligned} \\text{rate}&amp;=k[\\mathrm{A}]^{\\alpha}\\underbrace{[\\mathrm{B}]^{\\beta}[\\mathrm{C}]^{\\gamma}}_{\\text{constant}} \\\\ &amp;= k&#39;[\\mathrm{A}]^{\\alpha} \\end{aligned} \\end{equation}\\] and then determine \\(\\alpha\\) by verifying which order the data collected for \\([\\mathrm{A}]\\) at various time fit. This can be simply achieved by using the zero-, first-, and second-order kinetic plots, as reported in the table above. We can determine \\(\\beta\\) and \\(\\gamma\\) by repeating the same procedure for the data from the other two experiments. For example, if we find for a specific reaction that \\(\\alpha=\\) 1, \\(\\beta=2\\), and \\(\\gamma=0\\), we can then say that the reaction is pseudo-order one in \\(\\mathrm{A}\\), pseudo-order two in \\(\\mathrm{B}\\), and pseudo-order zero in \\(\\mathrm{C}\\), with an overall reaction order of three. 15.4 Temperature Dependence of the Rate Coefficients The dependence of the rate coefficient, \\(k\\), on the temperature is given by the Arrhenius equation. This formula was derived by Svante August Arrhenius (1859–1927) in 1889 and is based on the simple experimental observation that every chemical process gets faster when the temperature is increased. Working on data from equilibrium reactions previously reported by van ’t Hoff, Arrhenius proposed the following simple exponential formula to explain the increase of \\(k\\) when \\(T\\) is increased: \\[\\begin{equation} k=A\\exp\\left( \\frac{E_a}{RT}\\right), \\tag{15.26} \\end{equation}\\] where \\(A\\) is the so-called Arrhenius pre-exponential factor, and \\(E_a\\) is the activation energy. Both of these terms are independent of temperature,62 and they represent experimental quantities that are unique to each individual reaction. Since there is no known exception to the fact that a temperature increase speeds up chemical reactions, both \\(A\\) and \\(E_a\\) are always positive. The pre-exponential factor units are the same as the rate constant and will vary depending on the order of the reaction. As suggested by its name, the activation energy has units of energy per mole of substance, \\(\\frac{\\mathrm{J}}{\\mathrm{mol}}\\) in SI. The Arrhenius equation is experimentally useful in its linearized form, which is obtained from two Arrhenius experiments, taken at different temperatures. Applying eq. (15.26) to two different experiments, and taking the ratio between the results, we obtain: \\[\\begin{equation} \\ln \\frac{k_{T_2}}{k_{T_1}}=-\\frac{E_a}{RT}\\left(\\frac{1}{T_2}-\\frac{1}{T_1}\\right), \\tag{15.27} \\end{equation}\\] which gives the plot of Figure 15.9, from which \\(E_a\\) can be determined. Figure 15.9: Arrhenius Plot Obtained Using Experimental Data at Two Different Temperatures. From empirical arguments, Arrhenius proposed the idea that reactants must acquire a minimum amount of energy before they can form any product. He called this amount of minimum energy the activation energy. We can motivate this assumption by plotting energy of a reaction along the reaction coordinate, as in Figure 15.10.63 The reaction coordinate is defined as the minimum energy path that connects the reactants with the products. Figure 15.10: Reaction Coordinate Diagram for a Typical Reaction. Notice how large these numbers are for uranium. To put these numbers in perspective, we can compare them with the half-life of the most unstable isotope of plutonium, \\(^{241}\\mathrm{Pu}\\), which is \\(t_{1/2}=14.1\\) years.↩︎ In theory, both \\(A\\) and \\(E_a\\) show a weak temperature dependence. However, they can be considered constants at most experimental conditions, since kinetic studies are usually performed in a small temperature range.↩︎ This plot is taken from Wikipedia, and have been generated and distributed by Author Grimlock under CC-BY-SA license.↩︎ "],
["appendix.html", "16 Appendix 16.1 Thermodynamic Data of Inorganic Substances at 298 K 16.2 Thermodynamic Data of Organic Substances at 298 K", " 16 Appendix 16.1 Thermodynamic Data of Inorganic Substances at 298 K Substance: \\(\\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) \\(\\scriptstyle{\\text{[kJ/mol]}}\\) \\(\\Delta_{\\text{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) \\(\\scriptstyle{\\text{[kJ/mol]}}\\) \\(S^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) \\(\\scriptstyle{\\text{[J/(mol K)]}}\\) \\(C_P\\) \\(\\scriptstyle{\\text{[J/(mol K)]}}\\) Ag(g) 284.9 246 173 20.8 Ag(s) 0 0 42.6 25.4 Ag+(aq) 105.8 77.1 73.5 AgCN(s) 146 156.9 107.2 66.7 Ag2CO3(s) –505.8 –436.8 167.4 112.3 AgNO3(s) –124.4 –33.4 140.9 93.1 Ag2O(s) –31.1 –11.2 121.3 65.9 Ag2S(s) –32.6 –40.7 144 76.5 AgBr(s) –100.4 –96.9 107.1 52.4 AgCl(s) –127.0 –109.8 96.3 50.8 AgF(s) –204.6 –187 84 AgI(s) –61.8 –66.2 115.5 56.8 Al(g) 330 289.4 164.6 21.4 Al(s) 0 0 28.3 24.2 Al2O3(s) –1675.7 –1582.3 50.9 79.0 AlF3(s) –1510.4 –1431.1 66.5 75.1 AlI3(s) –302.9 195.9 AlBr3(s) –527.2 180.2 100.6 AlCl3(s) –704.5 –628.11 112.3 91.1 Al(OH)3(s) –1277 Al(OH)4-(aq) –1490 –1297 117 AlPO4(s) –1733.8 –1617.9 90.8 93.2 Ar(g) 0 154.9 20.8 B(s) 0 0 5.9 11.1 B(g) 565 521.0 153.4 20.8 BH(g) 442.7 412.7 171.8 29.2 BH3(g) 89.2 93.3 188.2 36.0 B2S3(s) –240.6 100.0 111.7 Ba(g) 180 146 170.2 Ba(s) 0 0 62.5 28.1 BaCO3(s) –1213.0 –1134.4 112.1 86.0 BaH2(s) –177 –138.2 63.0 BaBr2(s) –757.3 –736.8 146.0 BaCl2(s) –855 –806.7 123.7 75.1 BaF2(s) –1207.1 –1156.8 96.4 71.2 BaI2(s) –602.1 –597 167.0 BaO(s) –548.0 –520.3 72.1 47.3 BaSO4(s) –1473.2 –1362.2 132.2 101.8 Be(g) 324 286.6 136.3 20.8 Be(s) 0 0 9.5 13.4 BeBr2(s) –353.5 108 69.4 BeCl2(s) –490.4 –445.6 75.8 62.4 BeF2(s) –1026.8 –979.4 53.4 51.8 BeI2(s) –192.5 121 71.1 BeO(s) –609.4 –580.1 13.8 25.6 Be(OH)2(s) –902.5 –815.0 45.5 62.1 BeSO4(s) –1205.2 –1093.8 77.9 85.7 Bi(g) 207.1 168.2 187 20.8 Bi(s) 0 0 56.7 25.5 Bi2O3(s) –573.9 –493.7 151.5 113.5 BiCl3(s) –379.1 –315.0 177.0 105.0 Br–(aq) –121.4 –104.0 82.6 Br(g) 111.9 82.4 175 20.8 Br2(g) 30.9 3.1 245.5 36.0 Br2(l) 0 0 152.2 75.7 BrCl(g) 14.6 –1 240.1 35.0 BrF(g) –93.8 –109.2 229 33.0 BrF3(g) –1136 1119.4 254.4 66.6 C(g) 716.7 671.3 158.1 0.8 C(s,diamond) 1.9 2.9 2.4 6.1 C(s,graphite) 0 0 5.7 8.5 CBr4(g) 83.9 67 358.1 CBr4(s) 29.4 47.7 212.5 CCl2F2(g) –477.4 –439.4 300.8 CCl2O(g) –219.1 –204.9 283.5 CCl4(g) –95.7 –53.6 309.9 CCl4(l) –128.2 –62.6 216.2 CF4(g) –933.6 –888.3 261.6 CS2(g) 116.7 67.1 237.8 45.4 CS2(l) 89 64.6 151.3 76.4 CO(g) –110.5 –137.2 197.7 29.1 CO2(g) –393.5 –394.4 213.8 37.1 Ca(g) 177.8 144 154.9 20.8 Ca(s) 0 0 41.6 25.9 Ca(OH)2(s) –985.2 –897.5 83.4 87.5 CaBr2(s) –682.8 –663.6 130 CaCl2(s) –795.4 –748.8 108.4 72.9 CaCN(s) –184.5 CaCO3(s,arag.) –1207.8 –1128.2 88 82.3 CaCO3(s,calc.) –1207.6 –1129.1 91.7 83.5 CaF2(s) –1228.0 –1175.6 68.5 67.0 CaH2(s) –181.5 –142.5 41.4 41.0 CaI2(s) –533.5 –528.9 142 CaO(s) –634.9 –603.3 38.1 42.0 CaSO4(s) –1434.5 –1322.0 106.5 99.7 Cd(g) 111.8 167.7 20.8 Cd(s) 0 0 51.8 26.0 CdBr2(s) –316.2 –296.3 137.2 76.7 CdCl2(s) –391.5 –343.9 115.3 74.7 CdCO3(s) –750.6 –669.4 92.5 CdF2(s) –700.4 –647.7 77.4 CdS(s) –161.9 –156.5 64.9 CdSO4(s) –933.3 –822.7 123.0 99.6 Cl–(aq) –167.1 –131.2 56.6 Cl(g) 121.3 105.3 165.2 21.8 Cl2(g) 0 0 223.1 33.9 ClF(g) –50.3 –51.8 217.9 32.1 ClF3(g) –163.2 –123.0 281.6 63.9 ClO2(g) 89.1 105 263.7 46.0 Cl2O(g) 80.3 97.9 266.2 45.4 Co(g) 424.7 380.3 179.5 23.0 Co(s) 0 0 30 24.8 CoCl2(s) –312.5 –269.8 109.2 78.5 Cr(g) 396.6 351.8 174.5 20.8 Cr(s) 0 0 23.8 23.4 Cr2O3(s) –1139.7 –1058.1 81.2 118.7 CrCl2(s) –395.4 –356 115.3 71.2 CrCl3(s) –556.5 –486.1 123 91.8 CrO2(g) –598 CrO3(g) –292.9 266.2 56.0 Cs(g) 76.5 49.6 175.6 20.8 Cs(s) 0 0 85.2 32.2 CsCl(s) –443.0 –414.5 101.2 52.5 Cu(g) 337.4 297.7 166.4 20.8 Cu(s) 0 0 33.2 24.2 Cu2O(s) –168.6 –146.0 93.1 63.6 CuO(s) –157.3 –129.7 42.6 Cu2S(s) –79.5 –86.2 120.9 76.3 CuS(s) –53.1 –53.6 66.5 47.8 CuSO4(s) –771.4 –662.2 109.2 CuBr(s) –104.6 –100.8 96.1 54.7 CuBr2(s) –141.8 CuCl(s) –137.2 –119.9 86.2 48.5 CuCl2(s) –220.1 –175.7 108.1 71.9 CuCN(s) 96.2 111.3 84.5 F–(aq) –335.4 –278.8 –13.8 | F(g) 79.4 62.3 158.8 22.7 F2(g) 0 0 202.8 32.3 F2O(g) 24.5 41.8 247.5 43.3 FO(g) 109 105.3 216.4 32.0 FB(g) –122.2 –149.8 200.5 58.6 Fe(g) 416.3 370.7 180.5 25.7 Fe(s) 0 0 27.3 25.1 FeO(s) –272.0 –251.4 60.7 Fe2+(aq) –89.1 –78.9 –137.7 | Fe2O3(s) –824.2 –742.2 87.4 103.9 Fe3+(aq) –48.5 –4.7 –315.9 | Fe3O4(s) –1118.4 –1015.4 146.4 143.4 FeCO3(s) –740.6 –666.7 92.9 82.1 FeS2(s) –178.2 –166.9 52.9 62.2 FeCl2(s) –341.8 –302.3 118 75.7 FeCl3(s) –399.5 –334.0 142.3 96.7 FeBr2(s) –249.8 –238.1 140.6 FeBr3(s) –268.2 Fe3C(s) 25.1 20.1 104.6 105.9 H(g) 218.0 203.3 114.7 20.8 H+(aq) 0 0 0 H2(g) 0 0 130.7 28.8 H2O(g) –241.8 –228.6 188.8 33.6 H2O(l) –285.8 –237.1 70.0 75.3 H2O2(g) –136.3 –105.6 232.7 43.1 H2O2(l) –187.8 –120.4 109.6 89.1 H2S(g) –20.6 –33.4 205.8 34.2 H2Se(g) 29.7 15.9 219 34.7 H2SO4(aq) –909.3 –744.5 20.1 H2SO4(l) –814.0 –690.0 156.9 138.9 H3PO4(l) –1271.7 –1123.6 150.8 145.0 H3PO4(s) –1284.4 –1124.3 110.5 106.1 HBr(aq) –121.6 –104.0 82.4 HBr(g) –36.3 –53.4 198.7 29.1 HCl(aq) –167.2 –131.2 56.5 HCl(g) –92.3 –95.3 186.9 29.1 HCN(g) 135.1 124.7 201.8 35.9 HCN(l) 108.9 125 112.8 70.6 HF(aq) –332.6 –278.8 –13.8 | HF(g) –273.3 –275.4 173.8 HI(aq) –55.2 –51.6 111.3 HI(g) 26.5 1.7 206.6 29.2 HNO2(g) –79.5 –46.0 254.1 HNO3(aq) –207.4 –111.3 146.4 HNO3(g) –133.9 –73.5 266.9 54.1 HNO3(l) –174.1 –80.7 155.6 109.9 He(g) 0 0 126.2 20.8 Hg(g) 61.4 31.8 175 Hg(l) 0 0 75.9 28.0 Hg2(g) 108.8 68.2 288.1 HgO(s) –90.8 –58.5 70.3 44.1 HgS(s,red) –58.2 –50.6 82.4 48.4 Hg2SO4(s) –743.1 –625.8 200.7 132.0 HgSO4(s) –707.5 Hg2Cl2(s) –265.4 –210.7 191.6 191.6 HgCl2(s) –224.3 –178.6 146.0 146.0 Hg2Br2(s) –206.9 –181.1 218.0 218.0 HgBr2(s) –170.7 –153.1 172.0 172.0 Hg2I2(s) –121.3 –111 233.5 233.5 HgI2(s) –105.4 –101.7 180.0 180.0 I–(aq) –56.8 –51.6 106.5 I(g) 106.8 70.2 180.8 20.8 I2(g) 62.4 19.3 260.7 36.9 I2(s) 0 0 116.1 54.4 HIO3(s) –230.1 IBr(g) 40.8 3.7 258.8 36.4 ICl(g) 17.8 –5.5 247.6 35.6 IF(g) –95.7 –118.5 236.2 33.4 K(g) 89.0 60.5 160.3 20.8 K(s) 0 0 64.7 29.6 K2CO3(s) –1151.0 –1063.5 155.5 114.4 K2O(s) –361.5 –322.1 94.1 K2O2(s) –494.1 –425.1 102.1 K2SO4(s) –1437.8 –1321.4 175.6 131.5 KBr(s) –393.8 –380.7 95.9 52.3 KCl(s) –436.5 –408.5 82.6 51.3 KF(s) –567.3 –537.8 66.6 49.0 KI(s) –327.9 –324.9 106.3 52.9 KClO3(s) –397.7 –296.3 143.1 100.3 KMnO4(s) –837.2 –737.6 171.7 117.6 KNO2(s) –369.8 –306.6 152.1 107.4 KNO3(s) –494.6 –394.9 133.1 96.4 KSCN(s) –200.2 –178.3 124.3 88.5 Kr(g) 0 0 164.1 20.8 Li(g) 159.3 126.6 138.8 20.8 Li(s) 0 0 29.1 24.9 Li+(aq) –278.5 –293.3 12.4 Li2O(s) –597.9 –561.2 37.6 54.1 LiOH(s) –487.5 –441.5 42.8 49.6 LiNO3(s) –483.1 –381.1 90.0 LiBr(s) –351.2 –342 74.3 LiCl(s) –408.6 –384.4 59.3 48.0 LiF(s) –616 –587.7 35.7 41.6 LiI(s) –270.4 –270.3 86.8 51.0 Mg(g) 147.1 112.5 148.6 20.8 Mg(s) 0 0 32.7 24.9 MgO(s) –601.6 –569.3 27.0 37.2 Mg(OH)2(s) –924.5 –833.5 63.2 77.0 MgS(s) –346.0 –341.8 50.3 45.6 MgSO4(s) –1284.9 –1170.6 91.6 96.5 MgBr2(s) –524.3 –503.8 117.2 MgCl2(s) –641.3 –591.8 89.6 71.4 MgF2(s) –1124.2 –1071.1 57.2 61.6 Mn(g) 280.7 238.5 173.7 20.8 Mn(s) 0 0 32 26.3 MnO(s) –385.2 –362.9 59.7 45.4 MnO2(s) –520.0 –465.1 53.1 54.1 MnO4–(aq) –541.4 –447.2 191.2 MnBr2(s) –384.9 MnCl2(s) –481.3 –440.5 118.2 72.9 Mo(g) 658.1 612.5 182 20.8 Mo(s) 0 0 28.7 24.1 MoO2(s) –588.9 –533.0 46.3 56.0 MoO3(s) –745.1 –668.0 77.7 75.0 MoS2(s) –235.1 –225.9 62.6 63.6 MoS3(s) –364 –354 119 N(g) 472.7 455.5 153.3 20.8 N2(g) 0 0 191.6 29.1 NF3(g) –132.1 –90.6 260.8 53.4 NH3(g) –45.9 –16.4 192.8 35.1 NH4+(aq) –133.3 –79.3 111.2 NH4Cl(s) –314.4 –202.9 94.6 84.1 NH4NO3(s) –365.6 –183.9 151.1 139.3 NH4OH(l) –361.2 –254.0 165.6 154.9 (NH4)2SO4(s) –1180.9 –901.7 220.1 187.5 N2H4(g) 95.4 159.4 238.5 N2H4(l) 50.6 149.3 121.2 NO2(g) 33.2 51.3 240.1 37.2 N2O(g) 81.6 103.7 220 38.6 NO(g) 91.3 87.6 210.8 N2O4(g) 11.1 99.8 304.4 79.2 N2O4(l) –19.5 97.5 209.2 142.7 Na(g) 107.5 77 153.7 20.8 Na(s) 0 0 51.3 28.2 Na+(aq) –240.2 –261.9 58.5 Na2CO3(s) –1130.7 –1044.4 135 112.3 Na2O(s) –414.2 –375.5 75.1 69.1 Na2O2(s) –510.9 –447.7 95 89.2 Na2SO4(s) –1387.1 –1270.2 149.6 128.2 NaBr(aq) –361.7 –365.8 141.4 NaBr(g) –143.1 –177.1 241.2 36.3 NaBr(s) –361.1 –349.0 86.8 51.4 NaCl(aq) –407.3 –393.1 115.5 NaCl(s) –411.2 –384.1 72.1 50.5 NaCN(s) –87.5 –76.4 115.6 70.4 NaF(aq) –572.8 –540.7 45.2 NaF(s) –576.6 –546.3 51.1 46.9 NaN3(s) 21.7 93.8 96.9 76.6 NaNO3(aq) –447.5 –373.2 205.4 NaNO3(s) –467.9 –367.0 116.5 92.9 NaO2(s) –260.2 –218.4 115.9 72.1 NaOH(s) –425.8 –379.7 64.4 59.5 NaH(s) –56.3 –33.6 40 36.4 Ne(g) 0 0 146.3 20.8 Ni(g) 429.7 384.5 182.2 23.4 Ni(s) 0 0 29.9 26.1 Ni2O3(s) –489.5 Ni(OH)2(s) –529.7 –447.2 88 NiBr2(s) –212.1 NiCl2(s) –305.3 –259.0 97.7 71.7 NiF2(s) –651.4 –604.1 73.6 64.1 O(g) 249.2 231.7 161.1 21.9 O2(g) 0 0 205.2 29.4 O3(g) 142.7 163.2 238.9 39.2 OH–(aq) –230.0 –157.2 –10.9 | Os(g) 791 745 192.6 20.8 Os(s) 0 0 32.6 24.7 OsO4(g) –337.2 –292.8 293.8 74.1 OsO4(s) –394.1 –304.9 143.9 P(g,white) 316.5 280.1 163.2 20.8 P(s,black) –39.3 P(s,red) –17.6 –12.5 22.8 21.2 P(s,white) 0 0 41.1 23.8 P2(g) 144.0 103.5 218.1 P4(g) 58.9 24.4 280.0 PCl3(g) –287.0 –267.8 311.8 71.8 PCl3(l) –319.7 –272.3 217.1 PCl5(g) –374.9 –305.0 364.6 112.8 PH3(g) 5.4 13.5 210.2 37.1 POCl3(g) –558.5 –512.9 325.5 POCl3(l) –597.1 –520.8 222.5 Pb(g) 195.2 162.2 175.4 20.8 Pb(s) 0 0 64.8 26.8 PbCl2(s) –359.4 –314.1 136 PbCO3(s) –699.1 –625.5 131 87.4 PbO(s,litharge) –219.0 –188.9 66.5 45.8 PbO(s,massic.) –217.3 –187.9 68.7 45.8 PbO2(s) –277.4 –217.3 68.6 64.6 Pb(NO3)2(aq) –416.3 –246.9 303.3 Pb(NO3)2(s) –451.9 PbS(s) –100.4 –98.7 91.2 49.5 PbSO4(s) –920.0 –813.0 148.5 103.2 Rb(g) 80.9 53.1 170.1 20.8 Rb(s) 0 0 76.8 31.1 RbCl(s) –435.4 –407.8 95.9 52.4 S(g,rhombic) 277.2 236.7 167.8 23.7 S(s,rhombic) 0 0 32.1 22.6 SO2(g) –296.8 –300.1 248.2 39.9 SO3(g) –395.7 –371.1 256.8 50.7 SO42–(aq) –909.3 –744.5 18.5 SOCl2(g) –212.5 –198.3 309.8 Se(g,gray) 227.1 187 176.7 Se(s,gray) 0 0 42.4 25.4 Si(g) 450 405.5 168.0 22.3 Si(s) 0 0 18.8 20.0 SiC(s,cubic) –65.3 –62.8 16.6 26.9 SiC(s,hexag.) –62.8 –60.2 16.5 26.7 SiCl4(g) –657.0 –617.0 330.7 SiCl4(l) –687.0 –619.8 239.7 SiH4(g) 34.3 56.9 204.6 42.8 Sn(g,white) 301 266.2 168.5 21.3 Sn(s,gray) –2.1 0.1 44.1 25.8 Sn(s,white) 0 0 51.2 27.0 SnCl4(g) –471.5 –432.2 365.8 98.3 SnCl4(l) –511.3 –440.1 258.6 165.3 SnO2(s) –557.6 –515.8 49 52.6 Ti(g) 473 428.4 180.3 24.4 Ti(s) 0 0 30.7 25.1 TiCl2(s) –513.8 –464.4 87.4 69.8 TiCl3(s) –720.9 –653.5 139.7 97.2 TiCl4(g) –763 –726.3 353 95.4 TiCl4(l) –804.2 –737.2 252.3 145.2 TiO2(s) –944.0 –888.8 50.6 55.0 U(g) 533 488.4 199.8 23.7 U(s) 0 0 50.2 27.7 UF4(g) –1598.7 –1572.7 368 91.2 UF4(s) –1914.2 –1823.3 151.7 116.0 UF6(g) –2147.4 –2063.7 377.9 129.6 UF6(s) –2197.0 –2068.5 227.6 166.8 UO2(g) –465.7 –471.5 274.6 51.4 UO2(s) –1085.0 –1031.8 77.0 63.6 V(g) 514.2 754.4 182.3 26.0 V(s) 0 0 28.9 24.9 V2O5(s) –1550.6 –1419.5 131.0 127.7 VCl3(s) –580.7 –511.2 131.0 93.2 VCl4(g) –525.5 –492.0 362.4 96.2 VCl4(l) –569.4 –503.7 255.0 Xe(g) 0 0 169.7 20.8 Zn(g) 130.4 94.8 161.0 20.8 Zn(s) 0 0 41.6 25.4 ZnBr2(s) –328.7 –312.1 138.5 ZnCl2(s) –415.1 –369.4 111.5 71.3 ZnF2(s) –764.4 –713.3 73.7 65.7 ZnI2(s) –208.0 –209.0 161.1 Zn(NO3)2(s) –483.7 ZnS(s,sphaler.) –206.0 –201.3 57.7 46.0 ZnSO4(s) –982.8 –871.5 110.5 99.2 Zr(g) 608.8 566.5 181.4 26.7 Zr(s) 0 0 39 25.4 ZrCl2(s) –502.0 –386 110 ZrCl4(s) –980.5 –889.9 181.6 119.8 16.2 Thermodynamic Data of Organic Substances at 298 K Formula: Name: \\(\\Delta_{\\text{f}} H^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) \\(\\scriptstyle{\\text{[kJ/mol]}}\\) \\(\\Delta_{\\text{f}} G^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) \\(\\scriptstyle{\\text{[kJ/mol]}}\\) \\(S^{-\\kern-6pt{\\ominus}\\kern-6pt-}\\) \\(\\scriptstyle{\\text{[J/(mol K)]}}\\) \\(C_P\\) \\(\\scriptstyle{\\text{[J/(mol K)]}}\\) CHBr3 Bromoform(g) 25 16 331 71 CHCl3 Chloroform(l) –134.1 –73.7 201.7 114.2 CHCl3 Chloroform(g) –102.7 6.0 295.7 65.7 CH2O2 Formic acid(l) –425 –361.4 129 99 CH2O2 Formic acid(g) –378.7 CH3 Methyl(g) 145.7 47.9 194.2 38.7 CH3Br Bromomethane(l) –59.8 CH3Br Bromomethane(g) –35.4 –26.3 246.4 42.4 CH3Cl Chloromethane(g) –81.9 –63 234.6 40.8 CH3F Fluormethane(g) –234 –210 222.9 37.5 CH3I Iodomethane(l) –13.6 136.2 126 CH3I Iodomethane(g) 14.4 16 254.1 44.1 CH3NO2 Nitromethane(l) –112.6 –14.4 171.8 106.6 CH3NO2 Nitromethane(g) –80.8 –7 282.9 55.5 CH4 Methane(g) –74.6 –50.5 186.3 35.7 CH4O Methanol(l) –239.2 –166.6 126.8 81.1 CH4O Methanol(g) –201 –162.3 239.9 44.1 CH5N Methylamine(l) –47.3 35.7 150.2 102.1 CH5N Methylamine(g) –22.5 32.7 242.9 50.1 C2H2 Ethyne (acetylene)(g) 226.9 209 201 44 C2H4 Ethene(g) 52.5 68.4 219.3 42.9 C2H4O2 Acetic acid(l) –484.3 –389.9 159.8 123.3 C2H4O2 Acetic acid(g) –432.2 –374.2 283.5 63.4 C2H5Br Bromoethane(l) –90.5 –25.8 198.7 100.8 C2H5Br Bromoethane(g) –61.9 –23.9 286.7 64.5 C2H5Cl Chloroethane(l) –136.8 –59.3 190.8 104.3 C2H5Cl Chloroethane(g) –112.1 –60.4 276 62.8 C2H5NO2 Nitroethane(l) –143.9 134.4 C2H5NO2 Nitroethane(g) –103.8 –5 320.5 79 C2H6 Ethane(g) –84 –32 229.2 52.5 C2H6O Ethanol(l) –277.6 –174.8 160.7 112.3 C2H6O Ethanol(g) –234.8 –167.9 281.6 65.6 C2H6O Methoxymethane(l) –203,3 C2H6O Methoxymethane(g) –184.1 –112.6 266.4 C2H7N Ethylamine(l) –74.1 130 C2H7N Ethylamine(g) –47.5 36.3 283.8 71.5 C3H4 Cyclopropene(g) 277.1 286 244 53 C3H4 Propyne(g) 185 194 248 61 C3H6 Cyclopropane(l) 35.2 C3H6 Cyclopropane(g) 53.3 104.5 237.5 55.6 C3H6 Propene(g) 20 62 267 64 C3H6O Acetone(l) –248.4 199.8 126.3 C3H6O Acetone(g) –217.1 –152.7 295.3 74.5 C3H6O2 Propanoic acid(l) –510.7 191 152.8 C3H6O2 Propanoic acid(g) –455.7 C3H8 Propane(l) –120.9 C3H8 Propane(g) –103.8 –23.4 270.3 73.6 C3H8O 1-Propanol(l) –302.6 193.6 143.9 C3H8O 1-Propanol(g) –255.1 322.6 85.6 C3H8O 2-Propanol(l) –318.1 181.1 156.5 C3H8O 2-Propanol(g) –272.6 309.2 89.3 C3H9N 1-Propanamine(g) –72 40 324 C4H6 1-Butyne(l) 141.4 C4H6 1-Butyne(g) 165.2 202 291 81 C4H6 2-Butyne(l) 119.1 C4H6 2-Butyne(g) 145.7 185 283 78 C4H6 Cyclobutene(g) 156.7 175 64 64 C4H8 2-Methyl–1-propene(g) –17 58 294 89 C4H8 1-Butene(l) –20.8 227 118 C4H8 1-Butene(g) 0.1 71 306 86 C4H8 Cyclobutane(l) 3.7 C4H8 Cyclobutane(g) 27.7 110 265 C4H8O2 Butanoic acid(l) –533.8 222.2 178.6 C4H8O2 Butanoic acid(g) –475.9 C4H10 2-Methylpropane(g) –135 –21 295 97 C4H10 Butane(l) –147.3 140.9 C4H10 Butane(g) –125.7 –17 310 98 C4H10O 1-Butanol(l) –327.3 225.8 177.2 C4H10O 1-Butanol(g) –274.9 C4H10O 2-Butanol(l) –342.6 214.9 196.9 C4H10O 2-Butanol(g) –292.8 359.5 112.7 C5H8 1-Pentyne(g) 144 210 330 105 C5H8 2-Pentyne(g) 129 194 332 99 C5H8 Cyclopentene(l) 4.3 201.2 122.4 C5H8 Cyclopentene(g) 34 111 290 75 C5H10 1-Pentene(l) –46.9 262.6 154 C5H10 1-Pentene(g) –21.1 79 346 110 C5H10 2-Methyl–1-butene(g) –35.2 66 340 112 C5H10 2-Methyl–1-butene(l) –61.1 254 157.2 C5H10 Cyclopentane(l) –105.1 204.5 128.8 C5H10 Cyclopentane(g) –76.4 39 293 83 C5H10O2 Pentanoic acid(l) –559.4 259.8 210.3 C5H10O2 Pentanoic acid(g) –491.9 C5H12 2,2-Dimethylpropane(g) –166 –15 306 122 C5H12 2-Methylbutane(g) –155 –15 344 119 C5H12 Pentane(l) –173.5 167.2 C5H12 Pentane(g) –146.9 –8 349 120 C5H12O 1-Pentanol(l) –351.6 208.1 C5H12O 1-Pentanol(g) –294.6 C5H12O 2-Pentanol(l) –365.2 C5H12O 2-Pentanol(g) –311 C5H12O 3-Pentanol(l) –368.9 239.7 C5H12O 3-Pentanol(g) –314.9 C5H12O Methyl tert-butyl ether(l) –313.6 265.3 187.5 C5H12O Methyl tert-butyl ether(g) –283.7 C6H6 Benzene(l) 49.1 124.5 173.4 136 C6H6 Benzene(g) 82.9 129.7 269.2 82.4 C6H7N Aniline(l) 191.9 C6H7N Aniline(g) 87.5 –7 317.9 107.9 C6H10 1-Hexyne(g) 124 219 369 128 C6H10 Cyclohexene(l) –28.5 214.6 148.3 C6H10 Cyclohexene(g) –5 107 311 105 C6H12 1-Hexene(l) –74.2 295.2 183.3 C6H12 1-Hexene(g) –43.5 87 385 132 C6H12 2-Methyl–1-pentene(g) –59.4 C6H12 2-Methyl–1-pentene(l) –90 C6H12 Cyclohexane(l) –156.4 154.9 C6H12 Cyclohexane(g) –123.4 32 298 106 C6H12 Methylcyclopentane(g) –106.2 C6H12 Methylcyclopentane(l) –137.9 C6H12O2 Hexanoic acid(l) –583.8 C6H12O2 Hexanoic acid(g) –511.9 C6H14 2,2-Dimethylbutane(g) –185.9 –10 358 142 C6H14 2,2-Dimethylbutane(l) –213.8 272.5 191.9 C6H14 2-Methylpentane(g) –174.6 –5 381 144 C6H14 2-Methylpentane(l) –204.6 290.6 193.7 C6H14 3-Methylpentane(g) –171.9 –2 380 143 C6H14 3-Methylpentane(l) –202.4 292.5 190.7 C6H14 Hexane(l) –198.7 195.6 C6H14 Hexane(g) –166.9 –0.3 388 143 C6H14O 1-Hexanol(l) –377.5 287.4 240.4 C6H14O 1-Hexanol(g) 315.9 C6H14O 2-Hexanol(l) –392 C6H14O 2-Hexanol(g) –333.5 C7H6O Phenol(s) –165.1 144 127.4 C7H6O Phenol(g) –96.4 –33 316 104 C7H8 Methylbenzene(l) 12.0 220 156 C7H8 Methylbenzene(g) 50.0 122 321 104 C7H14 1-Heptene(l) –97.9 327.6 211.8 C7H14 1-Heptene(g) –62.3 96 424 15 C7H14 Cycloheptane(l) –156.6 C7H14 Cycloheptane(g) –118.1 C7H14 Ethylcyclopentane(l) –163.4 279.9 C7H14 Ethylcyclopentane(g) –126.9 C7H14 Methylcyclohexane(g) –154.7 C7H14 Methylcyclohexane(l) –190.1 184.8 C7H14O2 Heptanoic acid(l) –610.2 265.4 C7H14O2 Heptanoic acid(g) –536.2 C7H16 2,2-Dimethylpentane(g) –205.7 C7H16 2,2-Dimethylpentane(l) –238.3 300.3 221.1 C7H16 2-Methylhexane(g) –194.5 C7H16 2-Methylhexane(l) –229.5 323.3 222.9 C7H16 3-Methylhexane(g) –191.3 C7H16 3-Methylhexane(l) –226.4 C7H16 Heptane(l) –224.2 224.7 C7H16 Heptane(g) –187.6 8 428 166 C7H16O 1-Heptanol(l) –403.3 272.1 C7H16O 1-Heptanol(g) –336.5 C8H10 Ethylbenzene(l) –12.3 183.2 C8H10 Ethylbenzene(g) 29.9 131 361 128 C8H16 1-Octene(l) –124.5 241 C8H16 1-Octene(g) –81.3 104 463 178 C8H16 Cyclooctane(l) –167.7 C8H16 Cyclooctane(g) –124.4 C8H16 Ethylcyclohexane(l) –212.1 280.9 211.8 C8H16 Ethylcyclohexane(g) –171.5 C8H16O2 Octanoic acid(l) –636 297.9 C8H16O2 Octanoic acid(g) –554.3 C8H18 2-Methylheptane(g) –215.3 C8H18 2-Methylheptane(l) –255 356.4 252 C8H18 3-Methylheptane(g) –212.5 C8H18 3-Methylheptane(l) –252.3 362.6 250.2 C8H18 Octane(l) –250.1 254.6 C8H18 Octane(g) –208.5 16 467 189 C8H18O 1-Octanol(l) –426.5 305.2 C8H18O 1-Octanol(g) –355.6 C8H19 2,2-Dimethylhexane(g) –224.5 C8H19 2,2-Dimethylhexane(l) –261.9 C9H18 Propylcyclohexane(g) –192 420 242 C9H12 Propylbenzene(g) 8 137 401 154 C9H16 1-Nonyne(l) 16.3 C9H16 1-Nonyne(g) 62.3 C9H18O2 Nonanoic acid(l) –659.7 362.4 C9H18O2 Nonanoic acid(g) –577.3 C9H20 2,2-Dimethylheptane(g) –246 C9H20 2,2-Dimethylheptane(l) –288.1 C9H20 Nonane(l) –274.7 284.4 C9H20 Nonane(g) –228.2 25 506 212 C9H20O 1-Nonanol(l) –453.4 C9H20O 1-Nonanol(g) –376.5 C10H8 Naphthalene(g) 151 224 336 C10H14 Butylbenzene(l) –63.2 321.2 243.4 C10H14 Butylbenzene(g) –11.8 C10H20 1-Decene(l) –173.8 425 300.8 C10H20 1-Decene(g) –123.3 301 C10H20 Butylcyclohexane(l) –263.1 345 271 C10H20 Butylcyclohexane(g) –213.7 C10H20O2 Decanoic acid(s) –713.7 C10H20O2 Decanoic acid(l) –684.3 C10H20O2 Decanoic acid(g) –594.9 C10H22 2-Methylnonane(g) –260.2 C10H22 2-Methylnonane(l) –309.8 420.1 313.3 C10H22 Decane(l) –300.9 314.4 C10H22 Decane(g) –249.5 33 545 235 C10H22O 1-Decanol(l) –478.1 370.6 C10H22O 1-Decanol(g) –396.6 C11H10 1-Methylnaphthalene(l) 56.3 254.8 224.4 C11H10 2-Methylnaphthalene(s) 44.9 220 196 C11H10 2-Methylnaphthalene(g) 106.7 C11H22 1-Undecene(g) 344.9 C11H24 Undecane(l) –327.2 344.9 C11H24 Undecane(g) –270.8 42 584 257 C11H24O 1-Undecanol(l) –504.8 C12H24 1-Dodecene(l) –226.2 484.8 360.7 C12H24 1-Dodecene(g) –165.4 C12H24O2 Dodecanoic acid(s) –774.6 404.3 C12H24O2 Dodecanoic acid(l) –737.9 C12H24O2 Dodecanoic acid(g) 642 C12H26 Dodecane(l) –350.9 375.8 C12H26 Dodecane(g) –289.4 50 623 280 C12H26O 1-Dodecanol(l) –528.5 438.1 C12H26O 1-Dodecanol(g) –436.6 C14H10 Anthracene(g) 231 C14H10 Phenantrene(g) 207 C15H30 Decylcyclopentane(l) –367.3 C16H26 Decylbenzene(l) –218.3 C16H26 Decylbenzene(g) –138.6 C16H32 1-Hexadecene(l) –328.7 587.9 488.9 C16H32 1-Hexadecene(g) –248.4 C16H32O2 Hexadecanoic acid(s) –891.5 452.4 460.7 C16H32O2 Hexadecanoic acid(l) –838.1 C16H32O2 Hexadecanoic acid(g) –737.1 C16H34 N-hexadecane(l) –456.1 501.6 C16H34 N-hexadecane(g) –374.8 C18H12 Chrysene(s) 145.3 C18H12 Chrysene(g) 269.8 "]
]
